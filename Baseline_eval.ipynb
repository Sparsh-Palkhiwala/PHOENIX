{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1MwOE0yqZWueCPQDdQvIIkVcXX7bu0LYX",
      "authorship_tag": "ABX9TyMnmir5mnNXBinXmjPFsdhy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db012bfe818b4edabbd24b266baef7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_256c605f4f9640bbb2a576a9803f4ff3",
              "IPY_MODEL_eaa7c5800fa648b2a8085d1273cc73e7",
              "IPY_MODEL_1d650f1917334662b7f49003b2daabf4"
            ],
            "layout": "IPY_MODEL_9a49e90f9e2641a0b51584f803bd39d7"
          }
        },
        "256c605f4f9640bbb2a576a9803f4ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edcb763e77f349dda160eb819bb85ba7",
            "placeholder": "​",
            "style": "IPY_MODEL_ad3dcbb70b7144cbb35a8457491a3352",
            "value": "config.json: 100%"
          }
        },
        "eaa7c5800fa648b2a8085d1273cc73e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea587046dfd5476aa093d6df0ae9753c",
            "max": 1455,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_def3fb945dff43bab1ec3eb8c81424ad",
            "value": 1455
          }
        },
        "1d650f1917334662b7f49003b2daabf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8482dae6d944633b23595864343d3ba",
            "placeholder": "​",
            "style": "IPY_MODEL_bc9b0cfca5e24e85a12831de71205609",
            "value": " 1.46k/1.46k [00:00&lt;00:00, 28.7kB/s]"
          }
        },
        "9a49e90f9e2641a0b51584f803bd39d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edcb763e77f349dda160eb819bb85ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad3dcbb70b7144cbb35a8457491a3352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea587046dfd5476aa093d6df0ae9753c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "def3fb945dff43bab1ec3eb8c81424ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8482dae6d944633b23595864343d3ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc9b0cfca5e24e85a12831de71205609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fc7e709ccc14b179461d2b37c1bcc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9af5e9c6b2f8439ca7316f831bd1627e",
              "IPY_MODEL_bc9bd06c95e14d0ba85b22f644a761ea",
              "IPY_MODEL_31b67c66e15b44fda4ddc79ecec28792"
            ],
            "layout": "IPY_MODEL_e42d4a3ea62a4e378470993a7b8a56cb"
          }
        },
        "9af5e9c6b2f8439ca7316f831bd1627e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a4798ed22744c65ac4087b4999d6634",
            "placeholder": "​",
            "style": "IPY_MODEL_ee6997e72b3b40deb0ccebaa41413e78",
            "value": "model.safetensors: 100%"
          }
        },
        "bc9bd06c95e14d0ba85b22f644a761ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0081d8442f77471b801644096c6d7ef1",
            "max": 10672390984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5991da72224d4f78812a62085082d9df",
            "value": 10672390984
          }
        },
        "31b67c66e15b44fda4ddc79ecec28792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5be9123210f479681d71dadca07ddc6",
            "placeholder": "​",
            "style": "IPY_MODEL_b5399ec570e2420ea2b84d8ec31ad96d",
            "value": " 10.7G/10.7G [01:18&lt;00:00, 205MB/s]"
          }
        },
        "e42d4a3ea62a4e378470993a7b8a56cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a4798ed22744c65ac4087b4999d6634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee6997e72b3b40deb0ccebaa41413e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0081d8442f77471b801644096c6d7ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5991da72224d4f78812a62085082d9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5be9123210f479681d71dadca07ddc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5399ec570e2420ea2b84d8ec31ad96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be19edfe9118476f88a8c737ade64c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a7772f842f045f3932663e2621b3648",
              "IPY_MODEL_7bd6b1b2d4b948da9206b4b07fde89a5",
              "IPY_MODEL_c981c4a27e8245ecaa47dd4e768cd1e2"
            ],
            "layout": "IPY_MODEL_84ca1d444d24472093880f762bb920c9"
          }
        },
        "8a7772f842f045f3932663e2621b3648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca683dae34004b4b8f95f2acb4dcf57d",
            "placeholder": "​",
            "style": "IPY_MODEL_3122ca4930d349aeb35015996dbc71ce",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7bd6b1b2d4b948da9206b4b07fde89a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b527eeba050e49b2be09530aee444d52",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e563c0ba2ac547ddb7b8951845de6e0b",
            "value": 200
          }
        },
        "c981c4a27e8245ecaa47dd4e768cd1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_324e4185440a4bd08b4339e637a60930",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd65a3ce84d4244a78277c55a9d2d86",
            "value": " 200/200 [00:00&lt;00:00, 11.2kB/s]"
          }
        },
        "84ca1d444d24472093880f762bb920c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca683dae34004b4b8f95f2acb4dcf57d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3122ca4930d349aeb35015996dbc71ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b527eeba050e49b2be09530aee444d52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e563c0ba2ac547ddb7b8951845de6e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "324e4185440a4bd08b4339e637a60930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd65a3ce84d4244a78277c55a9d2d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f62864ded19b40688fd3de7a6ff4a2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec4af6871a6a4db4b004c3bae28a2077",
              "IPY_MODEL_4d402069621445a08df07134b3adaea3",
              "IPY_MODEL_98504b1208934b2596820e5b449feb63"
            ],
            "layout": "IPY_MODEL_5014d273955044dbaf736ccb696919f1"
          }
        },
        "ec4af6871a6a4db4b004c3bae28a2077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e852da58d640aebd9f292f8864c8df",
            "placeholder": "​",
            "style": "IPY_MODEL_c641a70f07d046f5ac88acea76ad4a2b",
            "value": "vocab.json: 100%"
          }
        },
        "4d402069621445a08df07134b3adaea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c1ce06065774f658b5101f41795da53",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecb1cac4df3746e0a72a9864bf7e3d55",
            "value": 798156
          }
        },
        "98504b1208934b2596820e5b449feb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04cc32ecf998470aa4ee8e89756c5599",
            "placeholder": "​",
            "style": "IPY_MODEL_5d00826be75e409bb9cca834c772c05f",
            "value": " 798k/798k [00:00&lt;00:00, 6.96MB/s]"
          }
        },
        "5014d273955044dbaf736ccb696919f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e852da58d640aebd9f292f8864c8df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c641a70f07d046f5ac88acea76ad4a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c1ce06065774f658b5101f41795da53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb1cac4df3746e0a72a9864bf7e3d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04cc32ecf998470aa4ee8e89756c5599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d00826be75e409bb9cca834c772c05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e59e9c40d814f1b9bbf88fd363924a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de3647ac64304a098c2a55e006f20065",
              "IPY_MODEL_e641a3cf9c314bb8874de9e9dab45616",
              "IPY_MODEL_819c0b8ff5ca41a79c6cc839cb34f91e"
            ],
            "layout": "IPY_MODEL_ea5cfca477ca49a1993415a9a8c0876c"
          }
        },
        "de3647ac64304a098c2a55e006f20065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e797eb02167e4930af126b2546c79636",
            "placeholder": "​",
            "style": "IPY_MODEL_e46a367397c946bb8508953c1e0880bc",
            "value": "merges.txt: 100%"
          }
        },
        "e641a3cf9c314bb8874de9e9dab45616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546f5a74827d4369ba8f2fe3ecbd6bd2",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7653655e0f114035b3a7de73a83f2a92",
            "value": 456356
          }
        },
        "819c0b8ff5ca41a79c6cc839cb34f91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d5563cb76d46abbf4a947b43b067ff",
            "placeholder": "​",
            "style": "IPY_MODEL_55ad0b13f0124b5a85ecf8543c7b6fd4",
            "value": " 456k/456k [00:00&lt;00:00, 3.18MB/s]"
          }
        },
        "ea5cfca477ca49a1993415a9a8c0876c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e797eb02167e4930af126b2546c79636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46a367397c946bb8508953c1e0880bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "546f5a74827d4369ba8f2fe3ecbd6bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7653655e0f114035b3a7de73a83f2a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1d5563cb76d46abbf4a947b43b067ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ad0b13f0124b5a85ecf8543c7b6fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0294cc1065540fdbb9d6b8272588eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63bc5e3c7146421da90411d1d5066498",
              "IPY_MODEL_3d14c10d189f4e70992ae680f150c5f0",
              "IPY_MODEL_47546720f2bf4be28c79658304f5ab03"
            ],
            "layout": "IPY_MODEL_e4dc78c989ce4025973a37acbfe308a7"
          }
        },
        "63bc5e3c7146421da90411d1d5066498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef8388cc2ee4c09b8acbfa568221b5f",
            "placeholder": "​",
            "style": "IPY_MODEL_b33baeed15334356a9cfcc0a306b1bff",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3d14c10d189f4e70992ae680f150c5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a500375c8ad44349a93cffdb5335cc5",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77e54c917ce34000a3221ff78d060fcd",
            "value": 90
          }
        },
        "47546720f2bf4be28c79658304f5ab03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccff3406115e4f7da74d9b9d76964fb2",
            "placeholder": "​",
            "style": "IPY_MODEL_9cba8ea3afb440aa97ebbf509661d56a",
            "value": " 90.0/90.0 [00:00&lt;00:00, 4.67kB/s]"
          }
        },
        "e4dc78c989ce4025973a37acbfe308a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef8388cc2ee4c09b8acbfa568221b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33baeed15334356a9cfcc0a306b1bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a500375c8ad44349a93cffdb5335cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e54c917ce34000a3221ff78d060fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccff3406115e4f7da74d9b9d76964fb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cba8ea3afb440aa97ebbf509661d56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sparsh-Palkhiwala/PHOENIX/blob/main/Baseline_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2C3KWfXTNJs",
        "outputId": "f0b610e6-e252-4104-cfc1-61168d78a989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate torch nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the dataset is huge, we are sampling random questions from the dataset so that we can get a baseline before we start the finetuning dataset\n",
        "import json\n",
        "import random\n",
        "\n",
        "def load_and_sample_json(file_path, num_samples=50):\n",
        "    \"\"\"Loads a JSON dataset, samples data points, and merges fields.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the JSON file.\n",
        "        num_samples (int, optional): Number of samples to take. Defaults to 50.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each with \"input\" and \"answer\" fields.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        dataset = json.load(f)\n",
        "\n",
        "    # Ensure num_samples is not larger than the dataset\n",
        "    num_samples = min(num_samples, len(dataset))\n",
        "\n",
        "    # Sample indices randomly\n",
        "    sampled_indices = random.sample(range(len(dataset)), num_samples)\n",
        "\n",
        "    # Create a list of dictionaries with merged inputs and answers\n",
        "    sampled_data = []\n",
        "    for i in sampled_indices:\n",
        "        data_point = dataset[i]\n",
        "        sampled_data.append({\n",
        "            \"input\": data_point['given_info'] + \" \" + data_point['question'],\n",
        "            \"answer\": data_point['answer']  # Include the answer field\n",
        "        })\n",
        "\n",
        "    return sampled_data\n",
        "\n",
        "# Example usage:\n",
        "file_path = '/content/drive/MyDrive/ASU/SEM-3/PRL/Project/CLadder/cladder-v1-q-balanced.json'  # Replace with your file path\n",
        "sampled_data = load_and_sample_json(file_path, num_samples=100)\n",
        "\n",
        "# Now you can work with sampled_data, for example, save it to a new JSON file:\n",
        "with open('sampled_dataset.json', 'w') as f:\n",
        "    json.dump(sampled_data, f, indent=4)  # Save with indentation for readability\n",
        "\n",
        "# Or, you can access the data directly:\n",
        "for data_point in sampled_data:\n",
        "    print(f\"Input: {data_point['input']}\")\n",
        "    print(f\"Answer: {data_point['answer']}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g46V_ZEPaZAO",
        "outputId": "ea44ab7a-b622-4a7a-86a9-a0d85f8717a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: We know that jyka causes not yupt. jyka and yupt causes kwox. Would an individual is not kwox if jyka instead of not jyka?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of smoking mother is 94%. For infants with nonsmoking mothers, the probability of high infant mortality is 52%. For infants with smoking mothers, the probability of high infant mortality is 32%. Is high infant mortality more likely than low infant mortality overall?\n",
            "Answer: no\n",
            "---\n",
            "Input: For infants with nonsmoking mothers, the probability of high infant mortality is 37%. For infants with smoking mothers, the probability of high infant mortality is 70%. Will smoking mother increase the chance of high infant mortality?\n",
            "Answer: yes\n",
            "---\n",
            "Input: Method 1: We look directly at how jyka correlates with lirg in general. Method 2: We look at this correlation case by case according to gyzp. To understand how jyka affects lirg, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: no\n",
            "---\n",
            "Input: Method 1: We look directly at how pexu correlates with rukz in general. Method 2: We look at this correlation case by case according to kraz. To understand how pexu affects rukz, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not pexu, the probability of rukz is 57%. For those who are pexu, the probability of rukz is 48%. Will pexu decrease the chance of rukz?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not yupt and are not xyfo, the probability of muvq is 50%. For those who are not yupt and are xyfo, the probability of muvq is 65%. For those who are yupt and are not xyfo, the probability of muvq is 65%. For those who are yupt and are xyfo, the probability of muvq is 47%. For those who are not yupt, the probability of xyfo is 30%. For those who are yupt, the probability of xyfo is 39%. For those who are yupt, would it be more likely to see muvq if the individual was not yupt?\n",
            "Answer: no\n",
            "---\n",
            "Input: For individuals who do not like spicy food and blue-collar workers, the probability of high salary is 23%. For individuals who do not like spicy food and white-collar workers, the probability of high salary is 1%. For individuals who like spicy food and blue-collar workers, the probability of high salary is 48%. For individuals who like spicy food and white-collar workers, the probability of high salary is 28%. For individuals who do not like spicy food and with low skill levels, the probability of white-collar job is 49%. For individuals who do not like spicy food and with high skill levels, the probability of white-collar job is 19%. For individuals who like spicy food and with low skill levels, the probability of white-collar job is 75%. For individuals who like spicy food and with high skill levels, the probability of white-collar job is 40%. The overall probability of high skill level is 98%. If we disregard the mediation effect through occupation, would liking spicy food positively affect salary?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of yupt is 69%. The probability of not yupt and muvq is 23%. The probability of yupt and muvq is 53%. Is the chance of muvq larger when observing yupt?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of zuph is 85%. The probability of not zuph and glimx is 4%. The probability of zuph and glimx is 21%. Is the chance of glimx smaller when observing zuph?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not zuph, the probability of uvzi is 34%. For those who are zuph, the probability of uvzi is 77%. Does zuph positively affect uvzi through wibl and vubr?\n",
            "Answer: yes\n",
            "---\n",
            "Input: We know that zuph causes wibl and vubr. wibl and vubr causes uvzi. Would an individual is uvzi if zuph instead of not zuph?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of jyka is 21%. The probability of not jyka and lirg is 2%. The probability of jyka and lirg is 1%. Is the chance of lirg smaller when observing jyka?\n",
            "Answer: no\n",
            "---\n",
            "Input: The overall probability of jyka is 17%. For those who are not jyka, the probability of lirg is 46%. For those who are jyka, the probability of lirg is 8%. Is lirg more likely than not lirg overall?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not zuph and are not vubr, the probability of uvzi is 49%. For those who are not zuph and are vubr, the probability of uvzi is 48%. For those who are zuph and are not vubr, the probability of uvzi is 65%. For those who are zuph and are vubr, the probability of uvzi is 30%. For those who are not zuph, the probability of vubr is 48%. For those who are zuph, the probability of vubr is 52%. For those who are zuph, would it be more likely to see uvzi if the individual was not zuph?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of zuph is 82%. The probability of not zuph and glimx is 7%. The probability of zuph and glimx is 24%. Is the chance of glimx smaller when observing zuph?\n",
            "Answer: yes\n",
            "---\n",
            "Input: We know that zuph causes not rixq and swoy. rixq and swoy causes xevu. We observed an individual is not zuph. Would an individual is not xevu if rixq instead of not rixq?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not zuph, the probability of glimx is 70%. For those who are zuph, the probability of glimx is 72%. Will zuph increase the chance of glimx?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not yomx, the probability of xevu is 68%. For those who are yomx, the probability of xevu is 40%. For those who are yomx, would it be less likely to see xevu if the individual was not yomx?\n",
            "Answer: no\n",
            "---\n",
            "Input: For patients not consuming citrus, the probability of scurvy is 55%. For patients consuming citrus, the probability of scurvy is 41%. Does eating citrus negatively affect scurvy through vitmain C?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not hwax, the probability of lirg is 61%. For those who are hwax, the probability of lirg is 79%. For those who are not hwax, the probability of jyka is 40%. For those who are hwax, the probability of jyka is 12%. Will jyka decrease the chance of lirg?\n",
            "Answer: yes\n",
            "---\n",
            "Input: Method 1: We look at how eating citrus correlates with curly hair case by case according to vitmain C. Method 2: We look directly at how eating citrus correlates with curly hair in general. To understand how eating citrus affects curly hair, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: no\n",
            "---\n",
            "Input: For unvaccinated individuals, the probability of black hair is 42%. For vaccinated individuals, the probability of black hair is 60%. Does vaccination status positively affect black hair through getting smallpox and vaccination reaction?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of respiratory issues is 84%. For people with no respiratory issues, the probability of broken bones is 82%. For people with respiratory issues, the probability of broken bones is 82%. Is broken bones more likely than no broken bones overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are yupt, the correlation between jyka and kwox is -0.20. If we look at those who are yupt, does it mean that jyka affects kwox?\n",
            "Answer: no\n",
            "---\n",
            "Input: We know that female causes smoking. smoking causes high tar deposit. female and high tar deposit causes lung cancer. We observed the person is female. Would the person has no lung cancer if nonsmoking instead of smoking?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For patients who have small kidney stones and not receiving treatment, the probability of thick lips is 3%. For patients who have small kidney stones and receiving treatment, the probability of thick lips is 15%. For patients who have large kidney stones and not receiving treatment, the probability of thick lips is 79%. For patients who have large kidney stones and receiving treatment, the probability of thick lips is 91%. The overall probability of large kidney stone is 60%. Will receives treatment increase the chance of thick lips?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of rainy season is 93%. For people in the dry season, the probability of high rainfall is 56%. For in the rainy season, the probability of high rainfall is 43%. Is high rainfall more likely than low rainfall overall?\n",
            "Answer: no\n",
            "---\n",
            "Input: The overall probability of tanning salon treatment is 89%. For people not using tanning salon treatments, the probability of tanned skin is 54%. For people who went to tanning salons, the probability of tanned skin is 16%. Is tanned skin less likely than pale skin overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not wibl and are not zuph, the probability of uvzi is 34%. For those who are not wibl and are zuph, the probability of uvzi is 63%. For those who are wibl and are not zuph, the probability of uvzi is 70%. For those who are wibl and are zuph, the probability of uvzi is 36%. The overall probability of wibl is 85%. Will zuph decrease the chance of uvzi?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For normal weight people, the probability of long lifespan is 63%. For obese people, the probability of long lifespan is 53%. For obese people, would it be less likely to see long lifespan if the person had been normal weight?\n",
            "Answer: no\n",
            "---\n",
            "Input: The overall probability of having visited England is 14%. For people who have not visited England, the probability of employee being fired is 19%. For people who have visited England, the probability of employee being fired is 64%. Is employee being fired less likely than employee not being fired overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of having a brother is 49%. The probability of not having a brother and recovering from the disease is 22%. The probability of having a brother and recovering from the disease is 36%. Is the chance of recovering from the disease larger when observing having a brother?\n",
            "Answer: yes\n",
            "---\n",
            "Input: Method 1: We look at how yomx correlates with xevu case by case according to gwet. Method 2: We look directly at how yomx correlates with xevu in general. To understand how yomx affects xevu, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: no\n",
            "---\n",
            "Input: We know that female causes smoking. smoking causes absence of tar deposit. female and high tar deposit causes lung cancer. We observed the person is female. Would the person has lung cancer if nonsmoking instead of smoking?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of alarm set by husband is 18%. The probability of alarm not set by husband and ringing alarm is 56%. The probability of alarm set by husband and ringing alarm is 3%. Is the chance of ringing alarm smaller when observing alarm set by husband?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For people not taking any medication, the probability of healthy heart is 24%. For people taking medication, the probability of healthy heart is 69%. Will taking medication decrease the chance of healthy heart?\n",
            "Answer: no\n",
            "---\n",
            "Input: For people without a college degree, the probability of high salary is 55%. For people with a college degree or higher, the probability of high salary is 87%. For people with a college degree or higher, would it be less likely to see high salary if the person had not had a college degree?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of attractive appearance is 49%. For people considered unattractive and are not famous, the probability of thick lips is 9%. For people considered unattractive and are famous, the probability of thick lips is 29%. For people considered attractive and are not famous, the probability of thick lips is 6%. For people considered attractive and are famous, the probability of thick lips is 21%. If we look at people who are famous, does the chance of thick lips decrease when attractive appearance?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not zuph, the probability of jyka is 24%. For those who are zuph, the probability of jyka is 51%. For those who are not zuph and are not jyka, the probability of glimx is 40%. For those who are not zuph and are jyka, the probability of glimx is 32%. For those who are zuph and are not jyka, the probability of glimx is 30%. For those who are zuph and are jyka, the probability of glimx is 38%. The overall probability of zuph is 38%. Does zuph negatively affect glimx through jyka?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not jyka, the probability of kwox is 81%. For those who are jyka, the probability of kwox is 27%. Will jyka decrease the chance of kwox?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For husbands that don't set the alarm, the probability of ringing alarm is 86%. For husbands that set the alarm, the probability of ringing alarm is 34%. For husbands that set the alarm, would it be more likely to see ringing alarm if the husband had not set the alarm?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of male gender is 6%. The probability of non-male gender and being lactose intolerant is 53%. The probability of male gender and being lactose intolerant is 1%. Is the chance of being lactose intolerant smaller when observing male gender?\n",
            "Answer: yes\n",
            "---\n",
            "Input: We know that blowing out the candle or candle with wax causes dark room. We observed the candle has wax. Would the room is dark if not blowing out the candle instead of blowing out the candle?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For nonsmokers and are lazy, the probability of college admission is 69%. For nonsmokers and are hard-working, the probability of college admission is 40%. For smokers and are lazy, the probability of college admission is 64%. For smokers and are hard-working, the probability of college admission is 26%. For nonsmokers, the probability of being hard-working is 16%. For smokers, the probability of being hard-working is 72%. Does smoking negatively affect college admission through effort?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For people who do not play card games and without diabetes, the probability of long lifespan is 41%. For people who do not play card games and with diabetes, the probability of long lifespan is 61%. For people who play card games and without diabetes, the probability of long lifespan is 63%. For people who play card games and with diabetes, the probability of long lifespan is 86%. For people who do not play card games and nonsmokers, the probability of having diabetes is 84%. For people who do not play card games and smokers, the probability of having diabetes is 60%. For people who play card games and nonsmokers, the probability of having diabetes is 56%. For people who play card games and smokers, the probability of having diabetes is 25%. The overall probability of smoker is 95%. If we disregard the mediation effect through diabetes, would playing card games negatively affect lifespan?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not zuph, the probability of glimx is 38%. For those who are zuph, the probability of glimx is 32%. Will zuph decrease the chance of glimx?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For people with no pre-conditions and refusing the vaccine, the probability of recovering from the disease is 7%. For people with no pre-conditions and getting the vaccine, the probability of recovering from the disease is 18%. For people with pre-conditions and refusing the vaccine, the probability of recovering from the disease is 81%. For people with pre-conditions and getting the vaccine, the probability of recovering from the disease is 94%. The overall probability of pre-conditions is 50%. For people getting the vaccine, would it be more likely to see recovering from the disease if the person had not refused the vaccine?\n",
            "Answer: no\n",
            "---\n",
            "Input: We know that hwax causes pexu and kraz. pexu and kraz causes rukz. We observed an individual is hwax. Would an individual is rukz if not pexu instead of pexu?\n",
            "Answer: no\n",
            "---\n",
            "Input: The overall probability of rainy season is 28%. For people in the dry season, the probability of wet ground is 39%. For in the rainy season, the probability of wet ground is 46%. Is wet ground less likely than dry ground overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of taking medication is 14%. The probability of not taking medication and healthy heart is 53%. The probability of taking medication and healthy heart is 5%. Is the chance of healthy heart smaller when observing taking medication?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For people with nonsmoking genes and nonsmokers, the probability of lung cancer is 61%. For people with nonsmoking genes and smokers, the probability of lung cancer is 31%. For people with smoking genes and nonsmokers, the probability of lung cancer is 69%. For people with smoking genes and smokers, the probability of lung cancer is 32%. For people with nonsmoking genes and with low pollution, the probability of smoking is 62%. For people with nonsmoking genes and with high pollution, the probability of smoking is 34%. For people with smoking genes and with low pollution, the probability of smoking is 31%. For people with smoking genes and with high pollution, the probability of smoking is 9%. The overall probability of high pollution is 44%. Does gene negatively affect lung cancer through smoking?\n",
            "Answer: no\n",
            "---\n",
            "Input: For people who are famous, the correlation between attractive appearance and talent is -0.08. If we look at people who are famous, does it mean that attractive appearance affects talent?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not jyka, the probability of lirg is 20%. For those who are jyka, the probability of lirg is 40%. Will jyka decrease the chance of lirg?\n",
            "Answer: no\n",
            "---\n",
            "Input: For individuals who are not male, the probability of brown eyes is 75%. For individuals who are male, the probability of brown eyes is 82%. For individuals who are male, would it be more likely to see brown eyes if the individual had not been male?\n",
            "Answer: no\n",
            "---\n",
            "Input: Method 1: We look at how zuph correlates with glimx case by case according to zory. Method 2: We look directly at how zuph correlates with glimx in general. To understand how zuph affects glimx, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: yes\n",
            "---\n",
            "Input: Method 1: We look at how talent correlates with effort case by case according to elite institution admission status. Method 2: We look directly at how talent correlates with effort in general. To understand how talent affects effort, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: no\n",
            "---\n",
            "Input: The overall probability of xevo is 64%. For those who are not xevo, the probability of gyzp is 42%. For those who are xevo, the probability of gyzp is 23%. Is gyzp less likely than not gyzp overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: Method 1: We look directly at how kwox correlates with kwoz in general. Method 2: We look at this correlation case by case according to swoq. To understand how kwox affects kwoz, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: no\n",
            "---\n",
            "Input: The overall probability of xevo is 36%. For those who are not xevo, the probability of gyzp is 27%. For those who are xevo, the probability of gyzp is 24%. Is gyzp less likely than not gyzp overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of smoking is 90%. For nonsmokers, the probability of college admission is 67%. For smokers, the probability of college admission is 55%. Is college admission more likely than college rejection overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of waking up late is 11%. The probability of waking up on time and high rainfall is 35%. The probability of waking up late and high rainfall is 8%. Is the chance of high rainfall smaller when observing waking up late?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not yu'detpt, the probability of kwox is 55%. For those who are yupt, the probability of kwox is 76%. For those who are not yu'detpt, the probability of jyka is 29%. For those who are yupt, the probability of jyka is 66%. Will jyka decrease the chance of kwox?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not yupt, the probability of muvq is 46%. For those who are yupt, the probability of muvq is 89%. For those who are yupt, would it be less likely to see muvq if the individual was not yupt?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of smoking is 90%. For nonsmokers, the probability of freckles is 67%. For smokers, the probability of freckles is 55%. Is freckles less likely than no freckles overall?\n",
            "Answer: no\n",
            "---\n",
            "Input: The overall probability of tanning salon treatment is 82%. The probability of no tanning salon treatment and tanned skin is 12%. The probability of tanning salon treatment and tanned skin is 19%. Is the chance of tanned skin smaller when observing tanning salon treatment?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of taking medication is 92%. The probability of not taking medication and healthy heart is 4%. The probability of taking medication and healthy heart is 67%. Is the chance of healthy heart smaller when observing taking medication?\n",
            "Answer: no\n",
            "---\n",
            "Input: For nonsmokers and with no tar deposit, the probability of lung cancer is 44%. For nonsmokers and with high tar deposit, the probability of lung cancer is 96%. For smokers and with no tar deposit, the probability of lung cancer is 25%. For smokers and with high tar deposit, the probability of lung cancer is 70%. For nonsmokers, the probability of high tar deposit is 62%. For smokers, the probability of high tar deposit is 93%. For smokers, would it be more likely to see lung cancer if the person had been a nonsmoker?\n",
            "Answer: no\n",
            "---\n",
            "Input: For students who are not encouraged, the probability of high exam score is 75%. For students who are encouraged, the probability of high exam score is 48%. Will encouragement decrease the chance of high exam score?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For individuals who are not male and applicants to a non-competitive department, the probability of freckles is 41%. For individuals who are not male and applicants to a competitive department, the probability of freckles is 64%. For individuals who are male and applicants to a non-competitive department, the probability of freckles is 64%. For individuals who are male and applicants to a competitive department, the probability of freckles is 87%. For individuals who are not male and out-of-state residents, the probability of competitive department is 8%. For individuals who are not male and in-state residents, the probability of competitive department is 39%. For individuals who are male and out-of-state residents, the probability of competitive department is 44%. For individuals who are male and in-state residents, the probability of competitive department is 72%. The overall probability of in-state residency is 1%. Does gender positively affect freckles through department competitiveness?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For people who do not have a brother, the probability of ringing alarm is 74%. For people who have a brother, the probability of ringing alarm is 22%. Will having a brother decrease the chance of ringing alarm?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of pexu is 33%. For those who are not pexu, the probability of rukz is 39%. For those who are pexu, the probability of rukz is 31%. Is rukz less likely than not rukz overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: Method 1: We look directly at how xevo correlates with gyzp in general. Method 2: We look at this correlation case by case according to tijv. To understand how xevo affects gyzp, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For infants with nonsmoking mothers, the probability of freckles is 42%. For infants with smoking mothers, the probability of freckles is 75%. Will smoking mother increase the chance of freckles?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For people who do not drink coffee, the probability of ringing alarm is 41%. For people who drink coffee, the probability of ringing alarm is 47%. For people who drink coffee, would it be less likely to see ringing alarm if the person did not drink coffee?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of jyka is 13%. For those who are not jyka, the probability of lirg is 55%. For those who are jyka, the probability of lirg is 66%. Is lirg less likely than not lirg overall?\n",
            "Answer: no\n",
            "---\n",
            "Input: The overall probability of taking of all assigned drugs is 45%. The probability of not taking of any assigned drugs and low cholesterol is 45%. The probability of taking of all assigned drugs and low cholesterol is 40%. Is the chance of low cholesterol larger when observing taking of all assigned drugs?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not kwox and are not muvy, the probability of kwoz is 39%. For those who are not kwox and are muvy, the probability of kwoz is 47%. For those who are kwox and are not muvy, the probability of kwoz is 57%. For those who are kwox and are muvy, the probability of kwoz is 62%. For those who are not kwox, the probability of muvy is 61%. For those who are kwox, the probability of muvy is 67%. For those who are kwox, would it be more likely to see kwoz if the individual was not kwox?\n",
            "Answer: no\n",
            "---\n",
            "Input: For farms with reduced crop yield per acre, the probability of increased price is 59%. For farms with increased crop yield per acre, the probability of increased price is 48%. For farms with reduced crop yield per acre, the probability of increased supply is 48%. For farms with increased crop yield per acre, the probability of increased supply is 92%. Will increased supply increase the chance of increased price?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not xevo, the probability of tijv is 31%. For those who are xevo, the probability of tijv is 83%. For those who are not xevo and are not tijv, the probability of gyzp is 70%. For those who are not xevo and are tijv, the probability of gyzp is 28%. For those who are xevo and are not tijv, the probability of gyzp is 70%. For those who are xevo and are tijv, the probability of gyzp is 29%. The overall probability of xevo is 22%. Does xevo positively affect gyzp through tijv?\n",
            "Answer: no\n",
            "---\n",
            "Input: We know that citrus intake causes vitamin C deficiency, and we know that sufficient vitamin C causes no scurvy. Would the patient recovers from scurvy if citrus intake instead of absence of citrus?\n",
            "Answer: no\n",
            "---\n",
            "Input: For those who are not yupt and are not xyfo, the probability of muvq is 7%. For those who are not yupt and are xyfo, the probability of muvq is 77%. For those who are yupt and are not xyfo, the probability of muvq is 73%. For those who are yupt and are xyfo, the probability of muvq is 14%. For those who are not yupt, the probability of xyfo is 14%. For those who are yupt, the probability of xyfo is 11%. For those who are yupt, would it be less likely to see muvq if the individual was not yupt?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of encouragement is 45%. For students who are not encouraged, the probability of high exam score is 21%. For students who are encouraged, the probability of high exam score is 87%. Is high exam score less likely than low exam score overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For individuals who do not like spicy food, the probability of high salary is 44%. For individuals who like spicy food, the probability of high salary is 29%. For individuals who like spicy food, would it be more likely to see high salary if the individual did not like spicy food?\n",
            "Answer: yes\n",
            "---\n",
            "Input: We know that obesity or smoker causes having diabetes. obesity or smoker or having diabetes causes long lifespan. We observed the person is a nonsmoker. Would the person has a short lifespan if obesity instead of normal weight?\n",
            "Answer: no\n",
            "---\n",
            "Input: For people who do not like spicy food, the probability of the forest on fire is 21%. For people who like spicy food, the probability of the forest on fire is 92%. Will liking spicy food increase the chance of the forest on fire?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not pexu, the probability of rukz is 59%. For those who are pexu, the probability of rukz is 63%. Will pexu decrease the chance of rukz?\n",
            "Answer: no\n",
            "---\n",
            "Input: We know that cwoi causes yomx. yomx causes not gwet. cwoi or gwet causes xevu. We observed an individual is cwoi. Would an individual is not xevu if not yomx instead of yomx?\n",
            "Answer: no\n",
            "---\n",
            "Input: Method 1: We look directly at how encouragement level correlates with exam score in general. Method 2: We look at this correlation case by case according to studying habit. To understand how encouragement level affects exam score, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: yes\n",
            "---\n",
            "Input: We know that drinking coffee causes alarm set by wife. drinking coffee or alarm set by wife causes ringing alarm. Would the alarm rings the next morning if drinking coffee instead of not drinking coffee?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For people who do not speak english, the probability of the forest on fire is 87%. For people who speak english, the probability of the forest on fire is 53%. For people who speak english, would it be more likely to see the forest on fire if the person did not speak english?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For patients not assigned the drug treatment, the probability of low cholesterol is 61%. For patients assigned the drug treatment, the probability of low cholesterol is 63%. For patients not assigned the drug treatment, the probability of taking of all assigned drugs is 39%. For patients assigned the drug treatment, the probability of taking of all assigned drugs is 63%. Will taking of all assigned drugs decrease the chance of low cholesterol?\n",
            "Answer: no\n",
            "---\n",
            "Input: For people with no pre-conditions and refusing the vaccine, the probability of being lactose intolerant is 9%. For people with no pre-conditions and getting the vaccine, the probability of being lactose intolerant is 32%. For people with pre-conditions and refusing the vaccine, the probability of being lactose intolerant is 75%. For people with pre-conditions and getting the vaccine, the probability of being lactose intolerant is 98%. The overall probability of pre-conditions is 54%. Will getting the vaccine increase the chance of being lactose intolerant?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not xevo and are not tijw, the probability of gyzp is 63%. For those who are not xevo and are tijw, the probability of gyzp is 82%. For those who are xevo and are not tijw, the probability of gyzp is 18%. For those who are xevo and are tijw, the probability of gyzp is 84%. For those who are not xevo, the probability of tijw is 31%. For those who are xevo, the probability of tijw is 49%. For those who are xevo, would it be more likely to see gyzp if the individual was not xevo?\n",
            "Answer: yes\n",
            "---\n",
            "Input: Method 1: We look at how manager correlates with foot size case by case according to director. Method 2: We look directly at how manager correlates with foot size in general. To understand how manager affects foot size, is it more correct to use the Method 1 than Method 2?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For people who do not speak english, the probability of the forest on fire is 83%. For people who speak english, the probability of the forest on fire is 48%. Will speaking english increase the chance of the forest on fire?\n",
            "Answer: no\n",
            "---\n",
            "Input: The overall probability of yupt is 38%. For those who are not yupt, the probability of muvq is 7%. For those who are yupt, the probability of muvq is 23%. Is muvq less likely than not muvq overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: The overall probability of college degree or higher is 60%. For people without a college degree, the probability of black hair is 26%. For people with a college degree or higher, the probability of black hair is 40%. Is black hair less likely than blond hair overall?\n",
            "Answer: yes\n",
            "---\n",
            "Input: For those who are not jyka, the probability of kwox is 46%. For those who are jyka, the probability of kwox is 61%. For those who are jyka, would it be more likely to see kwox if the individual was not jyka?\n",
            "Answer: no\n",
            "---\n",
            "Input: For people not taking any medication and with low blood pressure, the probability of healthy heart is 51%. For people not taking any medication and with high blood pressure, the probability of healthy heart is 23%. For people taking medication and with low blood pressure, the probability of healthy heart is 81%. For people taking medication and with high blood pressure, the probability of healthy heart is 47%. For people not taking any medication, the probability of high blood pressure is 46%. For people taking medication, the probability of high blood pressure is 59%. Does medication positively affect heart condition through blood pressure?\n",
            "Answer: no\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the main code where the model is going through the sampled dataset predicting ans and we are comparing the models answer with the resulting answers\n",
        "\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "import torch\n",
        "from sklearn.metrics import f1_score\n",
        "import nltk\n",
        "import math\n",
        "import json\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Load the pre-trained GPT-Neo model and tokenizer\n",
        "model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
        "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.half()\n",
        "model.eval()\n",
        "\n",
        "# Function to calculate Perplexity\n",
        "def calculate_perplexity(model, tokenizer, input_text):\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs.input_ids)\n",
        "    loss = outputs.loss\n",
        "    perplexity = torch.exp(loss).item()\n",
        "    return perplexity\n",
        "\n",
        "# Function to calculate BLEU score\n",
        "def calculate_bleu(reference, prediction):\n",
        "    reference_tokens = nltk.word_tokenize(reference.lower())\n",
        "    prediction_tokens = nltk.word_tokenize(prediction.lower())\n",
        "    return sentence_bleu([reference_tokens], prediction_tokens)\n",
        "\n",
        "# Function to calculate F1 score\n",
        "def calculate_f1(reference, prediction):\n",
        "    ref_label = 1 if reference.lower() == 'yes' else 0\n",
        "    pred_label = 1 if prediction.lower() == 'yes' else 0\n",
        "    return f1_score([ref_label], [pred_label], average='binary')\n",
        "\n",
        "# Function to preprocess a single sample and evaluate all metrics\n",
        "def evaluate_sample(sample):\n",
        "    input_text = f\"Given Info and Question: {sample['input']}\\nAnswer:\"\n",
        "    groundtruth_answer = sample['answer'].strip().lower()\n",
        "\n",
        "    # Generate answer from GPT-Neo\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(inputs.input_ids, max_new_tokens=50)\n",
        "    predicted_answer = tokenizer.decode(outputs[0], skip_special_tokens=True).strip().split(\"\\n\")[-1].lower()  # Better extraction\n",
        "\n",
        "    # Calculate metrics\n",
        "    perplexity = calculate_perplexity(model, tokenizer, input_text)\n",
        "    bleu_score = calculate_bleu(groundtruth_answer, predicted_answer)\n",
        "    f1 = calculate_f1(groundtruth_answer, predicted_answer)\n",
        "\n",
        "    return perplexity, bleu_score, f1\n",
        "\n",
        "\n",
        "def evaluate_cladder_dataset(dataset):\n",
        "    perplexity_scores = []\n",
        "    bleu_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for i, sample in enumerate(tqdm(dataset)):  # Use tqdm to wrap the dataset for a progress bar\n",
        "        perplexity, bleu, f1 = evaluate_sample(sample)\n",
        "        perplexity_scores.append(perplexity)\n",
        "        bleu_scores.append(bleu)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        # Display average scores every 10 iterations\n",
        "        if (i + 1) % 10 == 0:\n",
        "            avg_perplexity = sum(perplexity_scores) / len(perplexity_scores)\n",
        "            avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "            avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "            print(f\"Iteration {i + 1}: Avg Perplexity: {avg_perplexity:.2f}, Avg BLEU: {avg_bleu:.2f}, Avg F1: {avg_f1:.2f}\")\n",
        "\n",
        "    # Calculate average scores for the entire dataset\n",
        "    avg_perplexity = sum(perplexity_scores) / len(perplexity_scores)\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    return avg_perplexity, avg_bleu, avg_f1\n",
        "\n",
        "\n",
        "# Load the dataset from the JSON file\n",
        "with open('/content/drive/MyDrive/ASU/SEM-3/PRL/Project/sampled_dataset.json', 'r') as f:\n",
        "    cladder_dataset = json.load(f)\n",
        "\n",
        "\n",
        "# Run evaluation\n",
        "avg_perplexity, avg_bleu, avg_f1 = evaluate_cladder_dataset(cladder_dataset)\n",
        "\n",
        "print(f\"Average Perplexity: {avg_perplexity}\")\n",
        "print(f\"Average BLEU Score: {avg_bleu}\")\n",
        "print(f\"Average F1 Score: {avg_f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "citY7-6magaz",
        "outputId": "b495488b-3790-4da4-8c6d-f1e1337c85e8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-92fbcf53a925>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This is the main code where the model is going through the sampled dataset predicting ans and we are comparing the models answer with the resulting answers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPTNeoForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0;31m from .generic import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mContextManagers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_torch_pytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_model_output_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_pytree.Context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "import torch\n",
        "from sklearn.metrics import f1_score\n",
        "import nltk\n",
        "import math\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Load the pre-trained GPT-Neo model and tokenizer\n",
        "model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
        "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.half()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941,
          "referenced_widgets": [
            "db012bfe818b4edabbd24b266baef7a8",
            "256c605f4f9640bbb2a576a9803f4ff3",
            "eaa7c5800fa648b2a8085d1273cc73e7",
            "1d650f1917334662b7f49003b2daabf4",
            "9a49e90f9e2641a0b51584f803bd39d7",
            "edcb763e77f349dda160eb819bb85ba7",
            "ad3dcbb70b7144cbb35a8457491a3352",
            "ea587046dfd5476aa093d6df0ae9753c",
            "def3fb945dff43bab1ec3eb8c81424ad",
            "e8482dae6d944633b23595864343d3ba",
            "bc9b0cfca5e24e85a12831de71205609",
            "6fc7e709ccc14b179461d2b37c1bcc4a",
            "9af5e9c6b2f8439ca7316f831bd1627e",
            "bc9bd06c95e14d0ba85b22f644a761ea",
            "31b67c66e15b44fda4ddc79ecec28792",
            "e42d4a3ea62a4e378470993a7b8a56cb",
            "6a4798ed22744c65ac4087b4999d6634",
            "ee6997e72b3b40deb0ccebaa41413e78",
            "0081d8442f77471b801644096c6d7ef1",
            "5991da72224d4f78812a62085082d9df",
            "a5be9123210f479681d71dadca07ddc6",
            "b5399ec570e2420ea2b84d8ec31ad96d",
            "be19edfe9118476f88a8c737ade64c19",
            "8a7772f842f045f3932663e2621b3648",
            "7bd6b1b2d4b948da9206b4b07fde89a5",
            "c981c4a27e8245ecaa47dd4e768cd1e2",
            "84ca1d444d24472093880f762bb920c9",
            "ca683dae34004b4b8f95f2acb4dcf57d",
            "3122ca4930d349aeb35015996dbc71ce",
            "b527eeba050e49b2be09530aee444d52",
            "e563c0ba2ac547ddb7b8951845de6e0b",
            "324e4185440a4bd08b4339e637a60930",
            "0bd65a3ce84d4244a78277c55a9d2d86",
            "f62864ded19b40688fd3de7a6ff4a2d5",
            "ec4af6871a6a4db4b004c3bae28a2077",
            "4d402069621445a08df07134b3adaea3",
            "98504b1208934b2596820e5b449feb63",
            "5014d273955044dbaf736ccb696919f1",
            "11e852da58d640aebd9f292f8864c8df",
            "c641a70f07d046f5ac88acea76ad4a2b",
            "4c1ce06065774f658b5101f41795da53",
            "ecb1cac4df3746e0a72a9864bf7e3d55",
            "04cc32ecf998470aa4ee8e89756c5599",
            "5d00826be75e409bb9cca834c772c05f",
            "8e59e9c40d814f1b9bbf88fd363924a3",
            "de3647ac64304a098c2a55e006f20065",
            "e641a3cf9c314bb8874de9e9dab45616",
            "819c0b8ff5ca41a79c6cc839cb34f91e",
            "ea5cfca477ca49a1993415a9a8c0876c",
            "e797eb02167e4930af126b2546c79636",
            "e46a367397c946bb8508953c1e0880bc",
            "546f5a74827d4369ba8f2fe3ecbd6bd2",
            "7653655e0f114035b3a7de73a83f2a92",
            "c1d5563cb76d46abbf4a947b43b067ff",
            "55ad0b13f0124b5a85ecf8543c7b6fd4",
            "d0294cc1065540fdbb9d6b8272588eb1",
            "63bc5e3c7146421da90411d1d5066498",
            "3d14c10d189f4e70992ae680f150c5f0",
            "47546720f2bf4be28c79658304f5ab03",
            "e4dc78c989ce4025973a37acbfe308a7",
            "3ef8388cc2ee4c09b8acbfa568221b5f",
            "b33baeed15334356a9cfcc0a306b1bff",
            "2a500375c8ad44349a93cffdb5335cc5",
            "77e54c917ce34000a3221ff78d060fcd",
            "ccff3406115e4f7da74d9b9d76964fb2",
            "9cba8ea3afb440aa97ebbf509661d56a"
          ]
        },
        "id": "kjzNB_gG7AG1",
        "outputId": "cf6d88a7-e2ee-4d04-934f-0fe5ac89c977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db012bfe818b4edabbd24b266baef7a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/10.7G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fc7e709ccc14b179461d2b37c1bcc4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be19edfe9118476f88a8c737ade64c19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f62864ded19b40688fd3de7a6ff4a2d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e59e9c40d814f1b9bbf88fd363924a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0294cc1065540fdbb9d6b8272588eb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoForCausalLM(\n",
              "  (transformer): GPTNeoModel(\n",
              "    (wte): Embedding(50257, 2560)\n",
              "    (wpe): Embedding(2048, 2560)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-31): 32 x GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
              "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
              "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
              "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
              "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2560, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to calculate Perplexity\n",
        "def calculate_perplexity(model, tokenizer, input_text):\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs.input_ids)\n",
        "    loss = outputs.loss\n",
        "    perplexity = torch.exp(loss).item()\n",
        "    return perplexity\n",
        "\n",
        "# Function to calculate BLEU score\n",
        "def calculate_bleu(reference, prediction):\n",
        "    reference_tokens = nltk.word_tokenize(reference.lower())\n",
        "    prediction_tokens = nltk.word_tokenize(prediction.lower())\n",
        "    return sentence_bleu([reference_tokens], prediction_tokens)\n",
        "\n",
        "# Function to calculate F1 score\n",
        "def calculate_f1(reference, prediction):\n",
        "    ref_label = 1 if reference.lower() == 'yes' else 0\n",
        "    pred_label = 1 if prediction.lower() == 'yes' else 0\n",
        "    return f1_score([ref_label], [pred_label], average='binary')\n",
        "\n",
        "# Function to calculate Expected Calibration Error (ECE)\n",
        "def calculate_ece(pred_probs, true_labels, num_bins=10):\n",
        "    bin_boundaries = torch.linspace(0, 1, num_bins + 1)\n",
        "    ece = 0.0\n",
        "    for i in range(num_bins):\n",
        "        in_bin = (pred_probs > bin_boundaries[i]) & (pred_probs <= bin_boundaries[i + 1])\n",
        "        if in_bin.float().sum() > 0:\n",
        "            accuracy_in_bin = true_labels[in_bin].float().mean()\n",
        "            avg_confidence_in_bin = pred_probs[in_bin].mean()\n",
        "            ece += (avg_confidence_in_bin - accuracy_in_bin).abs() * in_bin.float().mean()\n",
        "    return ece.item()\n",
        "\n",
        "# Function to calculate Brier Score\n",
        "def calculate_brier_score(pred_probs, true_labels):\n",
        "    return ((pred_probs - true_labels.float()) ** 2).mean().item()\n",
        "\n",
        "# Function to preprocess a single sample and evaluate all metrics\n",
        "def evaluate_sample(sample):\n",
        "    input_text = f\"Given Info and Question: {sample['input']}\\nAnswer:\"\n",
        "    groundtruth_answer = sample['answer'].strip().lower()\n",
        "\n",
        "    # Generate answer from GPT-Neo\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(inputs.input_ids, max_new_tokens=50, return_dict_in_generate=True, output_scores=True)\n",
        "    predicted_answer = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True).strip().split(\"\\n\")[-1].lower()\n",
        "\n",
        "    # Calculate confidence for \"yes\" and \"no\" answers\n",
        "    last_token_logits = outputs.scores[-1].softmax(dim=-1)\n",
        "    yes_score = last_token_logits[0, tokenizer.convert_tokens_to_ids(\"yes\")].item()\n",
        "    no_score = last_token_logits[0, tokenizer.convert_tokens_to_ids(\"no\")].item()\n",
        "    pred_probs = torch.tensor([yes_score, no_score]) / (yes_score + no_score)\n",
        "\n",
        "    # Set true label based on groundtruth answer\n",
        "    true_label = torch.tensor([1, 0]) if groundtruth_answer == \"yes\" else torch.tensor([0, 1])\n",
        "\n",
        "    # Calculate metrics\n",
        "    perplexity = calculate_perplexity(model, tokenizer, input_text)\n",
        "    ece = calculate_ece(pred_probs, true_label)\n",
        "    brier_score = calculate_brier_score(pred_probs, true_label[0])  # Brier score expects single label\n",
        "    bleu_score = calculate_bleu(groundtruth_answer, predicted_answer)\n",
        "    f1 = calculate_f1(groundtruth_answer, predicted_answer)\n",
        "\n",
        "    return perplexity, ece, brier_score, bleu_score, f1\n",
        "\n",
        "# Function to evaluate the entire dataset\n",
        "def evaluate_cladder_dataset(dataset):\n",
        "    perplexity_scores = []\n",
        "    ece_scores = []\n",
        "    brier_scores = []\n",
        "    bleu_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for i, sample in enumerate(tqdm(dataset)):\n",
        "        perplexity, ece, brier, bleu, f1 = evaluate_sample(sample)\n",
        "        perplexity_scores.append(perplexity)\n",
        "        ece_scores.append(ece)\n",
        "        brier_scores.append(brier)\n",
        "        bleu_scores.append(bleu)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f\"Iteration {i + 1}: Avg Perplexity: {np.mean(perplexity_scores):.2f}, \"\n",
        "                  f\"Avg ECE: {np.mean(ece_scores):.2f}, Avg Brier: {np.mean(brier_scores):.2f}, \"\n",
        "                  f\"Avg BLEU: {np.mean(bleu_scores):.2f}, Avg F1: {np.mean(f1_scores):.2f}\")\n",
        "\n",
        "    return {\n",
        "        \"avg_perplexity\": np.mean(perplexity_scores),\n",
        "        \"avg_ece\": np.mean(ece_scores),\n",
        "        \"avg_brier\": np.mean(brier_scores),\n",
        "        \"avg_bleu\": np.mean(bleu_scores),\n",
        "        \"avg_f1\": np.mean(f1_scores),\n",
        "    }\n",
        "\n",
        "# Load the dataset and run evaluation\n",
        "with open('/content/drive/MyDrive/ASU/SEM-3/PRL/Project/sampled_dataset.json', 'r') as f:\n",
        "    cladder_dataset = json.load(f)\n",
        "\n",
        "# Run evaluation\n",
        "results = evaluate_cladder_dataset(cladder_dataset)\n",
        "print(\"Evaluation Results:\", results)\n"
      ],
      "metadata": {
        "id": "1zSrb_ud8EBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from sklearn.metrics import f1_score\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_perplexity(model, tokenizer, input_text, device):\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs.input_ids)\n",
        "    loss = outputs.loss\n",
        "    perplexity = torch.exp(loss).item()\n",
        "    return perplexity\n",
        "\n",
        "def calculate_bleu(reference, prediction):\n",
        "    try:\n",
        "        # Download required NLTK data if not already present\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt')\n",
        "        except LookupError:\n",
        "            nltk.download('punkt')\n",
        "\n",
        "        # Handle empty strings or None values\n",
        "        if not reference or not prediction:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = nltk.word_tokenize(str(reference).lower())\n",
        "        prediction_tokens = nltk.word_tokenize(str(prediction).lower())\n",
        "\n",
        "        # BLEU score requires non-empty sequences\n",
        "        if not reference_tokens or not prediction_tokens:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], prediction_tokens, weights=(1, 0, 0, 0))\n",
        "    except Exception as e:\n",
        "        print(f\"BLEU calculation error: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_f1(reference, prediction):\n",
        "    try:\n",
        "        # Convert to string and lowercase\n",
        "        reference = str(reference).lower().strip()\n",
        "        prediction = str(prediction).lower().strip()\n",
        "\n",
        "        # Convert yes/no answers to binary labels\n",
        "        ref_label = 1 if reference == 'yes' else 0\n",
        "        pred_label = 1 if prediction == 'yes' else 0\n",
        "\n",
        "        return f1_score([ref_label], [pred_label], average='binary')\n",
        "    except Exception as e:\n",
        "        print(f\"F1 calculation error: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_ece(pred_probs, true_labels, num_bins=10):\n",
        "    try:\n",
        "        # Ensure inputs are on CPU and the correct shape\n",
        "        pred_probs = pred_probs.cpu()\n",
        "        true_labels = true_labels.cpu()\n",
        "\n",
        "        bin_boundaries = torch.linspace(0, 1, num_bins + 1)\n",
        "        ece = 0.0\n",
        "\n",
        "        for i in range(num_bins):\n",
        "            in_bin = (pred_probs >= bin_boundaries[i]) & (pred_probs < bin_boundaries[i + 1])\n",
        "            if torch.any(in_bin):\n",
        "                accuracy_in_bin = true_labels[in_bin].float().mean()\n",
        "                avg_confidence_in_bin = pred_probs[in_bin].mean()\n",
        "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * (in_bin.float().sum() / len(pred_probs))\n",
        "\n",
        "        return ece.item()\n",
        "    except Exception as e:\n",
        "        print(f\"ECE calculation error: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_brier_score(pred_probs, true_labels):\n",
        "    try:\n",
        "        # Ensure inputs are on CPU\n",
        "        pred_probs = pred_probs.cpu()\n",
        "        true_labels = true_labels.cpu().float()\n",
        "\n",
        "        return ((pred_probs - true_labels) ** 2).mean().item()\n",
        "    except Exception as e:\n",
        "        print(f\"Brier score calculation error: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def evaluate_sample(model, tokenizer, sample, device):\n",
        "    try:\n",
        "        input_text = f\"Given Info and Question: {sample['input']}\\nAnswer:\"\n",
        "        groundtruth_answer = str(sample['answer']).strip().lower()\n",
        "\n",
        "        # Generate answer\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs.input_ids,\n",
        "                max_new_tokens=50,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Extract predicted answer\n",
        "        predicted_tokens = outputs.sequences[0][inputs.input_ids.shape[1]:]\n",
        "        predicted_answer = tokenizer.decode(predicted_tokens, skip_special_tokens=True).strip().lower()\n",
        "\n",
        "        # Calculate confidence scores\n",
        "        last_token_logits = outputs.scores[-1][0]  # Take first batch\n",
        "        yes_token_id = tokenizer.encode(\" yes\", add_special_tokens=False)[0]\n",
        "        no_token_id = tokenizer.encode(\" no\", add_special_tokens=False)[0]\n",
        "\n",
        "        logits = torch.zeros(2)  # [yes, no]\n",
        "        logits[0] = last_token_logits[yes_token_id]\n",
        "        logits[1] = last_token_logits[no_token_id]\n",
        "        pred_probs = torch.softmax(logits, dim=0)\n",
        "\n",
        "        # Calculate true label\n",
        "        true_label = torch.tensor([1.0, 0.0] if groundtruth_answer == \"yes\" else [0.0, 1.0])\n",
        "\n",
        "        # Calculate all metrics\n",
        "        metrics = {\n",
        "            \"perplexity\": calculate_perplexity(model, tokenizer, input_text, device),\n",
        "            \"ece\": calculate_ece(pred_probs, true_label),\n",
        "            \"brier_score\": calculate_brier_score(pred_probs[0], true_label[0]),  # Use yes probability\n",
        "            \"bleu_score\": calculate_bleu(groundtruth_answer, predicted_answer),\n",
        "            \"f1_score\": calculate_f1(groundtruth_answer, predicted_answer)\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Sample evaluation error: {e}\")\n",
        "        return {\n",
        "            \"perplexity\": 0.0,\n",
        "            \"ece\": 0.0,\n",
        "            \"brier_score\": 0.0,\n",
        "            \"bleu_score\": 0.0,\n",
        "            \"f1_score\": 0.0\n",
        "        }\n",
        "\n",
        "def evaluate_dataset(model, tokenizer, dataset, device):\n",
        "    all_metrics = {\n",
        "        \"perplexity\": [],\n",
        "        \"ece\": [],\n",
        "        \"brier_score\": [],\n",
        "        \"bleu_score\": [],\n",
        "        \"f1_score\": []\n",
        "    }\n",
        "\n",
        "    for i, sample in enumerate(tqdm(dataset)):\n",
        "        sample_metrics = evaluate_sample(model, tokenizer, sample, device)\n",
        "\n",
        "        for metric_name, value in sample_metrics.items():\n",
        "            all_metrics[metric_name].append(value)\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f\"\\nIteration {i + 1}:\")\n",
        "            for metric_name, values in all_metrics.items():\n",
        "                print(f\"Avg {metric_name}: {np.mean(values):.4f}\")\n",
        "\n",
        "    # Calculate final averages\n",
        "    return {\n",
        "        metric_name: float(np.mean(values))\n",
        "        for metric_name, values in all_metrics.items()\n",
        "    }\n",
        "\n",
        "# Load the dataset and run evaluation\n",
        "with open('/content/drive/MyDrive/ASU/SEM-3/PRL/Project/sampled_dataset.json', 'r') as f:\n",
        "    cladder_dataset = json.load(f)\n",
        "\n",
        "# Example usage:\n",
        "results = evaluate_dataset(model, tokenizer, cladder_dataset, device)\n",
        "print(\"\\nFinal Results:\")\n",
        "for metric_name, value in results.items():\n",
        "  print(f\"{metric_name}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7Wr2vrA7iFg",
        "outputId": "520491ad-7716-4e3d-edd6-8d902416b61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "  2%|▏         | 2/100 [00:09<07:03,  4.32s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "  4%|▍         | 4/100 [00:13<04:15,  2.66s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "  5%|▌         | 5/100 [00:14<03:42,  2.35s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "  7%|▋         | 7/100 [00:18<03:19,  2.14s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "  8%|▊         | 8/100 [00:20<03:17,  2.14s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "  9%|▉         | 9/100 [00:22<03:05,  2.04s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 10%|█         | 10/100 [00:24<02:56,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 10:\n",
            "Avg perplexity: 23.0262\n",
            "Avg ece: 0.3662\n",
            "Avg brier_score: 0.3053\n",
            "Avg bleu_score: 0.0000\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 13/100 [00:29<02:41,  1.86s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 16%|█▌        | 16/100 [00:35<02:42,  1.93s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 17%|█▋        | 17/100 [00:37<02:37,  1.89s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 18%|█▊        | 18/100 [00:39<02:32,  1.86s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 20%|██        | 20/100 [00:43<02:26,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 20:\n",
            "Avg perplexity: 25.1117\n",
            "Avg ece: 0.4684\n",
            "Avg brier_score: 0.3730\n",
            "Avg bleu_score: 0.0000\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 24/100 [00:51<02:23,  1.89s/it]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 25%|██▌       | 25/100 [00:52<02:20,  1.87s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 27%|██▋       | 27/100 [00:56<02:13,  1.83s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 29%|██▉       | 29/100 [01:00<02:25,  2.05s/it]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 30%|███       | 30/100 [01:02<02:19,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 30:\n",
            "Avg perplexity: 28.6329\n",
            "Avg ece: 0.5186\n",
            "Avg brier_score: 0.3885\n",
            "Avg bleu_score: 0.0017\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 31/100 [01:04<02:15,  1.96s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 32%|███▏      | 32/100 [01:06<02:11,  1.94s/it]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            " 34%|███▍      | 34/100 [01:10<02:03,  1.87s/it]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            " 37%|███▋      | 37/100 [01:16<02:04,  1.98s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 38%|███▊      | 38/100 [01:18<01:59,  1.93s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 39%|███▉      | 39/100 [01:19<01:55,  1.89s/it]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 40%|████      | 40/100 [01:21<01:51,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 40:\n",
            "Avg perplexity: 26.9104\n",
            "Avg ece: 0.5406\n",
            "Avg brier_score: 0.4153\n",
            "Avg bleu_score: 0.0030\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 41/100 [01:23<01:49,  1.85s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 43%|████▎     | 43/100 [01:27<01:51,  1.96s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 47%|████▋     | 47/100 [01:35<01:40,  1.89s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 48%|████▊     | 48/100 [01:36<01:37,  1.87s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 49%|████▉     | 49/100 [01:38<01:35,  1.87s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 50%|█████     | 50/100 [01:40<01:38,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 50:\n",
            "Avg perplexity: 24.2920\n",
            "Avg ece: 0.5231\n",
            "Avg brier_score: 0.4079\n",
            "Avg bleu_score: 0.0024\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 51/100 [01:43<01:38,  2.01s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 52%|█████▏    | 52/100 [01:44<01:33,  1.95s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 53%|█████▎    | 53/100 [01:46<01:31,  1.94s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 56%|█████▌    | 56/100 [01:52<01:22,  1.88s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 57%|█████▋    | 57/100 [01:55<01:38,  2.28s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 58%|█████▊    | 58/100 [01:57<01:31,  2.17s/it]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            " 59%|█████▉    | 59/100 [01:59<01:24,  2.06s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 60%|██████    | 60/100 [02:01<01:19,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 60:\n",
            "Avg perplexity: 23.4650\n",
            "Avg ece: 0.4839\n",
            "Avg brier_score: 0.3730\n",
            "Avg bleu_score: 0.0024\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 62%|██████▏   | 62/100 [02:04<01:14,  1.95s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 65%|██████▌   | 65/100 [02:11<01:10,  2.02s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 67%|██████▋   | 67/100 [02:14<01:03,  1.92s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 70%|███████   | 70/100 [02:20<00:56,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 70:\n",
            "Avg perplexity: 22.2386\n",
            "Avg ece: 0.4997\n",
            "Avg brier_score: 0.3876\n",
            "Avg bleu_score: 0.0020\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 71%|███████   | 71/100 [02:22<00:57,  1.97s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 73%|███████▎  | 73/100 [02:26<00:54,  2.00s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 74%|███████▍  | 74/100 [02:28<00:53,  2.05s/it]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            " 75%|███████▌  | 75/100 [02:30<00:49,  1.97s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 80%|████████  | 80/100 [02:40<00:38,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 80:\n",
            "Avg perplexity: 22.2860\n",
            "Avg ece: 0.5025\n",
            "Avg brier_score: 0.3863\n",
            "Avg bleu_score: 0.0022\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 82%|████████▏ | 82/100 [02:44<00:36,  2.00s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 84%|████████▍ | 84/100 [02:47<00:31,  1.94s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 90%|█████████ | 90/100 [02:59<00:18,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 90:\n",
            "Avg perplexity: 22.1331\n",
            "Avg ece: 0.5007\n",
            "Avg brier_score: 0.3828\n",
            "Avg bleu_score: 0.0019\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 92%|█████████▏| 92/100 [03:03<00:15,  1.94s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 96%|█████████▌| 96/100 [03:10<00:07,  1.84s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            " 97%|█████████▋| 97/100 [03:12<00:05,  1.83s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "100%|██████████| 100/100 [03:18<00:00,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 100:\n",
            "Avg perplexity: 22.3496\n",
            "Avg ece: 0.5056\n",
            "Avg brier_score: 0.3878\n",
            "Avg bleu_score: 0.0017\n",
            "Avg f1_score: 0.0000\n",
            "\n",
            "Final Results:\n",
            "perplexity: 22.3496\n",
            "ece: 0.5056\n",
            "brier_score: 0.3878\n",
            "bleu_score: 0.0017\n",
            "f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from sklearn.metrics import f1_score\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_perplexity(model, tokenizer, input_text, device):\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs.input_ids)\n",
        "    loss = outputs.loss\n",
        "    perplexity = torch.exp(loss).item()\n",
        "    return perplexity\n",
        "\n",
        "def calculate_bleu(reference, prediction):\n",
        "    try:\n",
        "        # Download required NLTK data if not already present\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt')\n",
        "        except LookupError:\n",
        "            nltk.download('punkt')\n",
        "\n",
        "        # Handle empty strings or None values\n",
        "        if not reference or not prediction:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = nltk.word_tokenize(str(reference).lower())\n",
        "        prediction_tokens = nltk.word_tokenize(str(prediction).lower())\n",
        "\n",
        "        # BLEU score requires non-empty sequences\n",
        "        if not reference_tokens or not prediction_tokens:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], prediction_tokens, weights=(1, 0, 0, 0))\n",
        "    except Exception as e:\n",
        "        print(f\"BLEU calculation error: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_f1(reference, prediction):\n",
        "    try:\n",
        "        # Convert to string and lowercase\n",
        "        reference = str(reference).lower().strip()\n",
        "        prediction = str(prediction).lower().strip()\n",
        "\n",
        "        # Convert yes/no answers to binary labels\n",
        "        ref_label = 1 if reference == 'yes' else 0\n",
        "        pred_label = 1 if prediction == 'yes' else 0\n",
        "\n",
        "        return f1_score([ref_label], [pred_label], average='binary')\n",
        "    except Exception as e:\n",
        "        print(f\"F1 calculation error: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_bleu(reference, prediction):\n",
        "    try:\n",
        "        # Ensure we have valid strings\n",
        "        reference = str(reference).strip().lower()\n",
        "        prediction = str(prediction).strip().lower()\n",
        "\n",
        "        # For yes/no answers, treat them as single tokens\n",
        "        if reference in ['yes', 'no'] and prediction in ['yes', 'no']:\n",
        "            return 1.0 if reference == prediction else 0.0\n",
        "\n",
        "        # For longer answers, use standard BLEU calculation\n",
        "        reference_tokens = nltk.word_tokenize(reference)\n",
        "        prediction_tokens = nltk.word_tokenize(prediction)\n",
        "\n",
        "        # Use smoother BLEU calculation for short sequences\n",
        "        from nltk.translate.bleu_score import SmoothingFunction\n",
        "        smoother = SmoothingFunction()\n",
        "\n",
        "        return sentence_bleu(\n",
        "            [reference_tokens],\n",
        "            prediction_tokens,\n",
        "            smoothing_function=smoother.method1,\n",
        "            weights=(0.25, 0.25, 0.25, 0.25)  # Use standard BLEU-4\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"BLEU calculation error: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def calculate_brier_score(pred_probs, true_labels):\n",
        "    try:\n",
        "        # Convert inputs to tensors if they aren't already\n",
        "        if not isinstance(pred_probs, torch.Tensor):\n",
        "            pred_probs = torch.tensor(pred_probs)\n",
        "        if not isinstance(true_labels, torch.Tensor):\n",
        "            true_labels = torch.tensor(true_labels)\n",
        "\n",
        "        # Ensure we're working with CPU tensors\n",
        "        pred_probs = pred_probs.cpu().float()\n",
        "        true_labels = true_labels.cpu().float()\n",
        "\n",
        "        return float(((pred_probs - true_labels) ** 2).mean())\n",
        "    except Exception as e:\n",
        "        print(f\"Brier score calculation error: {str(e)}\")\n",
        "        print(f\"pred_probs type: {type(pred_probs)}, value: {pred_probs}\")\n",
        "        print(f\"true_labels type: {type(true_labels)}, value: {true_labels}\")\n",
        "        return 0.0\n",
        "\n",
        "def evaluate_sample(model, tokenizer, sample, device):\n",
        "    try:\n",
        "        input_text = f\"Given Info and Question: {sample['input']}\\nAnswer:\"\n",
        "        groundtruth_answer = str(sample['answer']).strip().lower()\n",
        "\n",
        "        # Generate answer\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs.input_ids,\n",
        "                max_new_tokens=50,\n",
        "                num_beams=3,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        predicted_tokens = outputs.sequences[0][inputs.input_ids.shape[1]:]\n",
        "        predicted_answer = tokenizer.decode(predicted_tokens, skip_special_tokens=True).strip().lower()\n",
        "\n",
        "        # More robust probability calculation\n",
        "        try:\n",
        "            last_token_logits = outputs.scores[-1][0].float()  # Convert to float32\n",
        "\n",
        "            # Get token IDs for yes/no\n",
        "            yes_token_ids = tokenizer.encode(\" yes\", add_special_tokens=False)\n",
        "            no_token_ids = tokenizer.encode(\" no\", add_special_tokens=False)\n",
        "\n",
        "            # Handle case where tokens aren't found\n",
        "            if not yes_token_ids or not no_token_ids:\n",
        "                yes_token_ids = tokenizer.encode(\"yes\", add_special_tokens=False)\n",
        "                no_token_ids = tokenizer.encode(\"no\", add_special_tokens=False)\n",
        "\n",
        "            # Get logits for yes/no\n",
        "            yes_logits = last_token_logits[yes_token_ids].mean()\n",
        "            no_logits = last_token_logits[no_token_ids].mean()\n",
        "\n",
        "            # Apply stable softmax\n",
        "            logits = torch.tensor([yes_logits, no_logits], device=device)\n",
        "            logits = logits - logits.max()  # For numerical stability\n",
        "            exp_logits = torch.exp(logits)\n",
        "            pred_probs = exp_logits / exp_logits.sum()\n",
        "\n",
        "            # Check for NaN and replace with uniform distribution if needed\n",
        "            if torch.isnan(pred_probs).any():\n",
        "                pred_probs = torch.tensor([0.5, 0.5], device=device)\n",
        "                print(\"Warning: NaN detected in probabilities, using uniform distribution\")\n",
        "\n",
        "            # Ensure probabilities sum to 1\n",
        "            pred_probs = pred_probs.clamp(min=1e-7, max=1-1e-7)\n",
        "            pred_probs = pred_probs / pred_probs.sum()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Probability calculation error: {str(e)}\")\n",
        "            pred_probs = torch.tensor([0.5, 0.5], device=device)\n",
        "\n",
        "        # Ensure true label is on same device\n",
        "        true_label = torch.tensor([1.0, 0.0] if groundtruth_answer == \"yes\" else [0.0, 1.0], device=device)\n",
        "\n",
        "        # Add debugging prints\n",
        "        print(f\"\\nDetailed evaluation:\")\n",
        "        print(f\"Input: {sample['input']}\")\n",
        "        print(f\"Predicted answer: {predicted_answer}\")\n",
        "        print(f\"Ground truth: {groundtruth_answer}\")\n",
        "        print(f\"Prediction probabilities: {pred_probs}\")\n",
        "        print(f\"True label: {true_label}\")\n",
        "\n",
        "        # Calculate metrics with safeguards\n",
        "        metrics = {\n",
        "            \"perplexity\": calculate_perplexity(model, tokenizer, input_text, device),\n",
        "            \"ece\": calculate_ece(pred_probs.cpu(), true_label.cpu()),\n",
        "            \"brier_score\": calculate_brier_score(pred_probs[0].cpu(), true_label[0].cpu()),\n",
        "            \"bleu_score\": calculate_bleu(groundtruth_answer, predicted_answer),\n",
        "            \"f1_score\": calculate_f1(groundtruth_answer, predicted_answer)\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Sample evaluation error: {str(e)}\")\n",
        "        print(f\"Input text: {input_text}\")\n",
        "        return {\n",
        "            \"perplexity\": float('inf'),\n",
        "            \"ece\": 1.0,\n",
        "            \"brier_score\": 1.0,\n",
        "            \"bleu_score\": 0.0,\n",
        "            \"f1_score\": 0.0\n",
        "        }\n",
        "\n",
        "def calculate_ece(pred_probs, true_labels, num_bins=15):\n",
        "    try:\n",
        "        # Handle NaN values\n",
        "        if torch.isnan(pred_probs).any():\n",
        "            print(\"Warning: NaN values in pred_probs for ECE calculation\")\n",
        "            pred_probs = torch.tensor([0.5, 0.5])\n",
        "\n",
        "        pred_probs = pred_probs.float()\n",
        "        true_labels = true_labels.float()\n",
        "\n",
        "        bin_boundaries = torch.linspace(0, 1, num_bins + 1)\n",
        "        ece = 0.0\n",
        "\n",
        "        for i in range(num_bins):\n",
        "            mask = (pred_probs >= bin_boundaries[i]) & (pred_probs < bin_boundaries[i + 1])\n",
        "            if mask.any():\n",
        "                bin_conf = pred_probs[mask].mean()\n",
        "                bin_acc = true_labels[mask].mean()\n",
        "                bin_size = mask.float().mean()\n",
        "                ece += torch.abs(bin_conf - bin_acc) * bin_size\n",
        "\n",
        "        return float(ece)\n",
        "    except Exception as e:\n",
        "        print(f\"ECE calculation error: {str(e)}\")\n",
        "        return 1.0  # Return worst possible ECE score on error\n",
        "\n",
        "# Example usage:\n",
        "results = evaluate_dataset(model, tokenizer, cladder_dataset, device)\n",
        "print(\"\\nFinal Results:\")\n",
        "for metric_name, value in results.items():\n",
        "  print(f\"{metric_name}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj7qEFot9dG_",
        "outputId": "a20e844c-4e4c-4798-929d-0c509813401c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "  1%|          | 1/100 [00:02<04:55,  2.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that male gender or in-state residency causes competitive department. male gender or in-state residency or competitive department causes admission acceptance. We observed the resident is in-state. Would the applicant gets rejected if male gender instead of non-male gender?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: what is the best way to find out if a student is male or female? answer: you can check the student’s birth certificate. if it is a male, then he or she is female.\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:06<05:35,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of talent is 82%. For students who are not talented and rejected from elite institutions, the probability of being hard-working is 99%. For students who are not talented and accepted to elite institutions, the probability of being hard-working is 82%. For students who are talented and rejected from elite institutions, the probability of being hard-working is 96%. For students who are talented and accepted to elite institutions, the probability of being hard-working is 53%. If we look at students accepted to elite institutions, does the chance of being hard-working decrease when talent?\n",
            "Predicted answer: yes.\n",
            "question: what is the difference between talent and hard work? what does it mean to be hard working? why is it important to work hard? how do you know if you are working hard or not?\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r  3%|▎         | 3/100 [00:09<04:42,  2.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of pexu is 83%. For those who are not pexu, the probability of rukz is 81%. For those who are pexu, the probability of rukz is 81%. Is rukz less likely than not rukz overall?\n",
            "Predicted answer: no.\n",
            "question: what is the chance that a person who is not a member of a particular group will be in that group in the next year? the probability is 80%. the person is a non-member of the group. the group is\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:11<04:18,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not tijv and are not xevo, the probability of gyzp is 43%. For those who are not tijv and are xevo, the probability of gyzp is 13%. For those who are tijv and are not xevo, the probability of gyzp is 55%. For those who are tijv and are xevo, the probability of gyzp is 73%. The overall probability of tijv is 31%. For those who are xevo, would it be more likely to see gyzp if the individual was not xevo?\n",
            "Predicted answer: the answer to this question is yes.\n",
            "\n",
            "question: if you were to ask a random person, \"what is your favorite color?\" what is the chance that the person would say \"blue\" or \"red\"? the correct answer is 50%.\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r  5%|▌         | 5/100 [00:13<03:56,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not zuph, the probability of glimx is 70%. For those who are zuph, the probability of glimx is 72%. For those who are zuph, would it be more likely to see glimx if the individual was not zuph?\n",
            "Predicted answer: the answer is yes.\n",
            "\n",
            "question: what is the difference between the following two statements? (a) the probability that an individual is a member of a group is equal to the sum of the probabilities that the individuals in the group are members of\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r  6%|▌         | 6/100 [00:15<03:42,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look directly at how zuph correlates with glimx in general. Method 2: We look at this correlation case by case according to zory. To understand how zuph affects glimx, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: both methods are correct.\n",
            "\n",
            "question: what is the difference between the two methods? answer: the difference is that in the first method, we are looking at the correlation between zup and glimax. in the second method (method 2),\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:17<03:39,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not hwax and are not pexu, the probability of rukz is 15%. For those who are not hwax and are pexu, the probability of rukz is 16%. For those who are hwax and are not pexu, the probability of rukz is 18%. For those who are hwax and are pexu, the probability of rukz is 16%. The overall probability of hwax is 71%. Will pexu decrease the chance of rukz?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: what is the difference between the two types of people? the difference is that the first type of person has a higher chance to get a good job than the second type. which type is more likely to have a job?\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r  8%|▊         | 8/100 [00:20<03:47,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people with no pre-conditions and refusing the vaccine, the probability of recovering from the disease is 7%. For people with no pre-conditions and getting the vaccine, the probability of recovering from the disease is 37%. For people with pre-conditions and refusing the vaccine, the probability of recovering from the disease is 65%. For people with pre-conditions and getting the vaccine, the probability of recovering from the disease is 96%. The overall probability of pre-conditions is 41%. Will getting the vaccine decrease the chance of recovering from the disease?\n",
            "Predicted answer: yes, it will.\n",
            "\n",
            "question:\n",
            "for people who have a high risk of getting a cold, is it better for them to get the flu vaccine or not? the answer is yes. the flu is caused by a virus, which is\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r  9%|▉         | 9/100 [00:22<03:38,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of jyka is 51%. For those who are not jyka, the probability of kwox is 49%. For those who are jyka, the probability of kwox is 80%. Is kwox less likely than not kwox overall?\n",
            "Predicted answer: yes, it is.\n",
            "\n",
            "question: what is the chance that a student who is not a member of a club will join one in the next year? the probability is 50%. the chance of joining a new club is 20%. what will be\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 10%|█         | 10/100 [00:25<03:28,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of jyka is 54%. The probability of not jyka and lirg is 16%. The probability of jyka and lirg is 19%. Is the chance of lirg smaller when observing jyka?\n",
            "Predicted answer: question: in a coin toss, the probability that the coin will land heads is 50%. if you flip the same coin 10 times, what is the average number of heads you will observe? (hint: use the binomial distribution.)\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n",
            "\n",
            "Iteration 10:\n",
            "Avg perplexity: 23.0262\n",
            "Avg ece: 0.0000\n",
            "Avg brier_score: 0.2500\n",
            "Avg bleu_score: 0.0012\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:27<03:20,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look directly at how having a sister correlates with prisoner in general. Method 2: We look at this correlation case by case according to the private. To understand how having a sister affects prisoner, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: yes, it is.\n",
            "\n",
            "question: why do we need to look into the correlation between sister and prisoner? why can’t we just say that sister has a positive effect on prisoner and that is the reason why sister is correlated with prison\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:29<03:21,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people who do not have a sister and with low blood pressure, the probability of healthy heart is 40%. For people who do not have a sister and with high blood pressure, the probability of healthy heart is 69%. For people who have a sister and with low blood pressure, the probability of healthy heart is 7%. For people who have a sister and with high blood pressure, the probability of healthy heart is 44%. For people who do not have a sister, the probability of high blood pressure is 54%. For people who have a sister, the probability of high blood pressure is 28%. Does having a sister negatively affect heart condition through blood pressure?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: a person has a brother and sister. the brother is healthy and the sister is sick. which of the following is the most likely to be true about the brother’s health? (choose two.)\n",
            "a.\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:31<03:17,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of male gender is 48%. For individuals who are not male, the probability of high salary is 53%. For individuals who are male, the probability of high salary is 78%. Is high salary more likely than low salary overall?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: what is the expected value of the salary of an individual who is male and has a bachelor’s degree? the expected salary for this individual is $60,000. the probability that this person will have a high\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 14%|█▍        | 14/100 [00:34<03:22,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that hwax causes pexu and kraz. pexu or kraz causes rukz. We observed an individual is not hwax. Would an individual is rukz if not pexu instead of pexu?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: i have a question about the use of the word “rukz”. i am not sure if it is the correct word to use when referring to a person who has a rash. is it correct to\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:36<03:15,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of kwox is 73%. For those who are not kwox, the probability of kwoz is 56%. For those who are kwox, the probability of kwoz is 56%. Is kwoz more likely than not kwoz overall?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: what is the expected value of the number of zeros in the decimal expansion of a random number between 0 and 1? (hint: multiply the answer by 100 and then divide by 2.)\n",
            "solution:\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:38<03:09,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For husbands that don't set the alarm, the probability of ringing alarm is 74%. For husbands that set the alarm, the probability of ringing alarm is 21%. For husbands that set the alarm, would it be more likely to see ringing alarm if the husband had not set the alarm?\n",
            "Predicted answer: the answer is yes.\n",
            "\n",
            "question: a husband and wife are in a relationship where the wife is the primary caregiver for the children. the husband is a stay-at-home dad. he works full-time and is able to take\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 17%|█▋        | 17/100 [00:40<03:03,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of drinking coffee is 47%. The probability of not drinking coffee and high salary is 18%. The probability of drinking coffee and high salary is 41%. Is the chance of high salary smaller when observing drinking coffee?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: a company has a salary range of $50,000 to $60,500. the salary of the highest paid employee is $65,200. what is the probability that the company will have an employee with a high\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 18%|█▊        | 18/100 [00:42<03:00,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people who do not have a sister, the probability of lung cancer is 33%. For people who have a sister, the probability of lung cancer is 73%. For people who have a sister, would it be more likely to see lung cancer if the person did not have a sister?\n",
            "Predicted answer: the answer to this question depends on how you define \"more likely.\" if you are talking about a person who has a family history of cancer, then the answer is yes, it would be. however, this is not the same as saying that the\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 19%|█▉        | 19/100 [00:45<02:58,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that hwax causes pexu and kraz. pexu and kraz causes rukz. We observed an individual is hwax. Would an individual is rukz if not pexu instead of pexu?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: what is the difference between hwoax and hwinax? answer: hwaax is a type of wax that is used in the production of candles. it is made by heating paraffin wax and then adding\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:47<03:05,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of pexu is 95%. For those who are not pexu, the probability of rukz is 85%. For those who are pexu, the probability of rukz is 74%. Is rukz more likely than not rukz overall?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: if you were in a situation where you had to make a decision, which of the following would be the best choice for you? (choose all that apply.)\n",
            "(a) go to the store and buy a pack\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n",
            "\n",
            "Iteration 20:\n",
            "Avg perplexity: 25.1117\n",
            "Avg ece: 0.0000\n",
            "Avg brier_score: 0.2500\n",
            "Avg bleu_score: 0.0020\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:49<03:00,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of rainy season is 28%. For people in the dry season, the probability of wet ground is 39%. For in the rainy season, the probability of wet ground is 46%. Is wet ground less likely than dry ground overall?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: you are in a classroom. there are two students in your class. one of the students is male, and the other student is female. the male student has an average score of 90 out of 100 on a math test\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:52<03:00,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not rixq and are not swoy, the probability of xevu is 62%. For those who are not rixq and are swoy, the probability of xevu is 9%. For those who are rixq and are not swoy, the probability of xevu is 15%. For those who are rixq and are swoy, the probability of xevu is 59%. For those who are not rixq, the probability of swoy is 16%. For those who are rixq, the probability of swoy is 13%. For those who are rixq, would it be more likely to see xevu if the individual was not rixq?\n",
            "Predicted answer: it would be less likely.\n",
            "\n",
            "question: if you were to make a bet on the outcome of a coin flip, what is the expected value of the bet? (assume that the coin is fair and that you have no information about the\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [00:54<02:53,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people in a relationship, the correlation between kindness and freckles is -0.08. If we look at people in a relationship, does it mean that kindness does not affect freckles?\n",
            "Predicted answer: yes, it does.\n",
            "\n",
            "question: what is the relationship between the number of people you have in your life and the amount of time it takes you to get to know someone? answer: there is a direct relationship. the longer you spend with\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:56<02:47,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of receives treatment is 49%. The probability of receives no treatment and recovery is 20%. The probability of receives treatment and recovery is 33%. Is the chance of recovery larger when observing receives treatment?\n",
            "Predicted answer: the chance that the patient receives the treatment that he or she would have received if he/she had not been sick is (49% * 33%) / (20% + 20%) = 16.67%.\n",
            "\n",
            "question: a patient is\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 25%|██▌       | 25/100 [00:58<02:46,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For situations where there is no solar eclipse, the probability of arriving to school on time is 74%. For situations where there is a solar eclipse, the probability of arriving to school on time is 30%. Will solar eclipse increase the chance of arriving to school on time?\n",
            "Predicted answer: no, it will not.\n",
            "question: what is the difference between the following two events:\n",
            "event a: there is an eclipse in the sky. the eclipse will last for one hour. there will be a total eclipse of the sun in that\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 26%|██▌       | 26/100 [01:01<02:52,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look directly at how treatment correlates with recovery in general. Method 2: We look at this correlation case by case according to kidney stone size. To understand how treatment affects recovery, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: both methods are correct.\n",
            "\n",
            "question: i’ve been on a low-calorie diet for the past two weeks. i have lost about 15 pounds, and i feel great. however, i am still hungry all the time. what\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [01:03<02:45,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of receives treatment is 64%. For patients not receiving treatment, the probability of thick lips is 80%. For patients receiving treatment, the probability of thick lips is 51%. Is thick lips more likely than thin lips overall?\n",
            "Predicted answer: thick lips are less likely to receive treatment.\n",
            "\n",
            "question: a patient has been diagnosed with cancer of the tongue. the patient’s doctor has recommended surgery to remove the cancer, but the patient does not want to have surgery. what is\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 28%|██▊       | 28/100 [01:05<02:40,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look at how smoking correlates with lung cancer case by case according to tar deposit. Method 2: We look directly at how smoking correlates with lung cancer in general. To understand how smoking affects lung cancer, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: both methods are correct.\n",
            "\n",
            "question: what is the difference between the two methods? answer: the difference is that the first method looks at the correlation between smoking and the number of lung cancers, while the second method uses the general correlation of smoking\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [01:07<02:35,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that zory causes zuph. zuph causes jyka. zory and jyka causes glimx. We observed an individual is zory. Would an individual is glimx if zuph instead of not zuph?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: i have a question. i want to know if there is a way to find out if a person is or is not a member of a certain group. for example, if i was to ask someone if they were a\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 30%|███       | 30/100 [01:09<02:31,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that pexu causes hwax and not kraz. hwax or kraz causes rukz. Would an individual is not rukz if pexu instead of not pexu?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: what is the difference between a pexa and a krz? is there a difference in the effects of the two? if so, what are the differences in their effects on the body and mind? please explain.\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n",
            "\n",
            "Iteration 30:\n",
            "Avg perplexity: 28.6329\n",
            "Avg ece: 0.0000\n",
            "Avg brier_score: 0.2500\n",
            "Avg bleu_score: 0.0019\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [01:12<02:36,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people who have not visited England and directors who don't sign termination letters, the probability of employee being fired is 9%. For people who have not visited England and directors who sign termination letters, the probability of employee being fired is 54%. For people who have visited England and directors who don't sign termination letters, the probability of employee being fired is 46%. For people who have visited England and directors who sign termination letters, the probability of employee being fired is 90%. For people who have not visited England, the probability of director signing the termination letter is 17%. For people who have visited England, the probability of director signing the termination letter is 27%. For people who have visited England, would it be less likely to see employee being fired if the person had not visited England?\n",
            "Predicted answer: it would be more likely for the director to sign the letter.\n",
            "question: what is the chance that a person who has not been to england will be fired by a director who does not sign a termination notice? answer: the chance is 0.\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 32%|███▏      | 32/100 [01:16<03:21,  2.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not yomx and are not gwet, the probability of xevu is 32%. For those who are not yomx and are gwet, the probability of xevu is 44%. For those who are yomx and are not gwet, the probability of xevu is 38%. For those who are yomx and are gwet, the probability of xevu is 50%. For those who are not yomx, the probability of gwet is 54%. For those who are yomx, the probability of gwet is 69%. For those who are yomx, would it be more likely to see xevu if the individual was not yomx?\n",
            "Predicted answer: the answer is yes.\n",
            "\n",
            "question: what are the chances that a person who is not a jew, but is a member of a jewish family, will convert to judaism? what is the chance that he or she will become a full-fledged\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [01:19<03:16,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that smoking causes high tar deposit, and we know that high tar deposit causes absence of lung cancer. Would the person has lung cancer if nonsmoking instead of smoking?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: if a person smokes and then stops smoking, would he/she have lung carcinoma if he or she did not smoke before the stop? answer: no. the person would not have the lung tumor. this is because\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([1.0000e-07, 1.0000e+00], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [01:22<02:59,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people who do not have a sister, the probability of the prisoner's death is 20%. For people who have a sister, the probability of the prisoner's death is 69%. For people who have a sister, would it be less likely to see the prisoner's death if the person did not have a sister?\n",
            "Predicted answer: the probability that a prisoner will die if he is released is the same for all people.\n",
            "question: if a person has a brother, is it more likely that he will see his brother die than it is for him to die himself? answer:\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [01:24<02:45,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For days when Alice wakes up on time, the probability of arriving to school on time is 56%. For days when Alice wakes up late, the probability of arriving to school on time is 18%. For days when Alice wakes up late, would it be more likely to see arriving to school on time if Alice had gotten up on time?\n",
            "Predicted answer: yes, it would be.\n",
            "\n",
            "question: what is the chance that alice will arrive to the school at 8:00 am on monday? answer: the chance of alice arriving at school is 1/2. the probability that she arrives at the\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [01:26<02:35,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of having a brother is 41%. The probability of not having a brother and recovery is 42%. The probability of having a brother and recovery is 10%. Is the chance of recovery smaller when observing having a brother?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: if you have two brothers, what is the probability that both of them have the same birthday? answer:\n",
            "the probability is 1/4. the chance that they have different birthdays is 3/8.\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [01:29<02:52,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For CEOs who fire employees and managers who don't sign termination letters, the probability of large feet is 52%. For CEOs who fire employees and managers who sign termination letters, the probability of large feet is 14%. For CEOs who fire employees and managers who don't sign termination letters, the probability of large feet is 71%. For CEOs who fire employees and managers who sign termination letters, the probability of large feet is 32%. The overall probability of CEO's decision to fire the employee is 98%. Will manager signing the termination letter decrease the chance of large feet?\n",
            "Predicted answer: yes. the manager who signs the letter is more likely to be fired.\n",
            "\n",
            "question: what is the difference between a ceo and a manager? a ceo is a person who has the power to hire and fire people. a manager is someone who\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 38%|███▊      | 38/100 [01:31<02:38,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of alarm set by husband is 4%. The probability of alarm not set by husband and ringing alarm is 74%. The probability of alarm set by husband and ringing alarm is 1%. Is the chance of ringing alarm larger when observing alarm set by husband?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: a woman is having an affair with a married man. the woman's husband finds out about the affair. what is the probability that the husband will find out that his wife has been unfaithful to him? (h\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 39%|███▉      | 39/100 [01:34<02:28,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look at how jyka correlates with kwox case by case according to yupt. Method 2: We look directly at how jyka correlates with kwox in general. To understand how jyka affects kwox, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: the answer to this question depends on what you mean by “more correct.” if you are asking whether it is better to do the first method or the second method, then the answer is clearly yes. if, on the other hand,\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 40%|████      | 40/100 [01:36<02:19,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that pexu causes not hwax, and we know that hwax causes not rukz. Would an individual is not rukz if pexu instead of not pexu?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: is it possible to have both pexi and hwex at the same time? if so, what is the difference between the two? is there a difference in how they affect the body? what are the effects of\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n",
            "\n",
            "Iteration 40:\n",
            "Avg perplexity: 26.9104\n",
            "Avg ece: 0.0250\n",
            "Avg brier_score: 0.2687\n",
            "Avg bleu_score: 0.0020\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [01:38<02:15,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For areas with low cigarette tax, the probability of normal infant birth weight is 56%. For areas with high cigarette tax, the probability of normal infant birth weight is 67%. For areas with low cigarette tax, the probability of smoking mother is 49%. For areas with high cigarette tax, the probability of smoking mother is 20%. Will smoking mother decrease the chance of normal infant birth weight?\n",
            "Predicted answer: smoking mother increases the risk of having a low birthweight infant.\n",
            "\n",
            "question: is there any evidence that smoking during pregnancy has an adverse effect on the health of the fetus? if so, what is the magnitude of this effect and how does it\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 42%|████▏     | 42/100 [01:40<02:12,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of talent is 91%. For students who are not talented, the probability of brown eyes is 95%. For students who are talented, the probability of brown eyes is 95%. Is brown eyes less likely than blue eyes overall?\n",
            "Predicted answer: brown eyes are more likely to be brown.\n",
            "\n",
            "question: what is the chance that a student who is not gifted will be gifted in math? answer:\n",
            "the overall chance of being gifted is 90%. the chance for a non-gifted\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [01:43<02:18,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not zuph and are not jyka, the probability of glimx is 26%. For those who are not zuph and are jyka, the probability of glimx is 91%. For those who are zuph and are not jyka, the probability of glimx is 14%. For those who are zuph and are jyka, the probability of glimx is 88%. For those who are not zuph, the probability of jyka is 56%. For those who are zuph, the probability of jyka is 4%. For those who are zuph, would it be more likely to see glimx if the individual was not zuph?\n",
            "Predicted answer: the answer to this question is yes.\n",
            "\n",
            "question: what is the chance of a person being a jya and not a zuha? the probability is 1/2. the person is a non-zuph person and would be a\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 44%|████▍     | 44/100 [01:45<02:10,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For infants with nonsmoking mothers, the probability of high infant mortality is 61%. For infants with smoking mothers, the probability of high infant mortality is 32%. Will smoking mother increase the chance of high infant mortality?\n",
            "Predicted answer: smoking mother increases the risk of infant death.\n",
            "\n",
            "question: what is the effect of maternal smoking during pregnancy on the infant’s birth weight and length of gestation? how does this effect compare to the effects of other risk factors for low birth\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [01:47<02:05,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not jyka, the probability of lirg is 56%. For those who are jyka, the probability of lirg is 71%. Will jyka increase the chance of lirg?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: what is the difference between the following two statements:\n",
            "(a) the probability that a person is a male is 1/2. (b) a person’s gender is determined by the sex of his parents\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n",
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of yomx is 53%. The probability of not yomx and xevu is 6%. The probability of yomx and xevu is 37%. Is the chance of xevu larger when observing yomx?\n",
            "Predicted answer: yes.\n",
            "question: what is the probability that the overall chance is greater than or equal to 50%? the answer is 50%.\n",
            "\n",
            "the probability is not 50%, because the two events are not independent. the chance that both events occur is\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 47/100 [01:53<02:22,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people who do not listen to jazz and nonsmokers, the probability of lung cancer is 30%. For people who do not listen to jazz and smokers, the probability of lung cancer is 67%. For people who listen to jazz and nonsmokers, the probability of lung cancer is 20%. For people who listen to jazz and smokers, the probability of lung cancer is 63%. For people who do not listen to jazz and with low pollution, the probability of smoking is 33%. For people who do not listen to jazz and with high pollution, the probability of smoking is 65%. For people who listen to jazz and with low pollution, the probability of smoking is 53%. For people who listen to jazz and with high pollution, the probability of smoking is 96%. The overall probability of high pollution is 55%. If we disregard the mediation effect through smoking, would listening to jazz negatively affect lung cancer?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: if you are a smoker, you will have a 30% chance of getting cancer of the lung. if your friend is a non-smoker, he or she will also have the same chance. however, if you\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 48%|████▊     | 48/100 [01:56<02:17,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of having a sister is 81%. For infants who do not have a sister, the probability of high infant mortality is 70%. For infants who have a sister, the probability of high infant mortality is 54%. Is high infant mortality less likely than low infant mortality overall?\n",
            "Predicted answer: yes. the probability that an infant has a high mortality rate is less than the overall chance that the infant will die.\n",
            "\n",
            "question: what is the expected value of the number of siblings for a family of size n? (i.e.\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 49%|████▉     | 49/100 [01:58<02:10,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For patients who have small kidney stones and do not speak english, the probability of recovery is 86%. For patients who have small kidney stones and speak english, the probability of recovery is 75%. For patients who have large kidney stones and do not speak english, the probability of recovery is 19%. For patients who have large kidney stones and speak english, the probability of recovery is 9%. The overall probability of large kidney stone is 55%. Will speaking english increase the chance of recovery?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: if a patient has a large stone in the right kidney and does not have stones in other parts of the body, what is the likelihood that the patient will have a complete recovery of kidney function? answer: the probability is\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 50%|█████     | 50/100 [02:00<02:01,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of pexu is 92%. For those who are not pexu, the probability of rukz is 15%. For those who are pexu, the probability of rukz is 35%. Is rukz more likely than not rukz overall?\n",
            "Predicted answer: this is a question about conditional probability. the answer is yes.\n",
            "\n",
            "question: if you have a coin that is fair, and you flip it twice, what is the chance that you will get heads on both flips? answer: there are two\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([1.0000e-07, 1.0000e+00], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n",
            "\n",
            "Iteration 50:\n",
            "Avg perplexity: 24.2920\n",
            "Avg ece: 0.0200\n",
            "Avg brier_score: 0.2600\n",
            "Avg bleu_score: 0.0018\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [02:02<01:54,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of having visited England is 22%. For people who have not visited England, the probability of employee being fired is 14%. For people who have visited England, the probability of employee being fired is 76%. Is employee being fired less likely than employee not being fired overall?\n",
            "Predicted answer: the probability that an employee will be fired in a given year is the product of two probabilities: (1) the employee’s chance of being hired in that year, and (2) his or her chance that he or she will\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 52%|█████▏    | 52/100 [02:05<01:49,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that hwax causes not jyka and gyzp. jyka and gyzp causes lirg. We observed an individual is hwax. Would an individual is lirg if jyka instead of not jyka?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: i am not sure about the answer to the above question. could you please tell me the reason for not knowing the correct answer? thank you very much for your help.\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 53%|█████▎    | 53/100 [02:07<01:52,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For children with unintelligent parents and with low parental social status, the probability of intelligent child is 60%. For children with unintelligent parents and with high parental social status, the probability of intelligent child is 65%. For children with intelligent parents and with low parental social status, the probability of intelligent child is 29%. For children with intelligent parents and with high parental social status, the probability of intelligent child is 22%. For children with unintelligent parents and confounder inactive, the probability of high parental social status is 72%. For children with unintelligent parents and confounder active, the probability of high parental social status is 41%. For children with intelligent parents and confounder inactive, the probability of high parental social status is 35%. For children with intelligent parents and confounder active, the probability of high parental social status is 12%. The overall probability of confounder active is 52%. If we disregard the mediation effect through parents' social status, would parents' intelligence positively affect child's intelligence?\n",
            "Predicted answer: yes.\n",
            "question: what is the direct effect of parental intelligence on children's intellectual development? (a) 0.2 (b) -0.1 (c) 1.5 (d) 2.0 (e) 3.3\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 54%|█████▍    | 54/100 [02:10<01:52,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of having a brother is 88%. For people who do not have a brother, the probability of high salary is 12%. For people who have a brother, the probability of high salary is 26%. Is high salary more likely than low salary overall?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: if you have two brothers and one of them is a doctor and the other one is an engineer, which one would you choose to be your brother? the probability that you would choose the doctor is 0.5. the\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [02:12<01:48,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For nonsmokers and with no tar deposit, the probability of lung cancer is 34%. For nonsmokers and with high tar deposit, the probability of lung cancer is 59%. For smokers and with no tar deposit, the probability of lung cancer is 42%. For smokers and with high tar deposit, the probability of lung cancer is 69%. For nonsmokers, the probability of high tar deposit is 25%. For smokers, the probability of high tar deposit is 78%. For smokers, would it be less likely to see lung cancer if the person had been a nonsmoker?\n",
            "Predicted answer: it would be more likely.\n",
            "\n",
            "question:\n",
            "what is the difference between a smoker and a non-smoker in terms of the risk of developing cancer? answer: a smoker has a much higher risk than a person who has never smoked.\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [02:14<01:42,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of jyka is 14%. For those who are not jyka, the probability of lirg is 85%. For those who are jyka, the probability of lirg is 84%. Is lirg more likely than not lirg overall?\n",
            "Predicted answer: yes.\n",
            "question: what is the overall chance of being jya? the answer is 80%.\n",
            "\n",
            "1. the probability that a person will be a doctor is 0.6. if the person is a man, what is his chance that\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 57%|█████▋    | 57/100 [02:17<01:40,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For nonsmokers, the probability of high tar deposit is 56%. For smokers, the probability of high tar deposit is 83%. For nonsmokers and with no tar deposit, the probability of lung cancer is 42%. For nonsmokers and with high tar deposit, the probability of lung cancer is 83%. For smokers and with no tar deposit, the probability of lung cancer is 48%. For smokers and with high tar deposit, the probability of lung cancer is 74%. The overall probability of smoking is 45%. Does smoking negatively affect lung cancer through tar deposit?\n",
            "Predicted answer: the answer is yes.\n",
            "\n",
            "question: what is the difference between a smoker and a non-smoker? a smoker is a person who smokes cigarettes. a non smoker does not smoke. why is it important to know this difference? answer:\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 58%|█████▊    | 58/100 [02:19<01:45,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look directly at how drug taken correlates with freckles in general. Method 2: We look at this correlation case by case according to unobserved confounders. To understand how drug taken affects freckles, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: the answer to this question is yes.\n",
            "\n",
            "method 1 is correct because it is based on the assumption that there is a causal relationship between the two variables. in other words, it assumes that the drug is the cause of the change in the fre\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [02:22<01:42,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For infants with nonsmoking mothers, the probability of high infant mortality is 79%. For infants with smoking mothers, the probability of high infant mortality is 52%. For infants with smoking mothers, would it be more likely to see high infant mortality if the infant had a nonsmoking mother?\n",
            "Predicted answer: the answer is yes.\n",
            "\n",
            "question: what is the effect of maternal smoking on the risk of low birth weight infants in the united states? is there a difference in risk for infants born to mothers who smoke compared to those who do not smoke?\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 60%|██████    | 60/100 [02:24<01:39,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of alarm set by husband is 88%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 71%. Is ringing alarm less likely than silent alarm overall?\n",
            "Predicted answer: no. the probability that the husband will set an alarm and ring it is the same. however, there is a difference in the probabilities that he will not set it and that it will be silent.\n",
            "\n",
            "question: a man and a woman are\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n",
            "\n",
            "Iteration 60:\n",
            "Avg perplexity: 23.4650\n",
            "Avg ece: 0.0167\n",
            "Avg brier_score: 0.2583\n",
            "Avg bleu_score: 0.0018\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 61%|██████    | 61/100 [02:27<01:37,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For individuals who are not male and applicants to a non-competitive department, the probability of admission acceptance is 85%. For individuals who are not male and applicants to a competitive department, the probability of admission acceptance is 62%. For individuals who are male and applicants to a non-competitive department, the probability of admission acceptance is 87%. For individuals who are male and applicants to a competitive department, the probability of admission acceptance is 56%. For individuals who are not male and out-of-state residents, the probability of competitive department is 86%. For individuals who are not male and in-state residents, the probability of competitive department is 45%. For individuals who are male and out-of-state residents, the probability of competitive department is 85%. For individuals who are male and in-state residents, the probability of competitive department is 46%. The overall probability of in-state residency is 95%. If we disregard the mediation effect through department competitiveness, would gender positively affect admission status?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: what is the effect of gender on the likelihood of being admitted to the competitive and noncompetitive departments in the u.s. department of education? (for the purpose of this question, we will assume that there is no\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [02:29<01:35,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For individuals who do not like spicy food and blue-collar workers, the probability of high salary is 70%. For individuals who do not like spicy food and white-collar workers, the probability of high salary is 48%. For individuals who like spicy food and blue-collar workers, the probability of high salary is 44%. For individuals who like spicy food and white-collar workers, the probability of high salary is 17%. For individuals who do not like spicy food and with low skill levels, the probability of white-collar job is 74%. For individuals who do not like spicy food and with high skill levels, the probability of white-collar job is 45%. For individuals who like spicy food and with low skill levels, the probability of white-collar job is 49%. For individuals who like spicy food and with high skill levels, the probability of white-collar job is 18%. The overall probability of high skill level is 95%. If we disregard the mediation effect through occupation, would liking spicy food negatively affect salary?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: what is the effect of liking chili peppers on the likelihood of being hired for a white collar job? answer: the effect is negative. the probability that a person will be hired is lower if he or she likes spicy foods\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 63%|██████▎   | 63/100 [02:32<01:28,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of yomx is 21%. The probability of not yomx and xevu is 31%. The probability of yomx and xevu is 17%. Is the chance of xevu smaller when observing yomx?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: a man is asked to pick a card from a deck of 52 cards. he picks the card with the highest face value. what is the probability that he picked the ace of spades? (assume that the man\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [02:34<01:26,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of speaking english is 98%. For people who do not speak english and are not famous, the probability of talent is 94%. For people who do not speak english and are famous, the probability of talent is 81%. For people who speak english and are not famous, the probability of talent is 91%. For people who speak english and are famous, the probability of talent is 74%. If we look at people who are famous, does the chance of talent decrease when speaking english?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: if a person is born in a country that does not have an english speaking population, is it possible for that person to learn english in that country? if so, how much time would it take for this to happen?\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [02:37<01:28,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people with nonsmoking genes and nonsmokers, the probability of lung cancer is 76%. For people with nonsmoking genes and smokers, the probability of lung cancer is 60%. For people with smoking genes and nonsmokers, the probability of lung cancer is 61%. For people with smoking genes and smokers, the probability of lung cancer is 34%. For people with nonsmoking genes and with low pollution, the probability of smoking is 97%. For people with nonsmoking genes and with high pollution, the probability of smoking is 67%. For people with smoking genes and with low pollution, the probability of smoking is 53%. For people with smoking genes and with high pollution, the probability of smoking is 24%. The overall probability of high pollution is 16%. If we disregard the mediation effect through smoking, would gene negatively affect lung cancer?\n",
            "Predicted answer: yes, if we ignore the effect of gene on smoking.\n",
            "question: what is the relationship between gene and smoking? how does it affect the risk of cancer of the lung and other organs? for example, for people who have a gene that makes\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 66%|██████▌   | 66/100 [02:39<01:23,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For patients who are young and pay a low hospital bill, the probability of freckles is 2%. For patients who are young and pay a high hospital bill, the probability of freckles is 17%. For patients who are old and pay a low hospital bill, the probability of freckles is 81%. For patients who are old and pay a high hospital bill, the probability of freckles is 96%. The overall probability of old age is 45%. Will high hospital bill decrease the chance of freckles?\n",
            "Predicted answer: the probability that a patient is old is independent of the patient’s age. therefore, it does not matter whether the hospital bills are high or low.\n",
            "\n",
            "question: a patient has a family history of breast cancer. the patient wants to\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [02:42<01:21,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of jyka is 13%. For those who are not jyka, the probability of kwox is 36%. For those who are jyka, the probability of kwox is 49%. Is kwox less likely than not kwox overall?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: what is the chance that a person who is not a member of a particular group is also not in the group? (for example, if you were to ask this question, you would be looking for a group of people\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 68%|██████▊   | 68/100 [02:45<01:24,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of yupt is 83%. For those who are not yupt, the probability of muvq is 70%. For those who are yupt, the probability of muvq is 77%. Is muvq less likely than not muvq overall?\n",
            "Predicted answer: it depends on the question.\n",
            "question:\n",
            "\n",
            "the probability that a student is not a member of a club is 0.5. the probability the student belongs to the club, however, is 1.0. which of the following is the\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [02:48<01:25,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of male gender is 11%. For individuals who are not male, the probability of being lactose intolerant is 88%. For individuals who are male, the probability of being lactose intolerant is 13%. Is being lactose intolerant more likely than not being lactose intolerant overall?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: if you are a male who is lactase-intolerant, how likely is it that you will be lactating? answer: there is a 1 in 4 chance that the answer is yes, and a 2 in\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([1.0000e-07, 1.0000e+00], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [02:52<01:37,  3.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look directly at how zuph correlates with uvzi in general. Method 2: We look at this correlation case by case according to wibl. To understand how zuph affects uvzi, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: both methods are correct.\n",
            "\n",
            "question: what is the difference between the two methods? answer: the difference is that in the first method, we are looking at the correlation between uvi and zuvi, while in method 2, the question\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n",
            "\n",
            "Iteration 70:\n",
            "Avg perplexity: 22.2386\n",
            "Avg ece: 0.0286\n",
            "Avg brier_score: 0.2679\n",
            "Avg bleu_score: 0.0018\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 71%|███████   | 71/100 [02:56<01:42,  3.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of college degree or higher is 19%. For people without a college degree, the probability of high salary is 42%. For people with a college degree or higher, the probability of high salary is 63%. Is high salary more likely than low salary overall?\n",
            "Predicted answer: yes. the probability that a person will earn a salary of $60,000 or more is more than twice as likely as the person earning a low-salary job.\n",
            "\n",
            "question: a company has a policy that all employees are required to\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 72%|███████▏  | 72/100 [02:58<01:26,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people with nonsmoking genes, the probability of lung cancer is 43%. For people with smoking genes, the probability of lung cancer is 58%. Will smoking gene decrease the chance of lung cancer?\n",
            "Predicted answer: smoking gene does not affect the chances of developing lung cancers.\n",
            "\n",
            "question: how many people in the united states have a family history of breast cancer, and how many of those people have had a first-degree relative who has died from the disease\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [03:01<01:15,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of rixq is 62%. The probability of not rixq and xevu is 20%. The probability of rixq and xevu is 31%. Is the chance of xevu smaller when observing rixq?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: what is the probability that a coin will come up heads when it is flipped 100 times? the coin is fair and has a 50% chance to be heads each time. if you flip the coin 10 times, what is\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 74%|███████▍  | 74/100 [03:03<01:09,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of having a sister is 99%. For people who do not have a sister, the probability of lung cancer is 27%. For people who have a sister, the probability of lung cancer is 57%. Is lung cancer less likely than absence of lung cancer overall?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: if a person has two sisters, and one of them has breast cancer and the other one has colon cancer, what is the chance that the person will have breast and colon cancers at the same time? answer: this is\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [03:05<01:05,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that tijw causes xevo. xevo causes tijv. tijw or tijv causes gyzp. We observed an individual is tijw. Would an individual is gyzp if not xevo instead of xevo?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: why is it that when i press a key on my keyboard, it does not change the color of the key? it is the same color as it was before i pressed it. why does this happen? is it because\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 76%|███████▌  | 76/100 [03:08<00:59,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look directly at how hospital costs correlates with recovery in general. Method 2: We look at this correlation case by case according to age. To understand how hospital costs affects recovery, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: the answer to this question is that it is more appropriate to look into the correlation between hospital cost and recovery rather than looking at the recovery per se.\n",
            "\n",
            "question: what is the difference between the two methods? answer: there is no difference.\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [03:10<00:54,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of zuph is 88%. For those who are not zuph, the probability of glimx is 84%. For those who are zuph, the probability of glimx is 70%. Is glimx more likely than not glimx overall?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: what is the chance that a person who is not a member of any religion will convert to a particular religion in the next year? the answer is 50%.\n",
            "explanation: this question asks about the conversion rate of\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [03:12<00:50,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of pexu is 68%. For those who are not pexu, the probability of rukz is 78%. For those who are pexu, the probability of rukz is 79%. Is rukz more likely than not rukz overall?\n",
            "Predicted answer: no.\n",
            "question: what is the chance of a person who is not a member of any of the groups being asked to participate in the study being randomly selected to take part in it? the answer is 0.05. is this a correct answer\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [03:14<00:48,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For normal weight people and without diabetes, the probability of long lifespan is 23%. For normal weight people and with diabetes, the probability of long lifespan is 51%. For obese people and without diabetes, the probability of long lifespan is 52%. For obese people and with diabetes, the probability of long lifespan is 75%. For normal weight people and nonsmokers, the probability of having diabetes is 80%. For normal weight people and smokers, the probability of having diabetes is 58%. For obese people and nonsmokers, the probability of having diabetes is 51%. For obese people and smokers, the probability of having diabetes is 22%. The overall probability of smoker is 88%. Does obesity negatively affect lifespan through diabetes?\n",
            "Predicted answer: yes, obesity is a risk factor for diabetes. obesity increases the risk of diabetes by 2 to 3 times.\n",
            "\n",
            "question: what is the relationship between obesity and cancer? answer: obesity is one of the major risk factors for cancer. it increases\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [03:17<00:46,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not yomx, the probability of xevu is 76%. For those who are yomx, the probability of xevu is 84%. For those who are yomx, would it be less likely to see xevu if the individual was not yomx?\n",
            "Predicted answer: yes, it would.\n",
            "\n",
            "question: what is the chance that a person who is not jewish will have a child with a jewish mother? answer: the chance of a non-jewish person having a jew is 1 in 2.5 million.\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n",
            "\n",
            "Iteration 80:\n",
            "Avg perplexity: 22.2860\n",
            "Avg ece: 0.0250\n",
            "Avg brier_score: 0.2656\n",
            "Avg bleu_score: 0.0017\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 81%|████████  | 81/100 [03:19<00:46,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For patients who have small kidney stones and not receiving treatment, the probability of thick lips is 6%. For patients who have small kidney stones and receiving treatment, the probability of thick lips is 38%. For patients who have large kidney stones and not receiving treatment, the probability of thick lips is 63%. For patients who have large kidney stones and receiving treatment, the probability of thick lips is 95%. The overall probability of large kidney stone is 50%. For patients receiving treatment, would it be more likely to see thick lips if the patient had received no treatment?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: what is the chance that a patient who has a small stone will have a large stone? answer: the chance of having a stone of a certain size is 0.05. the probability that the stone does not exceed a\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [03:21<00:42,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look at how xevo correlates with gyzp case by case according to tijw. Method 2: We look directly at how xevo correlates with gyzp in general. To understand how xevo affects gyzp, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: both methods are correct.\n",
            "\n",
            "question: what is the difference between the two methods? answer: the method 1 is more accurate than the method 2 because it is based on the assumption that the gyroscope is a linear device. therefore, the\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 83%|████████▎ | 83/100 [03:24<00:38,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not yomx, the probability of xevu is 70%. For those who are yomx, the probability of xevu is 60%. Does yomx positively affect xevu through gwet?\n",
            "Predicted answer: yes, it does.\n",
            "\n",
            "question: what is the chance that a person who is not a jew will be killed by the nazis during world war ii? answer: the chance of a non-jew being killed is 1 in 100,000.\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [03:26<00:35,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of jyka is 40%. The probability of not jyka and lirg is 3%. The probability of jyka and lirg is 11%. Is the chance of lirg larger when observing jyka?\n",
            "Predicted answer: the probability that you will observe a particular event is given by the following formula: p(e) = p[e]/p[not e]\n",
            "in this case, you are asked to find the ratio of the probabilities of observing\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 85%|████████▌ | 85/100 [03:28<00:35,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For infants who do not have a sister and low infant birth weight, the probability of high infant mortality is 32%. For infants who do not have a sister and normal infant birth weight, the probability of high infant mortality is 73%. For infants who have a sister and low infant birth weight, the probability of high infant mortality is 4%. For infants who have a sister and normal infant birth weight, the probability of high infant mortality is 37%. For infants who do not have a sister and with poor health, the probability of normal infant birth weight is 55%. For infants who do not have a sister and with good health, the probability of normal infant birth weight is 24%. For infants who have a sister and with poor health, the probability of normal infant birth weight is 83%. For infants who have a sister and with good health, the probability of normal infant birth weight is 57%. The overall probability of good health is 6%. Does having a sister negatively affect infant mortality through infant's birth weight?\n",
            "Predicted answer: no.\n",
            "\n",
            "question: what is the relationship between the number of siblings and the likelihood of a child being born with down syndrome? is there a positive or negative relationship? explain. answer: there is no relationship. the likelihood that a baby will\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [03:31<00:33,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of the captain's order to execute the prisoner is 59%. For captains who release prisoners, the probability of the prisoner's death is 33%. For captains who execute prisoners, the probability of the prisoner's death is 56%. Is the prisoner's death less likely than the prisoner being alive overall?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: a prisoner has been sentenced to death by hanging. the prisoner will be executed at noon on the day of execution. if the execution is delayed until 2:00 p.m., what is the expected length of time the\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [03:33<00:31,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not tijv and are not xevo, the probability of gyzp is 15%. For those who are not tijv and are xevo, the probability of gyzp is 30%. For those who are tijv and are not xevo, the probability of gyzp is 15%. For those who are tijv and are xevo, the probability of gyzp is 66%. The overall probability of tijv is 79%. Will xevo increase the chance of gyzp?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: what is the best way to get rid of the fear of death? answer: do not worry about death. if you do not die, then you will not be afraid of it. the only thing you need to do\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [03:35<00:28,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of yupt is 83%. The probability of not yupt and muvq is 4%. The probability of yupt and muvq is 77%. Is the chance of muvq larger when observing yupt?\n",
            "Predicted answer: yes.\n",
            "question: what is the probability that the coin will come up heads when it lands on the head side? (hint: use the law of total probability.)\n",
            "solution:\n",
            "the chance that it will land heads is 1/\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [03:37<00:25,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look directly at how appearance correlates with talent in general. Method 2: We look at this correlation case by case according to fame. To understand how appearance affects talent, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: both methods are correct.\n",
            "\n",
            "question: what is the difference between the two methods? answer: the difference is that the first method looks at the correlation between appearance and talent while the second method uses the case-by-case approach. the first\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [03:40<00:22,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For nonsmokers, the probability of lung cancer is 34%. For smokers, the probability of lung cancer is 51%. Will smoking increase the chance of lung cancer?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: a woman is diagnosed with breast cancer. she is told that she has a 50% chance to live 5 years after her diagnosis. if she is a smoker, will she live longer than if she does not smoke? answer\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n",
            "\n",
            "Iteration 90:\n",
            "Avg perplexity: 22.1331\n",
            "Avg ece: 0.0222\n",
            "Avg brier_score: 0.2639\n",
            "Avg bleu_score: 0.0018\n",
            "Avg f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 91%|█████████ | 91/100 [03:42<00:19,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: Method 1: We look at how talent correlates with effort case by case according to elite institution admission status. Method 2: We look directly at how talent correlates with effort in general. To understand how talent affects effort, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted answer: the answer to this question depends on the purpose of the study. if the goal is to understand the relationship between effort and talent, then both methods are valid. however, if the aim is simply to find out whether there is a correlation between talent and\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [03:44<00:17,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of smoking is 48%. For nonsmokers, the probability of being allergic to peanuts is 50%. For smokers, the probability of being allergic to peanuts is 51%. Is being allergic to peanuts less likely than not being allergic to peanuts overall?\n",
            "Predicted answer: yes.\n",
            "\n",
            "question: if the overall chance of getting cancer is 10%, what is the chance that you will get cancer if you have a family history of cancer? answer: 0.1% of the population will develop cancer in their lifetime.\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 93%|█████████▎| 93/100 [03:47<00:16,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For people who do not have a sister and with low blood pressure, the probability of healthy heart is 61%. For people who do not have a sister and with high blood pressure, the probability of healthy heart is 92%. For people who have a sister and with low blood pressure, the probability of healthy heart is 18%. For people who have a sister and with high blood pressure, the probability of healthy heart is 45%. For people who do not have a sister, the probability of high blood pressure is 61%. For people who have a sister, the probability of high blood pressure is 14%. Does having a sister positively affect heart condition through blood pressure?\n",
            "Predicted answer: yes, it does.\n",
            "\n",
            "question: what is the effect of having children on the health of a person? answer: having children is good for health. having a child increases the chance of good health by 1.5 times. it also increases\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [03:49<00:13,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that blowing out the candle and candle with wax causes dark room. We observed the candle is out of wax. Would the room is bright if blowing out the candle instead of not blowing out the candle?\n",
            "Predicted answer: the room would be bright.\n",
            "\n",
            "question: what is the difference between a candle, a lamp, and a light bulb? answer: a lamp is a source of light. a candle produces light by burning wax, which is made of hydrocar\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [03:51<00:11,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For children with unintelligent parents, the probability of intelligent child is 42%. For children with intelligent parents, the probability of intelligent child is 56%. For children with intelligent parents, would it be less likely to see intelligent child if the child had unintelligent parents?\n",
            "Predicted answer: the answer is yes.\n",
            "\n",
            "question: if a child has an iq of 100, what is the chance that he or she will have an intelligent parent? answer: this is a difficult question to answer. there are a number of factors that affect\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [03:53<00:08,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of receives treatment is 56%. The probability of receives no treatment and being allergic to peanuts is 8%. The probability of receives treatment and being allergic to peanuts is 36%. Is the chance of being allergic to peanuts larger when observing receives treatment?\n",
            "Predicted answer: no.\n",
            "question: a patient has an allergy to peanut. the patient is given information on the likelihood of receiving treatment for peanut allergy. what is the probability that the patient will receive treatment if he or she is allergic? (hint: use\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 97%|█████████▋| 97/100 [03:55<00:06,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: We know that speaking english and smoker causes having diabetes. speaking english and smoker and having diabetes causes long lifespan. We observed the person is a smoker. Would the person has a long lifespan if not speaking english instead of speaking english?\n",
            "Predicted answer: yes, the smoker would have a longer lifespan than the non-smoker.\n",
            "\n",
            "question: if you know the answer to the above question, then why do you need to ask the question in the first place? why not just say that the\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\r 98%|█████████▊| 98/100 [03:58<00:04,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of smoking mother is 15%. For infants with nonsmoking mothers, the probability of normal infant birth weight is 7%. For infants with smoking mothers, the probability of normal infant birth weight is 47%. Is normal infant birth weight more likely than low infant birth weight overall?\n",
            "Predicted answer: yes.\n",
            "question: a mother smokes during pregnancy. the infant is born with a birthweight of 3.5 pounds. if the mother smoked during the pregnancy, is the infant more or less likely to have a normal weight than if she did not\n",
            "Ground truth: no\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([0., 1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [04:00<00:02,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: The overall probability of manager signing the termination letter is 30%. For managers who don't sign termination letters, the probability of large feet is 73%. For managers who sign termination letters, the probability of large feet is 25%. Is large feet more likely than small feet overall?\n",
            "Predicted answer: yes.\n",
            "question: what is the expected value of the number of feet a manager will sign a termination notice for the year? (assume that the manager is a random variable with a uniform distribution on the interval [0,1].)\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [04:02<00:00,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NaN detected in probabilities, using uniform distribution\n",
            "\n",
            "Detailed evaluation:\n",
            "Input: For those who are not yomx, the probability of xevu is 36%. For those who are yomx, the probability of xevu is 38%. For those who are yomx, would it be less likely to see xevu if the individual was not yomx?\n",
            "Predicted answer: the answer to this question is yes, it would be more likely for someone who is not yom kippur to have a xeva.\n",
            "\n",
            "question: what is the most likely reason for a person to get a yeva? answer:\n",
            "Ground truth: yes\n",
            "Prediction probabilities: tensor([0.5000, 0.5000], device='cuda:0')\n",
            "True label: tensor([1., 0.], device='cuda:0')\n",
            "\n",
            "Iteration 100:\n",
            "Avg perplexity: 22.3496\n",
            "Avg ece: 0.0200\n",
            "Avg brier_score: 0.2625\n",
            "Avg bleu_score: 0.0017\n",
            "Avg f1_score: 0.0000\n",
            "\n",
            "Final Results:\n",
            "perplexity: 22.3496\n",
            "ece: 0.0200\n",
            "brier_score: 0.2625\n",
            "bleu_score: 0.0017\n",
            "f1_score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_binary_prediction(model, tokenizer, input_text, device):\n",
        "    \"\"\"Generate a binary yes/no prediction with confidence scores.\"\"\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Generate the response\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_new_tokens=10,  # Reduced since we only need yes/no\n",
        "            num_beams=2,\n",
        "            do_sample=False,  # Deterministic for binary classification\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        # Get the predicted answer\n",
        "        predicted_tokens = outputs.sequences[0][inputs.input_ids.shape[1]:]\n",
        "        predicted_answer = tokenizer.decode(predicted_tokens, skip_special_tokens=True).strip().lower()\n",
        "\n",
        "        # Calculate probabilities for yes/no\n",
        "        last_token_logits = outputs.scores[-1][0].float()\n",
        "        yes_token_ids = tokenizer.encode(\" yes\", add_special_tokens=False)\n",
        "        no_token_ids = tokenizer.encode(\" no\", add_special_tokens=False)\n",
        "\n",
        "        # Get average logits for yes/no tokens\n",
        "        yes_logit = last_token_logits[yes_token_ids].mean()\n",
        "        no_logit = last_token_logits[no_token_ids].mean()\n",
        "\n",
        "        # Convert to probabilities using softmax\n",
        "        logits = torch.tensor([yes_logit, no_logit], device=device)\n",
        "        probs = torch.nn.functional.softmax(logits, dim=0)\n",
        "\n",
        "        return {\n",
        "            'prediction': 'yes' if predicted_answer.startswith('yes') else 'no',\n",
        "            'confidence': float(probs[0] if predicted_answer.startswith('yes') else probs[1]),\n",
        "            'yes_prob': float(probs[0]),\n",
        "            'no_prob': float(probs[1])\n",
        "        }\n",
        "\n",
        "def calculate_binary_metrics(predictions, ground_truths):\n",
        "    \"\"\"Calculate metrics for binary classification.\"\"\"\n",
        "    # Convert yes/no to 1/0\n",
        "    pred_labels = [1 if p['prediction'] == 'yes' else 0 for p in predictions]\n",
        "    true_labels = [1 if gt == 'yes' else 0 for gt in ground_truths]\n",
        "    confidences = [p['confidence'] for p in predictions]\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(true_labels, pred_labels),\n",
        "        'f1': f1_score(true_labels, pred_labels),\n",
        "        'precision': precision_score(true_labels, pred_labels),\n",
        "        'recall': recall_score(true_labels, pred_labels),\n",
        "        'brier_score': np.mean([(c - t)**2 for c, t in zip(confidences, true_labels)]),\n",
        "    }\n",
        "\n",
        "    # Calculate calibration metrics\n",
        "    confidences = np.array(confidences)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    # Expected Calibration Error (ECE)\n",
        "    n_bins = 10\n",
        "    bins = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_indices = np.digitize(confidences, bins) - 1\n",
        "\n",
        "    ece = 0.0\n",
        "    for bin_idx in range(n_bins):\n",
        "        mask = bin_indices == bin_idx\n",
        "        if mask.any():\n",
        "            bin_conf = confidences[mask].mean()\n",
        "            bin_acc = true_labels[mask].mean()\n",
        "            bin_size = mask.mean()\n",
        "            ece += np.abs(bin_conf - bin_acc) * bin_size\n",
        "\n",
        "    metrics['ece'] = float(ece)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate_binary_dataset(model, tokenizer, dataset, device):\n",
        "    \"\"\"Evaluate the model on a dataset of binary questions.\"\"\"\n",
        "    all_predictions = []\n",
        "    all_ground_truths = []\n",
        "\n",
        "    for sample in tqdm(dataset, desc=\"Evaluating\"):\n",
        "        input_text = f\"Given Info and Question: {sample['input']}\\nAnswer:\"\n",
        "        ground_truth = str(sample['answer']).strip().lower()\n",
        "\n",
        "        try:\n",
        "            prediction = get_binary_prediction(model, tokenizer, input_text, device)\n",
        "            all_predictions.append(prediction)\n",
        "            all_ground_truths.append(ground_truth)\n",
        "\n",
        "            # Print sample results\n",
        "            print(f\"\\nInput: {sample['input']}\")\n",
        "            print(f\"Predicted: {prediction['prediction']} (confidence: {prediction['confidence']:.3f})\")\n",
        "            print(f\"Ground truth: {ground_truth}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing sample: {str(e)}\")\n",
        "\n",
        "    # Calculate and return all metrics\n",
        "    return calculate_binary_metrics(all_predictions, all_ground_truths)\n",
        "\n",
        "# Example usage:\n",
        "results = evaluate_binary_dataset(model, tokenizer, cladder_dataset, device)\n",
        "print(\"\\nFinal Results:\")\n",
        "for metric_name, value in results.items():\n",
        "  print(f\"{metric_name}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRYbrzdFAYCq",
        "outputId": "7c08a3ce-b234-472c-e773-b6cc8c980554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   1%|          | 1/100 [00:00<01:15,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that male gender or in-state residency causes competitive department. male gender or in-state residency or competitive department causes admission acceptance. We observed the resident is in-state. Would the applicant gets rejected if male gender instead of non-male gender?\n",
            "Predicted: yes (confidence: 0.671)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 2/100 [00:01<01:19,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of talent is 82%. For students who are not talented and rejected from elite institutions, the probability of being hard-working is 99%. For students who are not talented and accepted to elite institutions, the probability of being hard-working is 82%. For students who are talented and rejected from elite institutions, the probability of being hard-working is 96%. For students who are talented and accepted to elite institutions, the probability of being hard-working is 53%. If we look at students accepted to elite institutions, does the chance of being hard-working decrease when talent?\n",
            "Predicted: no (confidence: 0.576)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 3/100 [00:02<01:21,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of pexu is 83%. For those who are not pexu, the probability of rukz is 81%. For those who are pexu, the probability of rukz is 81%. Is rukz less likely than not rukz overall?\n",
            "Predicted: no (confidence: 0.719)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 4/100 [00:03<01:19,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not tijv and are not xevo, the probability of gyzp is 43%. For those who are not tijv and are xevo, the probability of gyzp is 13%. For those who are tijv and are not xevo, the probability of gyzp is 55%. For those who are tijv and are xevo, the probability of gyzp is 73%. The overall probability of tijv is 31%. For those who are xevo, would it be more likely to see gyzp if the individual was not xevo?\n",
            "Predicted: no (confidence: 0.984)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 5/100 [00:04<01:20,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not zuph, the probability of glimx is 70%. For those who are zuph, the probability of glimx is 72%. For those who are zuph, would it be more likely to see glimx if the individual was not zuph?\n",
            "Predicted: no (confidence: 0.871)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 6/100 [00:05<01:19,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how zuph correlates with glimx in general. Method 2: We look at this correlation case by case according to zory. To understand how zuph affects glimx, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.551)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 7/100 [00:06<01:26,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not hwax and are not pexu, the probability of rukz is 15%. For those who are not hwax and are pexu, the probability of rukz is 16%. For those who are hwax and are not pexu, the probability of rukz is 18%. For those who are hwax and are pexu, the probability of rukz is 16%. The overall probability of hwax is 71%. Will pexu decrease the chance of rukz?\n",
            "Predicted: no (confidence: 0.993)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 8/100 [00:07<01:26,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people with no pre-conditions and refusing the vaccine, the probability of recovering from the disease is 7%. For people with no pre-conditions and getting the vaccine, the probability of recovering from the disease is 37%. For people with pre-conditions and refusing the vaccine, the probability of recovering from the disease is 65%. For people with pre-conditions and getting the vaccine, the probability of recovering from the disease is 96%. The overall probability of pre-conditions is 41%. Will getting the vaccine decrease the chance of recovering from the disease?\n",
            "Predicted: no (confidence: 0.957)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 9/100 [00:07<01:20,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 51%. For those who are not jyka, the probability of kwox is 49%. For those who are jyka, the probability of kwox is 80%. Is kwox less likely than not kwox overall?\n",
            "Predicted: no (confidence: 0.691)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 10/100 [00:08<01:09,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 54%. The probability of not jyka and lirg is 16%. The probability of jyka and lirg is 19%. Is the chance of lirg smaller when observing jyka?\n",
            "Predicted: no (confidence: 0.987)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 11/100 [00:08<01:03,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how having a sister correlates with prisoner in general. Method 2: We look at this correlation case by case according to the private. To understand how having a sister affects prisoner, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.973)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 12/100 [00:09<00:58,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not have a sister and with low blood pressure, the probability of healthy heart is 40%. For people who do not have a sister and with high blood pressure, the probability of healthy heart is 69%. For people who have a sister and with low blood pressure, the probability of healthy heart is 7%. For people who have a sister and with high blood pressure, the probability of healthy heart is 44%. For people who do not have a sister, the probability of high blood pressure is 54%. For people who have a sister, the probability of high blood pressure is 28%. Does having a sister negatively affect heart condition through blood pressure?\n",
            "Predicted: no (confidence: 0.984)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 13/100 [00:10<00:56,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of male gender is 48%. For individuals who are not male, the probability of high salary is 53%. For individuals who are male, the probability of high salary is 78%. Is high salary more likely than low salary overall?\n",
            "Predicted: no (confidence: 0.145)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 14/100 [00:10<00:56,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that hwax causes pexu and kraz. pexu or kraz causes rukz. We observed an individual is not hwax. Would an individual is rukz if not pexu instead of pexu?\n",
            "Predicted: no (confidence: 0.846)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 15/100 [00:11<00:56,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of kwox is 73%. For those who are not kwox, the probability of kwoz is 56%. For those who are kwox, the probability of kwoz is 56%. Is kwoz more likely than not kwoz overall?\n",
            "Predicted: no (confidence: 0.871)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 16/100 [00:12<00:55,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For husbands that don't set the alarm, the probability of ringing alarm is 74%. For husbands that set the alarm, the probability of ringing alarm is 21%. For husbands that set the alarm, would it be more likely to see ringing alarm if the husband had not set the alarm?\n",
            "Predicted: no (confidence: 0.982)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 17/100 [00:12<00:53,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of drinking coffee is 47%. The probability of not drinking coffee and high salary is 18%. The probability of drinking coffee and high salary is 41%. Is the chance of high salary smaller when observing drinking coffee?\n",
            "Predicted: no (confidence: 0.992)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 18/100 [00:13<00:47,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not have a sister, the probability of lung cancer is 33%. For people who have a sister, the probability of lung cancer is 73%. For people who have a sister, would it be more likely to see lung cancer if the person did not have a sister?\n",
            "Predicted: no (confidence: 0.998)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 19/100 [00:13<00:42,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that hwax causes pexu and kraz. pexu and kraz causes rukz. We observed an individual is hwax. Would an individual is rukz if not pexu instead of pexu?\n",
            "Predicted: no (confidence: 0.841)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 20/100 [00:13<00:39,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of pexu is 95%. For those who are not pexu, the probability of rukz is 85%. For those who are pexu, the probability of rukz is 74%. Is rukz more likely than not rukz overall?\n",
            "Predicted: no (confidence: 0.657)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 21/100 [00:14<00:37,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of rainy season is 28%. For people in the dry season, the probability of wet ground is 39%. For in the rainy season, the probability of wet ground is 46%. Is wet ground less likely than dry ground overall?\n",
            "Predicted: no (confidence: 0.820)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 22/100 [00:14<00:37,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not rixq and are not swoy, the probability of xevu is 62%. For those who are not rixq and are swoy, the probability of xevu is 9%. For those who are rixq and are not swoy, the probability of xevu is 15%. For those who are rixq and are swoy, the probability of xevu is 59%. For those who are not rixq, the probability of swoy is 16%. For those who are rixq, the probability of swoy is 13%. For those who are rixq, would it be more likely to see xevu if the individual was not rixq?\n",
            "Predicted: no (confidence: 0.957)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 23/100 [00:15<00:35,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people in a relationship, the correlation between kindness and freckles is -0.08. If we look at people in a relationship, does it mean that kindness does not affect freckles?\n",
            "Predicted: no (confidence: 1.000)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 24/100 [00:15<00:33,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of receives treatment is 49%. The probability of receives no treatment and recovery is 20%. The probability of receives treatment and recovery is 33%. Is the chance of recovery larger when observing receives treatment?\n",
            "Predicted: no (confidence: 0.711)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 25/100 [00:16<00:32,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For situations where there is no solar eclipse, the probability of arriving to school on time is 74%. For situations where there is a solar eclipse, the probability of arriving to school on time is 30%. Will solar eclipse increase the chance of arriving to school on time?\n",
            "Predicted: no (confidence: 0.993)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 26/100 [00:16<00:31,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how treatment correlates with recovery in general. Method 2: We look at this correlation case by case according to kidney stone size. To understand how treatment affects recovery, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.350)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 27/100 [00:16<00:30,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of receives treatment is 64%. For patients not receiving treatment, the probability of thick lips is 80%. For patients receiving treatment, the probability of thick lips is 51%. Is thick lips more likely than thin lips overall?\n",
            "Predicted: no (confidence: 0.950)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 28/100 [00:17<00:30,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look at how smoking correlates with lung cancer case by case according to tar deposit. Method 2: We look directly at how smoking correlates with lung cancer in general. To understand how smoking affects lung cancer, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.880)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 29/100 [00:17<00:31,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that zory causes zuph. zuph causes jyka. zory and jyka causes glimx. We observed an individual is zory. Would an individual is glimx if zuph instead of not zuph?\n",
            "Predicted: no (confidence: 0.920)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 30/100 [00:18<00:31,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that pexu causes hwax and not kraz. hwax or kraz causes rukz. Would an individual is not rukz if pexu instead of not pexu?\n",
            "Predicted: no (confidence: 0.979)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 31/100 [00:18<00:33,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who have not visited England and directors who don't sign termination letters, the probability of employee being fired is 9%. For people who have not visited England and directors who sign termination letters, the probability of employee being fired is 54%. For people who have visited England and directors who don't sign termination letters, the probability of employee being fired is 46%. For people who have visited England and directors who sign termination letters, the probability of employee being fired is 90%. For people who have not visited England, the probability of director signing the termination letter is 17%. For people who have visited England, the probability of director signing the termination letter is 27%. For people who have visited England, would it be less likely to see employee being fired if the person had not visited England?\n",
            "Predicted: no (confidence: 0.975)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 32/100 [00:19<00:34,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not yomx and are not gwet, the probability of xevu is 32%. For those who are not yomx and are gwet, the probability of xevu is 44%. For those who are yomx and are not gwet, the probability of xevu is 38%. For those who are yomx and are gwet, the probability of xevu is 50%. For those who are not yomx, the probability of gwet is 54%. For those who are yomx, the probability of gwet is 69%. For those who are yomx, would it be more likely to see xevu if the individual was not yomx?\n",
            "Predicted: no (confidence: 0.260)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 33/100 [00:19<00:33,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that smoking causes high tar deposit, and we know that high tar deposit causes absence of lung cancer. Would the person has lung cancer if nonsmoking instead of smoking?\n",
            "Predicted: yes (confidence: 0.475)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 34/100 [00:20<00:34,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not have a sister, the probability of the prisoner's death is 20%. For people who have a sister, the probability of the prisoner's death is 69%. For people who have a sister, would it be less likely to see the prisoner's death if the person did not have a sister?\n",
            "Predicted: no (confidence: 0.959)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 35/100 [00:21<00:33,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For days when Alice wakes up on time, the probability of arriving to school on time is 56%. For days when Alice wakes up late, the probability of arriving to school on time is 18%. For days when Alice wakes up late, would it be more likely to see arriving to school on time if Alice had gotten up on time?\n",
            "Predicted: no (confidence: 0.703)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 36/100 [00:21<00:31,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having a brother is 41%. The probability of not having a brother and recovery is 42%. The probability of having a brother and recovery is 10%. Is the chance of recovery smaller when observing having a brother?\n",
            "Predicted: no (confidence: 0.955)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 37/100 [00:21<00:29,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For CEOs who fire employees and managers who don't sign termination letters, the probability of large feet is 52%. For CEOs who fire employees and managers who sign termination letters, the probability of large feet is 14%. For CEOs who fire employees and managers who don't sign termination letters, the probability of large feet is 71%. For CEOs who fire employees and managers who sign termination letters, the probability of large feet is 32%. The overall probability of CEO's decision to fire the employee is 98%. Will manager signing the termination letter decrease the chance of large feet?\n",
            "Predicted: no (confidence: 0.970)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 38/100 [00:22<00:28,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of alarm set by husband is 4%. The probability of alarm not set by husband and ringing alarm is 74%. The probability of alarm set by husband and ringing alarm is 1%. Is the chance of ringing alarm larger when observing alarm set by husband?\n",
            "Predicted: no (confidence: 0.711)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 39/100 [00:22<00:27,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look at how jyka correlates with kwox case by case according to yupt. Method 2: We look directly at how jyka correlates with kwox in general. To understand how jyka affects kwox, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.696)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 40/100 [00:23<00:26,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that pexu causes not hwax, and we know that hwax causes not rukz. Would an individual is not rukz if pexu instead of not pexu?\n",
            "Predicted: no (confidence: 0.860)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 41/100 [00:23<00:25,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For areas with low cigarette tax, the probability of normal infant birth weight is 56%. For areas with high cigarette tax, the probability of normal infant birth weight is 67%. For areas with low cigarette tax, the probability of smoking mother is 49%. For areas with high cigarette tax, the probability of smoking mother is 20%. Will smoking mother decrease the chance of normal infant birth weight?\n",
            "Predicted: no (confidence: 0.949)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 42/100 [00:24<00:24,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of talent is 91%. For students who are not talented, the probability of brown eyes is 95%. For students who are talented, the probability of brown eyes is 95%. Is brown eyes less likely than blue eyes overall?\n",
            "Predicted: no (confidence: 0.893)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 43/100 [00:24<00:25,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not zuph and are not jyka, the probability of glimx is 26%. For those who are not zuph and are jyka, the probability of glimx is 91%. For those who are zuph and are not jyka, the probability of glimx is 14%. For those who are zuph and are jyka, the probability of glimx is 88%. For those who are not zuph, the probability of jyka is 56%. For those who are zuph, the probability of jyka is 4%. For those who are zuph, would it be more likely to see glimx if the individual was not zuph?\n",
            "Predicted: no (confidence: 0.868)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 44/100 [00:24<00:24,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For infants with nonsmoking mothers, the probability of high infant mortality is 61%. For infants with smoking mothers, the probability of high infant mortality is 32%. Will smoking mother increase the chance of high infant mortality?\n",
            "Predicted: no (confidence: 0.945)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 45/100 [00:25<00:23,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not jyka, the probability of lirg is 56%. For those who are jyka, the probability of lirg is 71%. Will jyka increase the chance of lirg?\n",
            "Predicted: no (confidence: 0.500)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 46/100 [00:25<00:22,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of yomx is 53%. The probability of not yomx and xevu is 6%. The probability of yomx and xevu is 37%. Is the chance of xevu larger when observing yomx?\n",
            "Predicted: no (confidence: 0.768)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 47/100 [00:26<00:23,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not listen to jazz and nonsmokers, the probability of lung cancer is 30%. For people who do not listen to jazz and smokers, the probability of lung cancer is 67%. For people who listen to jazz and nonsmokers, the probability of lung cancer is 20%. For people who listen to jazz and smokers, the probability of lung cancer is 63%. For people who do not listen to jazz and with low pollution, the probability of smoking is 33%. For people who do not listen to jazz and with high pollution, the probability of smoking is 65%. For people who listen to jazz and with low pollution, the probability of smoking is 53%. For people who listen to jazz and with high pollution, the probability of smoking is 96%. The overall probability of high pollution is 55%. If we disregard the mediation effect through smoking, would listening to jazz negatively affect lung cancer?\n",
            "Predicted: no (confidence: 0.245)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 48/100 [00:26<00:22,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having a sister is 81%. For infants who do not have a sister, the probability of high infant mortality is 70%. For infants who have a sister, the probability of high infant mortality is 54%. Is high infant mortality less likely than low infant mortality overall?\n",
            "Predicted: no (confidence: 0.514)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 49/100 [00:27<00:22,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For patients who have small kidney stones and do not speak english, the probability of recovery is 86%. For patients who have small kidney stones and speak english, the probability of recovery is 75%. For patients who have large kidney stones and do not speak english, the probability of recovery is 19%. For patients who have large kidney stones and speak english, the probability of recovery is 9%. The overall probability of large kidney stone is 55%. Will speaking english increase the chance of recovery?\n",
            "Predicted: no (confidence: 0.516)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 50/100 [00:27<00:21,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of pexu is 92%. For those who are not pexu, the probability of rukz is 15%. For those who are pexu, the probability of rukz is 35%. Is rukz more likely than not rukz overall?\n",
            "Predicted: no (confidence: 0.581)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 51/100 [00:27<00:20,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having visited England is 22%. For people who have not visited England, the probability of employee being fired is 14%. For people who have visited England, the probability of employee being fired is 76%. Is employee being fired less likely than employee not being fired overall?\n",
            "Predicted: no (confidence: 0.832)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 52/100 [00:28<00:20,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that hwax causes not jyka and gyzp. jyka and gyzp causes lirg. We observed an individual is hwax. Would an individual is lirg if jyka instead of not jyka?\n",
            "Predicted: yes (confidence: 0.199)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 53/100 [00:28<00:21,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For children with unintelligent parents and with low parental social status, the probability of intelligent child is 60%. For children with unintelligent parents and with high parental social status, the probability of intelligent child is 65%. For children with intelligent parents and with low parental social status, the probability of intelligent child is 29%. For children with intelligent parents and with high parental social status, the probability of intelligent child is 22%. For children with unintelligent parents and confounder inactive, the probability of high parental social status is 72%. For children with unintelligent parents and confounder active, the probability of high parental social status is 41%. For children with intelligent parents and confounder inactive, the probability of high parental social status is 35%. For children with intelligent parents and confounder active, the probability of high parental social status is 12%. The overall probability of confounder active is 52%. If we disregard the mediation effect through parents' social status, would parents' intelligence positively affect child's intelligence?\n",
            "Predicted: no (confidence: 0.941)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 54/100 [00:29<00:20,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having a brother is 88%. For people who do not have a brother, the probability of high salary is 12%. For people who have a brother, the probability of high salary is 26%. Is high salary more likely than low salary overall?\n",
            "Predicted: no (confidence: 0.551)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 55/100 [00:29<00:20,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For nonsmokers and with no tar deposit, the probability of lung cancer is 34%. For nonsmokers and with high tar deposit, the probability of lung cancer is 59%. For smokers and with no tar deposit, the probability of lung cancer is 42%. For smokers and with high tar deposit, the probability of lung cancer is 69%. For nonsmokers, the probability of high tar deposit is 25%. For smokers, the probability of high tar deposit is 78%. For smokers, would it be less likely to see lung cancer if the person had been a nonsmoker?\n",
            "Predicted: no (confidence: 0.945)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 56/100 [00:30<00:19,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 14%. For those who are not jyka, the probability of lirg is 85%. For those who are jyka, the probability of lirg is 84%. Is lirg more likely than not lirg overall?\n",
            "Predicted: no (confidence: 0.707)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 57/100 [00:30<00:19,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For nonsmokers, the probability of high tar deposit is 56%. For smokers, the probability of high tar deposit is 83%. For nonsmokers and with no tar deposit, the probability of lung cancer is 42%. For nonsmokers and with high tar deposit, the probability of lung cancer is 83%. For smokers and with no tar deposit, the probability of lung cancer is 48%. For smokers and with high tar deposit, the probability of lung cancer is 74%. The overall probability of smoking is 45%. Does smoking negatively affect lung cancer through tar deposit?\n",
            "Predicted: no (confidence: 0.814)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 58/100 [00:31<00:19,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how drug taken correlates with freckles in general. Method 2: We look at this correlation case by case according to unobserved confounders. To understand how drug taken affects freckles, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.434)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 59/100 [00:31<00:19,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For infants with nonsmoking mothers, the probability of high infant mortality is 79%. For infants with smoking mothers, the probability of high infant mortality is 52%. For infants with smoking mothers, would it be more likely to see high infant mortality if the infant had a nonsmoking mother?\n",
            "Predicted: no (confidence: 0.696)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 60/100 [00:32<00:19,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of alarm set by husband is 88%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 71%. Is ringing alarm less likely than silent alarm overall?\n",
            "Predicted: no (confidence: 0.905)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 61/100 [00:32<00:20,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For individuals who are not male and applicants to a non-competitive department, the probability of admission acceptance is 85%. For individuals who are not male and applicants to a competitive department, the probability of admission acceptance is 62%. For individuals who are male and applicants to a non-competitive department, the probability of admission acceptance is 87%. For individuals who are male and applicants to a competitive department, the probability of admission acceptance is 56%. For individuals who are not male and out-of-state residents, the probability of competitive department is 86%. For individuals who are not male and in-state residents, the probability of competitive department is 45%. For individuals who are male and out-of-state residents, the probability of competitive department is 85%. For individuals who are male and in-state residents, the probability of competitive department is 46%. The overall probability of in-state residency is 95%. If we disregard the mediation effect through department competitiveness, would gender positively affect admission status?\n",
            "Predicted: yes (confidence: 0.016)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 62/100 [00:33<00:20,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For individuals who do not like spicy food and blue-collar workers, the probability of high salary is 70%. For individuals who do not like spicy food and white-collar workers, the probability of high salary is 48%. For individuals who like spicy food and blue-collar workers, the probability of high salary is 44%. For individuals who like spicy food and white-collar workers, the probability of high salary is 17%. For individuals who do not like spicy food and with low skill levels, the probability of white-collar job is 74%. For individuals who do not like spicy food and with high skill levels, the probability of white-collar job is 45%. For individuals who like spicy food and with low skill levels, the probability of white-collar job is 49%. For individuals who like spicy food and with high skill levels, the probability of white-collar job is 18%. The overall probability of high skill level is 95%. If we disregard the mediation effect through occupation, would liking spicy food negatively affect salary?\n",
            "Predicted: no (confidence: 0.798)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 63/100 [00:33<00:20,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of yomx is 21%. The probability of not yomx and xevu is 31%. The probability of yomx and xevu is 17%. Is the chance of xevu smaller when observing yomx?\n",
            "Predicted: no (confidence: 0.947)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 64/100 [00:34<00:19,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of speaking english is 98%. For people who do not speak english and are not famous, the probability of talent is 94%. For people who do not speak english and are famous, the probability of talent is 81%. For people who speak english and are not famous, the probability of talent is 91%. For people who speak english and are famous, the probability of talent is 74%. If we look at people who are famous, does the chance of talent decrease when speaking english?\n",
            "Predicted: no (confidence: 0.372)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 65/100 [00:35<00:19,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people with nonsmoking genes and nonsmokers, the probability of lung cancer is 76%. For people with nonsmoking genes and smokers, the probability of lung cancer is 60%. For people with smoking genes and nonsmokers, the probability of lung cancer is 61%. For people with smoking genes and smokers, the probability of lung cancer is 34%. For people with nonsmoking genes and with low pollution, the probability of smoking is 97%. For people with nonsmoking genes and with high pollution, the probability of smoking is 67%. For people with smoking genes and with low pollution, the probability of smoking is 53%. For people with smoking genes and with high pollution, the probability of smoking is 24%. The overall probability of high pollution is 16%. If we disregard the mediation effect through smoking, would gene negatively affect lung cancer?\n",
            "Predicted: no (confidence: 0.207)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 66/100 [00:35<00:17,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For patients who are young and pay a low hospital bill, the probability of freckles is 2%. For patients who are young and pay a high hospital bill, the probability of freckles is 17%. For patients who are old and pay a low hospital bill, the probability of freckles is 81%. For patients who are old and pay a high hospital bill, the probability of freckles is 96%. The overall probability of old age is 45%. Will high hospital bill decrease the chance of freckles?\n",
            "Predicted: no (confidence: 0.987)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 67/100 [00:35<00:16,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 13%. For those who are not jyka, the probability of kwox is 36%. For those who are jyka, the probability of kwox is 49%. Is kwox less likely than not kwox overall?\n",
            "Predicted: no (confidence: 0.733)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 68/100 [00:36<00:15,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of yupt is 83%. For those who are not yupt, the probability of muvq is 70%. For those who are yupt, the probability of muvq is 77%. Is muvq less likely than not muvq overall?\n",
            "Predicted: no (confidence: 0.203)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 69/100 [00:36<00:14,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of male gender is 11%. For individuals who are not male, the probability of being lactose intolerant is 88%. For individuals who are male, the probability of being lactose intolerant is 13%. Is being lactose intolerant more likely than not being lactose intolerant overall?\n",
            "Predicted: no (confidence: 0.286)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 70/100 [00:37<00:13,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how zuph correlates with uvzi in general. Method 2: We look at this correlation case by case according to wibl. To understand how zuph affects uvzi, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.683)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 71/100 [00:37<00:12,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of college degree or higher is 19%. For people without a college degree, the probability of high salary is 42%. For people with a college degree or higher, the probability of high salary is 63%. Is high salary more likely than low salary overall?\n",
            "Predicted: no (confidence: 0.731)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 72/100 [00:37<00:11,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people with nonsmoking genes, the probability of lung cancer is 43%. For people with smoking genes, the probability of lung cancer is 58%. Will smoking gene decrease the chance of lung cancer?\n",
            "Predicted: no (confidence: 0.477)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 73/100 [00:38<00:11,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of rixq is 62%. The probability of not rixq and xevu is 20%. The probability of rixq and xevu is 31%. Is the chance of xevu smaller when observing rixq?\n",
            "Predicted: no (confidence: 0.459)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 74/100 [00:38<00:10,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having a sister is 99%. For people who do not have a sister, the probability of lung cancer is 27%. For people who have a sister, the probability of lung cancer is 57%. Is lung cancer less likely than absence of lung cancer overall?\n",
            "Predicted: no (confidence: 0.621)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 75/100 [00:39<00:10,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that tijw causes xevo. xevo causes tijv. tijw or tijv causes gyzp. We observed an individual is tijw. Would an individual is gyzp if not xevo instead of xevo?\n",
            "Predicted: yes (confidence: 0.147)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 76/100 [00:39<00:10,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how hospital costs correlates with recovery in general. Method 2: We look at this correlation case by case according to age. To understand how hospital costs affects recovery, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.722)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 77/100 [00:40<00:09,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of zuph is 88%. For those who are not zuph, the probability of glimx is 84%. For those who are zuph, the probability of glimx is 70%. Is glimx more likely than not glimx overall?\n",
            "Predicted: no (confidence: 0.168)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 78/100 [00:40<00:09,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of pexu is 68%. For those who are not pexu, the probability of rukz is 78%. For those who are pexu, the probability of rukz is 79%. Is rukz more likely than not rukz overall?\n",
            "Predicted: no (confidence: 0.665)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 79/100 [00:40<00:09,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For normal weight people and without diabetes, the probability of long lifespan is 23%. For normal weight people and with diabetes, the probability of long lifespan is 51%. For obese people and without diabetes, the probability of long lifespan is 52%. For obese people and with diabetes, the probability of long lifespan is 75%. For normal weight people and nonsmokers, the probability of having diabetes is 80%. For normal weight people and smokers, the probability of having diabetes is 58%. For obese people and nonsmokers, the probability of having diabetes is 51%. For obese people and smokers, the probability of having diabetes is 22%. The overall probability of smoker is 88%. Does obesity negatively affect lifespan through diabetes?\n",
            "Predicted: no (confidence: 0.773)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 80/100 [00:41<00:08,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not yomx, the probability of xevu is 76%. For those who are yomx, the probability of xevu is 84%. For those who are yomx, would it be less likely to see xevu if the individual was not yomx?\n",
            "Predicted: no (confidence: 0.547)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 81/100 [00:41<00:08,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For patients who have small kidney stones and not receiving treatment, the probability of thick lips is 6%. For patients who have small kidney stones and receiving treatment, the probability of thick lips is 38%. For patients who have large kidney stones and not receiving treatment, the probability of thick lips is 63%. For patients who have large kidney stones and receiving treatment, the probability of thick lips is 95%. The overall probability of large kidney stone is 50%. For patients receiving treatment, would it be more likely to see thick lips if the patient had received no treatment?\n",
            "Predicted: no (confidence: 0.989)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 82/100 [00:42<00:07,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look at how xevo correlates with gyzp case by case according to tijw. Method 2: We look directly at how xevo correlates with gyzp in general. To understand how xevo affects gyzp, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.927)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 83/100 [00:42<00:07,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not yomx, the probability of xevu is 70%. For those who are yomx, the probability of xevu is 60%. Does yomx positively affect xevu through gwet?\n",
            "Predicted: no (confidence: 0.494)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 84/100 [00:43<00:06,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 40%. The probability of not jyka and lirg is 3%. The probability of jyka and lirg is 11%. Is the chance of lirg larger when observing jyka?\n",
            "Predicted: no (confidence: 0.983)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 85/100 [00:43<00:06,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For infants who do not have a sister and low infant birth weight, the probability of high infant mortality is 32%. For infants who do not have a sister and normal infant birth weight, the probability of high infant mortality is 73%. For infants who have a sister and low infant birth weight, the probability of high infant mortality is 4%. For infants who have a sister and normal infant birth weight, the probability of high infant mortality is 37%. For infants who do not have a sister and with poor health, the probability of normal infant birth weight is 55%. For infants who do not have a sister and with good health, the probability of normal infant birth weight is 24%. For infants who have a sister and with poor health, the probability of normal infant birth weight is 83%. For infants who have a sister and with good health, the probability of normal infant birth weight is 57%. The overall probability of good health is 6%. Does having a sister negatively affect infant mortality through infant's birth weight?\n",
            "Predicted: no (confidence: 0.155)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 86/100 [00:44<00:06,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of the captain's order to execute the prisoner is 59%. For captains who release prisoners, the probability of the prisoner's death is 33%. For captains who execute prisoners, the probability of the prisoner's death is 56%. Is the prisoner's death less likely than the prisoner being alive overall?\n",
            "Predicted: no (confidence: 0.915)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 87/100 [00:44<00:05,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not tijv and are not xevo, the probability of gyzp is 15%. For those who are not tijv and are xevo, the probability of gyzp is 30%. For those who are tijv and are not xevo, the probability of gyzp is 15%. For those who are tijv and are xevo, the probability of gyzp is 66%. The overall probability of tijv is 79%. Will xevo increase the chance of gyzp?\n",
            "Predicted: no (confidence: 0.988)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 88/100 [00:44<00:05,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of yupt is 83%. The probability of not yupt and muvq is 4%. The probability of yupt and muvq is 77%. Is the chance of muvq larger when observing yupt?\n",
            "Predicted: no (confidence: 0.810)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 89/100 [00:45<00:05,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how appearance correlates with talent in general. Method 2: We look at this correlation case by case according to fame. To understand how appearance affects talent, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.266)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 90/100 [00:45<00:04,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For nonsmokers, the probability of lung cancer is 34%. For smokers, the probability of lung cancer is 51%. Will smoking increase the chance of lung cancer?\n",
            "Predicted: no (confidence: 0.939)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 91/100 [00:46<00:04,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look at how talent correlates with effort case by case according to elite institution admission status. Method 2: We look directly at how talent correlates with effort in general. To understand how talent affects effort, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no (confidence: 0.857)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 92/100 [00:46<00:03,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of smoking is 48%. For nonsmokers, the probability of being allergic to peanuts is 50%. For smokers, the probability of being allergic to peanuts is 51%. Is being allergic to peanuts less likely than not being allergic to peanuts overall?\n",
            "Predicted: no (confidence: 0.753)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 93/100 [00:47<00:03,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not have a sister and with low blood pressure, the probability of healthy heart is 61%. For people who do not have a sister and with high blood pressure, the probability of healthy heart is 92%. For people who have a sister and with low blood pressure, the probability of healthy heart is 18%. For people who have a sister and with high blood pressure, the probability of healthy heart is 45%. For people who do not have a sister, the probability of high blood pressure is 61%. For people who have a sister, the probability of high blood pressure is 14%. Does having a sister positively affect heart condition through blood pressure?\n",
            "Predicted: no (confidence: 0.378)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 94/100 [00:48<00:03,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that blowing out the candle and candle with wax causes dark room. We observed the candle is out of wax. Would the room is bright if blowing out the candle instead of not blowing out the candle?\n",
            "Predicted: yes (confidence: 0.026)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 95/100 [00:48<00:02,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For children with unintelligent parents, the probability of intelligent child is 42%. For children with intelligent parents, the probability of intelligent child is 56%. For children with intelligent parents, would it be less likely to see intelligent child if the child had unintelligent parents?\n",
            "Predicted: no (confidence: 0.985)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 96/100 [00:48<00:01,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of receives treatment is 56%. The probability of receives no treatment and being allergic to peanuts is 8%. The probability of receives treatment and being allergic to peanuts is 36%. Is the chance of being allergic to peanuts larger when observing receives treatment?\n",
            "Predicted: no (confidence: 0.917)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 97/100 [00:49<00:01,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that speaking english and smoker causes having diabetes. speaking english and smoker and having diabetes causes long lifespan. We observed the person is a smoker. Would the person has a long lifespan if not speaking english instead of speaking english?\n",
            "Predicted: yes (confidence: 0.009)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 98/100 [00:49<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of smoking mother is 15%. For infants with nonsmoking mothers, the probability of normal infant birth weight is 7%. For infants with smoking mothers, the probability of normal infant birth weight is 47%. Is normal infant birth weight more likely than low infant birth weight overall?\n",
            "Predicted: no (confidence: 0.953)\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 99/100 [00:50<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of manager signing the termination letter is 30%. For managers who don't sign termination letters, the probability of large feet is 73%. For managers who sign termination letters, the probability of large feet is 25%. Is large feet more likely than small feet overall?\n",
            "Predicted: no (confidence: 0.537)\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 100/100 [00:50<00:00,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not yomx, the probability of xevu is 36%. For those who are yomx, the probability of xevu is 38%. For those who are yomx, would it be less likely to see xevu if the individual was not yomx?\n",
            "Predicted: no (confidence: 0.558)\n",
            "Ground truth: yes\n",
            "\n",
            "Final Results:\n",
            "accuracy: 0.4400\n",
            "f1: 0.0968\n",
            "precision: 0.4286\n",
            "recall: 0.0545\n",
            "brier_score: 0.3299\n",
            "ece: 0.2653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, log_loss\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def calculate_perplexity(model, tokenizer, input_text, device):\n",
        "    \"\"\"Calculate perplexity for a given input text.\"\"\"\n",
        "    try:\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, labels=inputs.input_ids)\n",
        "            neg_log_likelihood = outputs.loss\n",
        "            return torch.exp(neg_log_likelihood).item()\n",
        "    except Exception as e:\n",
        "        print(f\"Perplexity calculation error: {str(e)}\")\n",
        "        return float('inf')\n",
        "\n",
        "def calculate_kl_divergence(p_probs, q_probs):\n",
        "    \"\"\"Calculate KL divergence between two probability distributions.\"\"\"\n",
        "    p = np.array([p_probs, 1 - p_probs])\n",
        "    q = np.array([q_probs, 1 - q_probs])\n",
        "    return float(entropy(p, q))\n",
        "\n",
        "def get_binary_prediction(model, tokenizer, input_text, device):\n",
        "    \"\"\"Generate a binary yes/no prediction with detailed confidence scores and metrics.\"\"\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Calculate perplexity first\n",
        "        perplexity = calculate_perplexity(model, tokenizer, input_text, device)\n",
        "\n",
        "        # Generate the response\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_new_tokens=10,\n",
        "            num_beams=2,\n",
        "            do_sample=False,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        # Get the predicted answer\n",
        "        predicted_tokens = outputs.sequences[0][inputs.input_ids.shape[1]:]\n",
        "        predicted_answer = tokenizer.decode(predicted_tokens, skip_special_tokens=True).strip().lower()\n",
        "\n",
        "        # Calculate probabilities for yes/no\n",
        "        last_token_logits = outputs.scores[-1][0].float()\n",
        "        yes_token_ids = tokenizer.encode(\" yes\", add_special_tokens=False)\n",
        "        no_token_ids = tokenizer.encode(\" no\", add_special_tokens=False)\n",
        "\n",
        "        # Get average logits for yes/no tokens\n",
        "        yes_logit = last_token_logits[yes_token_ids].mean()\n",
        "        no_logit = last_token_logits[no_token_ids].mean()\n",
        "\n",
        "        # Convert to probabilities using softmax\n",
        "        logits = torch.tensor([yes_logit, no_logit], device=device)\n",
        "        probs = torch.nn.functional.softmax(logits, dim=0)\n",
        "\n",
        "        # Calculate entropy-based uncertainty\n",
        "        probs_np = probs.cpu().numpy()\n",
        "        uncertainty = entropy([probs_np[0], probs_np[1]], base=2) / np.log2(2)\n",
        "\n",
        "        # Determine confidence level categories\n",
        "        confidence = float(probs[0] if predicted_answer.startswith('yes') else probs[1])\n",
        "        if confidence >= 0.9:\n",
        "            confidence_level = \"Very High\"\n",
        "        elif confidence >= 0.7:\n",
        "            confidence_level = \"High\"\n",
        "        elif confidence >= 0.5:\n",
        "            confidence_level = \"Moderate\"\n",
        "        else:\n",
        "            confidence_level = \"Low\"\n",
        "\n",
        "        return {\n",
        "            'prediction': 'yes' if predicted_answer.startswith('yes') else 'no',\n",
        "            'confidence': confidence,\n",
        "            'confidence_level': confidence_level,\n",
        "            'uncertainty': float(uncertainty),\n",
        "            'yes_prob': float(probs[0]),\n",
        "            'no_prob': float(probs[1]),\n",
        "            'perplexity': perplexity,\n",
        "            'logits': {\n",
        "                'yes': float(yes_logit),\n",
        "                'no': float(no_logit)\n",
        "            }\n",
        "        }\n",
        "\n",
        "def calculate_binary_metrics(predictions, ground_truths):\n",
        "    \"\"\"Calculate comprehensive metrics for binary classification.\"\"\"\n",
        "    pred_labels = [1 if p['prediction'] == 'yes' else 0 for p in predictions]\n",
        "    true_labels = [1 if gt == 'yes' else 0 for gt in ground_truths]\n",
        "    confidences = [p['confidence'] for p in predictions]\n",
        "    yes_probs = [p['yes_prob'] for p in predictions]\n",
        "\n",
        "    # Basic classification metrics\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(true_labels, pred_labels),\n",
        "        'f1': f1_score(true_labels, pred_labels),\n",
        "        'precision': precision_score(true_labels, pred_labels),\n",
        "        'recall': recall_score(true_labels, pred_labels),\n",
        "        'roc_auc': roc_auc_score(true_labels, yes_probs),\n",
        "        'brier_score': np.mean([(c - t)**2 for c, t in zip(confidences, true_labels)]),\n",
        "        'log_loss': log_loss(true_labels, yes_probs),\n",
        "    }\n",
        "\n",
        "    # Perplexity statistics\n",
        "    perplexities = [p['perplexity'] for p in predictions]\n",
        "    metrics['perplexity'] = {\n",
        "        'mean': np.mean(perplexities),\n",
        "        'std': np.std(perplexities),\n",
        "        'min': np.min(perplexities),\n",
        "        'max': np.max(perplexities)\n",
        "    }\n",
        "\n",
        "    # Confidence analysis\n",
        "    confidence_levels = [p['confidence_level'] for p in predictions]\n",
        "    metrics['confidence_distribution'] = {\n",
        "        'Very High': confidence_levels.count('Very High') / len(confidence_levels),\n",
        "        'High': confidence_levels.count('High') / len(confidence_levels),\n",
        "        'Moderate': confidence_levels.count('Moderate') / len(confidence_levels),\n",
        "        'Low': confidence_levels.count('Low') / len(confidence_levels)\n",
        "    }\n",
        "\n",
        "    # Calibration metrics\n",
        "    n_bins = 10\n",
        "    bins = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_indices = np.digitize(confidences, bins) - 1\n",
        "\n",
        "    ece = 0.0  # Expected Calibration Error\n",
        "    mce = 0.0  # Maximum Calibration Error\n",
        "\n",
        "    for bin_idx in range(n_bins):\n",
        "        mask = bin_indices == bin_idx\n",
        "        if mask.any():\n",
        "            bin_conf = np.mean([c for c, m in zip(confidences, mask) if m])\n",
        "            bin_acc = np.mean([1 if p == t else 0\n",
        "                             for p, t, m in zip(pred_labels, true_labels, mask) if m])\n",
        "            bin_size = np.mean(mask)\n",
        "\n",
        "            calibration_error = np.abs(bin_conf - bin_acc)\n",
        "            ece += calibration_error * bin_size\n",
        "            mce = max(mce, calibration_error)\n",
        "\n",
        "    metrics['calibration'] = {\n",
        "        'ece': float(ece),\n",
        "        'mce': float(mce)\n",
        "    }\n",
        "\n",
        "    # Average metrics by confidence level\n",
        "    for level in ['Very High', 'High', 'Moderate', 'Low']:\n",
        "        level_indices = [i for i, l in enumerate(confidence_levels) if l == level]\n",
        "        if level_indices:\n",
        "            level_pred = [pred_labels[i] for i in level_indices]\n",
        "            level_true = [true_labels[i] for i in level_indices]\n",
        "            metrics[f'{level.lower()}_confidence_accuracy'] = accuracy_score(level_true, level_pred)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate_binary_dataset(model, tokenizer, dataset, device):\n",
        "    \"\"\"Evaluate the model on a dataset with comprehensive metrics.\"\"\"\n",
        "    all_predictions = []\n",
        "    all_ground_truths = []\n",
        "\n",
        "    for sample in tqdm(dataset, desc=\"Evaluating\"):\n",
        "        input_text = f\"Given Info and Question: {sample['input']}\\nAnswer:\"\n",
        "        ground_truth = str(sample['answer']).strip().lower()\n",
        "\n",
        "        try:\n",
        "            prediction = get_binary_prediction(model, tokenizer, input_text, device)\n",
        "            all_predictions.append(prediction)\n",
        "            all_ground_truths.append(ground_truth)\n",
        "\n",
        "            # Print detailed sample results\n",
        "            print(f\"\\nInput: {sample['input']}\")\n",
        "            print(f\"Predicted: {prediction['prediction']}\")\n",
        "            print(f\"Confidence: {prediction['confidence']:.3f} ({prediction['confidence_level']})\")\n",
        "            print(f\"Perplexity: {prediction['perplexity']:.3f}\")\n",
        "            print(f\"Uncertainty: {prediction['uncertainty']:.3f}\")\n",
        "            print(f\"Ground truth: {ground_truth}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing sample: {str(e)}\")\n",
        "\n",
        "    # Calculate all metrics\n",
        "    metrics = calculate_binary_metrics(all_predictions, all_ground_truths)\n",
        "\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Run evaluation\n",
        "results = evaluate_binary_dataset(model, tokenizer, cladder_dataset, device)\n",
        "\n",
        "# Print detailed results\n",
        "print(\"\\nDetailed Evaluation Results:\")\n",
        "for metric_name, value in results.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"\\n{metric_name}:\")\n",
        "        for sub_name, sub_value in value.items():\n",
        "            print(f\"  {sub_name}: {sub_value:.4f}\")\n",
        "    else:\n",
        "        print(f\"{metric_name}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoWVGfxvBj3e",
        "outputId": "4229652d-ed8d-408b-d0d3-3bd9e4eed9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   1%|          | 1/100 [00:00<01:11,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that male gender or in-state residency causes competitive department. male gender or in-state residency or competitive department causes admission acceptance. We observed the resident is in-state. Would the applicant gets rejected if male gender instead of non-male gender?\n",
            "Predicted: yes\n",
            "Confidence: 0.671 (Moderate)\n",
            "Perplexity: 66.625\n",
            "Uncertainty: 0.914\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 2/100 [00:01<01:04,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of talent is 82%. For students who are not talented and rejected from elite institutions, the probability of being hard-working is 99%. For students who are not talented and accepted to elite institutions, the probability of being hard-working is 82%. For students who are talented and rejected from elite institutions, the probability of being hard-working is 96%. For students who are talented and accepted to elite institutions, the probability of being hard-working is 53%. If we look at students accepted to elite institutions, does the chance of being hard-working decrease when talent?\n",
            "Predicted: no\n",
            "Confidence: 0.576 (Moderate)\n",
            "Perplexity: 6.801\n",
            "Uncertainty: 0.983\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 3/100 [00:01<01:02,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of pexu is 83%. For those who are not pexu, the probability of rukz is 81%. For those who are pexu, the probability of rukz is 81%. Is rukz less likely than not rukz overall?\n",
            "Predicted: no\n",
            "Confidence: 0.719 (High)\n",
            "Perplexity: 18.250\n",
            "Uncertainty: 0.857\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 4/100 [00:02<01:03,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not tijv and are not xevo, the probability of gyzp is 43%. For those who are not tijv and are xevo, the probability of gyzp is 13%. For those who are tijv and are not xevo, the probability of gyzp is 55%. For those who are tijv and are xevo, the probability of gyzp is 73%. The overall probability of tijv is 31%. For those who are xevo, would it be more likely to see gyzp if the individual was not xevo?\n",
            "Predicted: no\n",
            "Confidence: 0.984 (Very High)\n",
            "Perplexity: 6.723\n",
            "Uncertainty: 0.116\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 5/100 [00:03<01:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not zuph, the probability of glimx is 70%. For those who are zuph, the probability of glimx is 72%. For those who are zuph, would it be more likely to see glimx if the individual was not zuph?\n",
            "Predicted: no\n",
            "Confidence: 0.871 (High)\n",
            "Perplexity: 17.141\n",
            "Uncertainty: 0.555\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 6/100 [00:03<00:59,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how zuph correlates with glimx in general. Method 2: We look at this correlation case by case according to zory. To understand how zuph affects glimx, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.551 (Moderate)\n",
            "Perplexity: 60.906\n",
            "Uncertainty: 0.993\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 7/100 [00:04<00:58,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not hwax and are not pexu, the probability of rukz is 15%. For those who are not hwax and are pexu, the probability of rukz is 16%. For those who are hwax and are not pexu, the probability of rukz is 18%. For those who are hwax and are pexu, the probability of rukz is 16%. The overall probability of hwax is 71%. Will pexu decrease the chance of rukz?\n",
            "Predicted: no\n",
            "Confidence: 0.993 (Very High)\n",
            "Perplexity: 6.664\n",
            "Uncertainty: 0.057\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 8/100 [00:05<00:58,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people with no pre-conditions and refusing the vaccine, the probability of recovering from the disease is 7%. For people with no pre-conditions and getting the vaccine, the probability of recovering from the disease is 37%. For people with pre-conditions and refusing the vaccine, the probability of recovering from the disease is 65%. For people with pre-conditions and getting the vaccine, the probability of recovering from the disease is 96%. The overall probability of pre-conditions is 41%. Will getting the vaccine decrease the chance of recovering from the disease?\n",
            "Predicted: no\n",
            "Confidence: 0.957 (Very High)\n",
            "Perplexity: 5.699\n",
            "Uncertainty: 0.258\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 9/100 [00:05<01:02,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 51%. For those who are not jyka, the probability of kwox is 49%. For those who are jyka, the probability of kwox is 80%. Is kwox less likely than not kwox overall?\n",
            "Predicted: no\n",
            "Confidence: 0.691 (Moderate)\n",
            "Perplexity: 17.969\n",
            "Uncertainty: 0.892\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 10/100 [00:06<01:02,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 54%. The probability of not jyka and lirg is 16%. The probability of jyka and lirg is 19%. Is the chance of lirg smaller when observing jyka?\n",
            "Predicted: no\n",
            "Confidence: 0.987 (Very High)\n",
            "Perplexity: 23.484\n",
            "Uncertainty: 0.103\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 11/100 [00:07<01:03,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how having a sister correlates with prisoner in general. Method 2: We look at this correlation case by case according to the private. To understand how having a sister affects prisoner, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.973 (Very High)\n",
            "Perplexity: 43.875\n",
            "Uncertainty: 0.180\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 12/100 [00:08<01:02,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not have a sister and with low blood pressure, the probability of healthy heart is 40%. For people who do not have a sister and with high blood pressure, the probability of healthy heart is 69%. For people who have a sister and with low blood pressure, the probability of healthy heart is 7%. For people who have a sister and with high blood pressure, the probability of healthy heart is 44%. For people who do not have a sister, the probability of high blood pressure is 54%. For people who have a sister, the probability of high blood pressure is 28%. Does having a sister negatively affect heart condition through blood pressure?\n",
            "Predicted: no\n",
            "Confidence: 0.984 (Very High)\n",
            "Perplexity: 4.637\n",
            "Uncertainty: 0.117\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 13/100 [00:08<00:55,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of male gender is 48%. For individuals who are not male, the probability of high salary is 53%. For individuals who are male, the probability of high salary is 78%. Is high salary more likely than low salary overall?\n",
            "Predicted: no\n",
            "Confidence: 0.145 (Low)\n",
            "Perplexity: 17.688\n",
            "Uncertainty: 0.597\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 14/100 [00:09<00:50,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that hwax causes pexu and kraz. pexu or kraz causes rukz. We observed an individual is not hwax. Would an individual is rukz if not pexu instead of pexu?\n",
            "Predicted: no\n",
            "Confidence: 0.846 (High)\n",
            "Perplexity: 62.844\n",
            "Uncertainty: 0.620\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 15/100 [00:09<00:46,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of kwox is 73%. For those who are not kwox, the probability of kwoz is 56%. For those who are kwox, the probability of kwoz is 56%. Is kwoz more likely than not kwoz overall?\n",
            "Predicted: no\n",
            "Confidence: 0.871 (High)\n",
            "Perplexity: 15.219\n",
            "Uncertainty: 0.556\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 16/100 [00:10<00:46,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For husbands that don't set the alarm, the probability of ringing alarm is 74%. For husbands that set the alarm, the probability of ringing alarm is 21%. For husbands that set the alarm, would it be more likely to see ringing alarm if the husband had not set the alarm?\n",
            "Predicted: no\n",
            "Confidence: 0.982 (Very High)\n",
            "Perplexity: 14.133\n",
            "Uncertainty: 0.132\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 17/100 [00:10<00:44,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of drinking coffee is 47%. The probability of not drinking coffee and high salary is 18%. The probability of drinking coffee and high salary is 41%. Is the chance of high salary smaller when observing drinking coffee?\n",
            "Predicted: no\n",
            "Confidence: 0.992 (Very High)\n",
            "Perplexity: 24.516\n",
            "Uncertainty: 0.066\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 18/100 [00:11<00:45,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not have a sister, the probability of lung cancer is 33%. For people who have a sister, the probability of lung cancer is 73%. For people who have a sister, would it be more likely to see lung cancer if the person did not have a sister?\n",
            "Predicted: no\n",
            "Confidence: 0.998 (Very High)\n",
            "Perplexity: 10.359\n",
            "Uncertainty: 0.018\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 19/100 [00:11<00:44,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that hwax causes pexu and kraz. pexu and kraz causes rukz. We observed an individual is hwax. Would an individual is rukz if not pexu instead of pexu?\n",
            "Predicted: no\n",
            "Confidence: 0.841 (High)\n",
            "Perplexity: 61.156\n",
            "Uncertainty: 0.631\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 20/100 [00:12<00:44,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of pexu is 95%. For those who are not pexu, the probability of rukz is 85%. For those who are pexu, the probability of rukz is 74%. Is rukz more likely than not rukz overall?\n",
            "Predicted: no\n",
            "Confidence: 0.657 (Moderate)\n",
            "Perplexity: 17.547\n",
            "Uncertainty: 0.928\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 21/100 [00:12<00:44,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of rainy season is 28%. For people in the dry season, the probability of wet ground is 39%. For in the rainy season, the probability of wet ground is 46%. Is wet ground less likely than dry ground overall?\n",
            "Predicted: no\n",
            "Confidence: 0.820 (High)\n",
            "Perplexity: 20.844\n",
            "Uncertainty: 0.680\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 22/100 [00:13<00:46,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not rixq and are not swoy, the probability of xevu is 62%. For those who are not rixq and are swoy, the probability of xevu is 9%. For those who are rixq and are not swoy, the probability of xevu is 15%. For those who are rixq and are swoy, the probability of xevu is 59%. For those who are not rixq, the probability of swoy is 16%. For those who are rixq, the probability of swoy is 13%. For those who are rixq, would it be more likely to see xevu if the individual was not rixq?\n",
            "Predicted: no\n",
            "Confidence: 0.957 (Very High)\n",
            "Perplexity: 5.152\n",
            "Uncertainty: 0.257\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 23/100 [00:13<00:42,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people in a relationship, the correlation between kindness and freckles is -0.08. If we look at people in a relationship, does it mean that kindness does not affect freckles?\n",
            "Predicted: no\n",
            "Confidence: 1.000 (Very High)\n",
            "Perplexity: 23.484\n",
            "Uncertainty: 0.006\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 24/100 [00:14<00:40,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of receives treatment is 49%. The probability of receives no treatment and recovery is 20%. The probability of receives treatment and recovery is 33%. Is the chance of recovery larger when observing receives treatment?\n",
            "Predicted: no\n",
            "Confidence: 0.711 (High)\n",
            "Perplexity: 34.969\n",
            "Uncertainty: 0.868\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 25/100 [00:14<00:38,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For situations where there is no solar eclipse, the probability of arriving to school on time is 74%. For situations where there is a solar eclipse, the probability of arriving to school on time is 30%. Will solar eclipse increase the chance of arriving to school on time?\n",
            "Predicted: no\n",
            "Confidence: 0.993 (Very High)\n",
            "Perplexity: 11.133\n",
            "Uncertainty: 0.057\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 26/100 [00:15<00:36,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how treatment correlates with recovery in general. Method 2: We look at this correlation case by case according to kidney stone size. To understand how treatment affects recovery, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.350 (Low)\n",
            "Perplexity: 42.344\n",
            "Uncertainty: 0.934\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 27/100 [00:15<00:35,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of receives treatment is 64%. For patients not receiving treatment, the probability of thick lips is 80%. For patients receiving treatment, the probability of thick lips is 51%. Is thick lips more likely than thin lips overall?\n",
            "Predicted: no\n",
            "Confidence: 0.950 (Very High)\n",
            "Perplexity: 25.094\n",
            "Uncertainty: 0.285\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 28/100 [00:16<00:34,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look at how smoking correlates with lung cancer case by case according to tar deposit. Method 2: We look directly at how smoking correlates with lung cancer in general. To understand how smoking affects lung cancer, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.880 (High)\n",
            "Perplexity: 28.547\n",
            "Uncertainty: 0.529\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 29/100 [00:16<00:33,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that zory causes zuph. zuph causes jyka. zory and jyka causes glimx. We observed an individual is zory. Would an individual is glimx if zuph instead of not zuph?\n",
            "Predicted: no\n",
            "Confidence: 0.920 (Very High)\n",
            "Perplexity: 81.938\n",
            "Uncertainty: 0.402\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 30/100 [00:17<00:32,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that pexu causes hwax and not kraz. hwax or kraz causes rukz. Would an individual is not rukz if pexu instead of not pexu?\n",
            "Predicted: no\n",
            "Confidence: 0.979 (Very High)\n",
            "Perplexity: 83.250\n",
            "Uncertainty: 0.150\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 31/100 [00:17<00:34,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who have not visited England and directors who don't sign termination letters, the probability of employee being fired is 9%. For people who have not visited England and directors who sign termination letters, the probability of employee being fired is 54%. For people who have visited England and directors who don't sign termination letters, the probability of employee being fired is 46%. For people who have visited England and directors who sign termination letters, the probability of employee being fired is 90%. For people who have not visited England, the probability of director signing the termination letter is 17%. For people who have visited England, the probability of director signing the termination letter is 27%. For people who have visited England, would it be less likely to see employee being fired if the person had not visited England?\n",
            "Predicted: no\n",
            "Confidence: 0.975 (Very High)\n",
            "Perplexity: 4.965\n",
            "Uncertainty: 0.167\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 32/100 [00:18<00:35,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not yomx and are not gwet, the probability of xevu is 32%. For those who are not yomx and are gwet, the probability of xevu is 44%. For those who are yomx and are not gwet, the probability of xevu is 38%. For those who are yomx and are gwet, the probability of xevu is 50%. For those who are not yomx, the probability of gwet is 54%. For those who are yomx, the probability of gwet is 69%. For those who are yomx, would it be more likely to see xevu if the individual was not yomx?\n",
            "Predicted: no\n",
            "Confidence: 0.260 (Low)\n",
            "Perplexity: 5.160\n",
            "Uncertainty: 0.826\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 33/100 [00:18<00:33,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that smoking causes high tar deposit, and we know that high tar deposit causes absence of lung cancer. Would the person has lung cancer if nonsmoking instead of smoking?\n",
            "Predicted: yes\n",
            "Confidence: 0.475 (Low)\n",
            "Perplexity: 36.031\n",
            "Uncertainty: 0.998\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 34/100 [00:19<00:32,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not have a sister, the probability of the prisoner's death is 20%. For people who have a sister, the probability of the prisoner's death is 69%. For people who have a sister, would it be less likely to see the prisoner's death if the person did not have a sister?\n",
            "Predicted: no\n",
            "Confidence: 0.959 (Very High)\n",
            "Perplexity: 11.008\n",
            "Uncertainty: 0.245\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 35/100 [00:19<00:32,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For days when Alice wakes up on time, the probability of arriving to school on time is 56%. For days when Alice wakes up late, the probability of arriving to school on time is 18%. For days when Alice wakes up late, would it be more likely to see arriving to school on time if Alice had gotten up on time?\n",
            "Predicted: no\n",
            "Confidence: 0.703 (High)\n",
            "Perplexity: 13.117\n",
            "Uncertainty: 0.878\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 36/100 [00:20<00:30,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having a brother is 41%. The probability of not having a brother and recovery is 42%. The probability of having a brother and recovery is 10%. Is the chance of recovery smaller when observing having a brother?\n",
            "Predicted: no\n",
            "Confidence: 0.955 (Very High)\n",
            "Perplexity: 23.812\n",
            "Uncertainty: 0.263\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 37/100 [00:20<00:30,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For CEOs who fire employees and managers who don't sign termination letters, the probability of large feet is 52%. For CEOs who fire employees and managers who sign termination letters, the probability of large feet is 14%. For CEOs who fire employees and managers who don't sign termination letters, the probability of large feet is 71%. For CEOs who fire employees and managers who sign termination letters, the probability of large feet is 32%. The overall probability of CEO's decision to fire the employee is 98%. Will manager signing the termination letter decrease the chance of large feet?\n",
            "Predicted: no\n",
            "Confidence: 0.970 (Very High)\n",
            "Perplexity: 8.133\n",
            "Uncertainty: 0.192\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 38/100 [00:21<00:29,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of alarm set by husband is 4%. The probability of alarm not set by husband and ringing alarm is 74%. The probability of alarm set by husband and ringing alarm is 1%. Is the chance of ringing alarm larger when observing alarm set by husband?\n",
            "Predicted: no\n",
            "Confidence: 0.711 (High)\n",
            "Perplexity: 25.234\n",
            "Uncertainty: 0.868\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 39/100 [00:21<00:29,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look at how jyka correlates with kwox case by case according to yupt. Method 2: We look directly at how jyka correlates with kwox in general. To understand how jyka affects kwox, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.696 (Moderate)\n",
            "Perplexity: 33.844\n",
            "Uncertainty: 0.886\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 40/100 [00:22<00:28,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that pexu causes not hwax, and we know that hwax causes not rukz. Would an individual is not rukz if pexu instead of not pexu?\n",
            "Predicted: no\n",
            "Confidence: 0.860 (High)\n",
            "Perplexity: 56.125\n",
            "Uncertainty: 0.585\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 41/100 [00:22<00:28,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For areas with low cigarette tax, the probability of normal infant birth weight is 56%. For areas with high cigarette tax, the probability of normal infant birth weight is 67%. For areas with low cigarette tax, the probability of smoking mother is 49%. For areas with high cigarette tax, the probability of smoking mother is 20%. Will smoking mother decrease the chance of normal infant birth weight?\n",
            "Predicted: no\n",
            "Confidence: 0.949 (Very High)\n",
            "Perplexity: 8.406\n",
            "Uncertainty: 0.291\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 42/100 [00:23<00:27,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of talent is 91%. For students who are not talented, the probability of brown eyes is 95%. For students who are talented, the probability of brown eyes is 95%. Is brown eyes less likely than blue eyes overall?\n",
            "Predicted: no\n",
            "Confidence: 0.893 (High)\n",
            "Perplexity: 20.688\n",
            "Uncertainty: 0.490\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 43/100 [00:23<00:29,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not zuph and are not jyka, the probability of glimx is 26%. For those who are not zuph and are jyka, the probability of glimx is 91%. For those who are zuph and are not jyka, the probability of glimx is 14%. For those who are zuph and are jyka, the probability of glimx is 88%. For those who are not zuph, the probability of jyka is 56%. For those who are zuph, the probability of jyka is 4%. For those who are zuph, would it be more likely to see glimx if the individual was not zuph?\n",
            "Predicted: no\n",
            "Confidence: 0.868 (High)\n",
            "Perplexity: 5.391\n",
            "Uncertainty: 0.562\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 44/100 [00:24<00:29,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For infants with nonsmoking mothers, the probability of high infant mortality is 61%. For infants with smoking mothers, the probability of high infant mortality is 32%. Will smoking mother increase the chance of high infant mortality?\n",
            "Predicted: no\n",
            "Confidence: 0.945 (Very High)\n",
            "Perplexity: 16.328\n",
            "Uncertainty: 0.309\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 45/100 [00:24<00:29,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not jyka, the probability of lirg is 56%. For those who are jyka, the probability of lirg is 71%. Will jyka increase the chance of lirg?\n",
            "Predicted: no\n",
            "Confidence: 0.500 (Moderate)\n",
            "Perplexity: 19.094\n",
            "Uncertainty: 1.000\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 46/100 [00:25<00:28,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of yomx is 53%. The probability of not yomx and xevu is 6%. The probability of yomx and xevu is 37%. Is the chance of xevu larger when observing yomx?\n",
            "Predicted: no\n",
            "Confidence: 0.768 (High)\n",
            "Perplexity: 24.469\n",
            "Uncertainty: 0.782\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 47/100 [00:26<00:30,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not listen to jazz and nonsmokers, the probability of lung cancer is 30%. For people who do not listen to jazz and smokers, the probability of lung cancer is 67%. For people who listen to jazz and nonsmokers, the probability of lung cancer is 20%. For people who listen to jazz and smokers, the probability of lung cancer is 63%. For people who do not listen to jazz and with low pollution, the probability of smoking is 33%. For people who do not listen to jazz and with high pollution, the probability of smoking is 65%. For people who listen to jazz and with low pollution, the probability of smoking is 53%. For people who listen to jazz and with high pollution, the probability of smoking is 96%. The overall probability of high pollution is 55%. If we disregard the mediation effect through smoking, would listening to jazz negatively affect lung cancer?\n",
            "Predicted: no\n",
            "Confidence: 0.245 (Low)\n",
            "Perplexity: 4.633\n",
            "Uncertainty: 0.803\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 48/100 [00:26<00:31,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having a sister is 81%. For infants who do not have a sister, the probability of high infant mortality is 70%. For infants who have a sister, the probability of high infant mortality is 54%. Is high infant mortality less likely than low infant mortality overall?\n",
            "Predicted: no\n",
            "Confidence: 0.514 (Moderate)\n",
            "Perplexity: 14.750\n",
            "Uncertainty: 0.999\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 49/100 [00:27<00:29,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For patients who have small kidney stones and do not speak english, the probability of recovery is 86%. For patients who have small kidney stones and speak english, the probability of recovery is 75%. For patients who have large kidney stones and do not speak english, the probability of recovery is 19%. For patients who have large kidney stones and speak english, the probability of recovery is 9%. The overall probability of large kidney stone is 55%. Will speaking english increase the chance of recovery?\n",
            "Predicted: no\n",
            "Confidence: 0.516 (Moderate)\n",
            "Perplexity: 6.656\n",
            "Uncertainty: 0.999\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 50/100 [00:28<00:35,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of pexu is 92%. For those who are not pexu, the probability of rukz is 15%. For those who are pexu, the probability of rukz is 35%. Is rukz more likely than not rukz overall?\n",
            "Predicted: no\n",
            "Confidence: 0.581 (Moderate)\n",
            "Perplexity: 17.766\n",
            "Uncertainty: 0.981\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 51/100 [00:29<00:38,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having visited England is 22%. For people who have not visited England, the probability of employee being fired is 14%. For people who have visited England, the probability of employee being fired is 76%. Is employee being fired less likely than employee not being fired overall?\n",
            "Predicted: no\n",
            "Confidence: 0.832 (High)\n",
            "Perplexity: 16.453\n",
            "Uncertainty: 0.653\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 52/100 [00:30<00:45,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that hwax causes not jyka and gyzp. jyka and gyzp causes lirg. We observed an individual is hwax. Would an individual is lirg if jyka instead of not jyka?\n",
            "Predicted: yes\n",
            "Confidence: 0.199 (Low)\n",
            "Perplexity: 56.125\n",
            "Uncertainty: 0.721\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 53/100 [00:31<00:41,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For children with unintelligent parents and with low parental social status, the probability of intelligent child is 60%. For children with unintelligent parents and with high parental social status, the probability of intelligent child is 65%. For children with intelligent parents and with low parental social status, the probability of intelligent child is 29%. For children with intelligent parents and with high parental social status, the probability of intelligent child is 22%. For children with unintelligent parents and confounder inactive, the probability of high parental social status is 72%. For children with unintelligent parents and confounder active, the probability of high parental social status is 41%. For children with intelligent parents and confounder inactive, the probability of high parental social status is 35%. For children with intelligent parents and confounder active, the probability of high parental social status is 12%. The overall probability of confounder active is 52%. If we disregard the mediation effect through parents' social status, would parents' intelligence positively affect child's intelligence?\n",
            "Predicted: no\n",
            "Confidence: 0.941 (Very High)\n",
            "Perplexity: 4.695\n",
            "Uncertainty: 0.323\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 54/100 [00:31<00:34,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having a brother is 88%. For people who do not have a brother, the probability of high salary is 12%. For people who have a brother, the probability of high salary is 26%. Is high salary more likely than low salary overall?\n",
            "Predicted: no\n",
            "Confidence: 0.551 (Moderate)\n",
            "Perplexity: 15.164\n",
            "Uncertainty: 0.993\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 55/100 [00:32<00:30,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For nonsmokers and with no tar deposit, the probability of lung cancer is 34%. For nonsmokers and with high tar deposit, the probability of lung cancer is 59%. For smokers and with no tar deposit, the probability of lung cancer is 42%. For smokers and with high tar deposit, the probability of lung cancer is 69%. For nonsmokers, the probability of high tar deposit is 25%. For smokers, the probability of high tar deposit is 78%. For smokers, would it be less likely to see lung cancer if the person had been a nonsmoker?\n",
            "Predicted: no\n",
            "Confidence: 0.945 (Very High)\n",
            "Perplexity: 6.344\n",
            "Uncertainty: 0.307\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 56/100 [00:32<00:27,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 14%. For those who are not jyka, the probability of lirg is 85%. For those who are jyka, the probability of lirg is 84%. Is lirg more likely than not lirg overall?\n",
            "Predicted: no\n",
            "Confidence: 0.707 (High)\n",
            "Perplexity: 17.219\n",
            "Uncertainty: 0.872\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 57/100 [00:33<00:25,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For nonsmokers, the probability of high tar deposit is 56%. For smokers, the probability of high tar deposit is 83%. For nonsmokers and with no tar deposit, the probability of lung cancer is 42%. For nonsmokers and with high tar deposit, the probability of lung cancer is 83%. For smokers and with no tar deposit, the probability of lung cancer is 48%. For smokers and with high tar deposit, the probability of lung cancer is 74%. The overall probability of smoking is 45%. Does smoking negatively affect lung cancer through tar deposit?\n",
            "Predicted: no\n",
            "Confidence: 0.814 (High)\n",
            "Perplexity: 6.766\n",
            "Uncertainty: 0.693\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 58/100 [00:33<00:23,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how drug taken correlates with freckles in general. Method 2: We look at this correlation case by case according to unobserved confounders. To understand how drug taken affects freckles, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.434 (Low)\n",
            "Perplexity: 34.219\n",
            "Uncertainty: 0.987\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 59/100 [00:34<00:22,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For infants with nonsmoking mothers, the probability of high infant mortality is 79%. For infants with smoking mothers, the probability of high infant mortality is 52%. For infants with smoking mothers, would it be more likely to see high infant mortality if the infant had a nonsmoking mother?\n",
            "Predicted: no\n",
            "Confidence: 0.696 (Moderate)\n",
            "Perplexity: 11.852\n",
            "Uncertainty: 0.886\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 60/100 [00:34<00:20,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of alarm set by husband is 88%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 71%. Is ringing alarm less likely than silent alarm overall?\n",
            "Predicted: no\n",
            "Confidence: 0.905 (Very High)\n",
            "Perplexity: 24.469\n",
            "Uncertainty: 0.454\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 61/100 [00:35<00:21,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For individuals who are not male and applicants to a non-competitive department, the probability of admission acceptance is 85%. For individuals who are not male and applicants to a competitive department, the probability of admission acceptance is 62%. For individuals who are male and applicants to a non-competitive department, the probability of admission acceptance is 87%. For individuals who are male and applicants to a competitive department, the probability of admission acceptance is 56%. For individuals who are not male and out-of-state residents, the probability of competitive department is 86%. For individuals who are not male and in-state residents, the probability of competitive department is 45%. For individuals who are male and out-of-state residents, the probability of competitive department is 85%. For individuals who are male and in-state residents, the probability of competitive department is 46%. The overall probability of in-state residency is 95%. If we disregard the mediation effect through department competitiveness, would gender positively affect admission status?\n",
            "Predicted: yes\n",
            "Confidence: 0.016 (Low)\n",
            "Perplexity: 5.441\n",
            "Uncertainty: 0.119\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 62/100 [00:35<00:21,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For individuals who do not like spicy food and blue-collar workers, the probability of high salary is 70%. For individuals who do not like spicy food and white-collar workers, the probability of high salary is 48%. For individuals who like spicy food and blue-collar workers, the probability of high salary is 44%. For individuals who like spicy food and white-collar workers, the probability of high salary is 17%. For individuals who do not like spicy food and with low skill levels, the probability of white-collar job is 74%. For individuals who do not like spicy food and with high skill levels, the probability of white-collar job is 45%. For individuals who like spicy food and with low skill levels, the probability of white-collar job is 49%. For individuals who like spicy food and with high skill levels, the probability of white-collar job is 18%. The overall probability of high skill level is 95%. If we disregard the mediation effect through occupation, would liking spicy food negatively affect salary?\n",
            "Predicted: no\n",
            "Confidence: 0.798 (High)\n",
            "Perplexity: 4.434\n",
            "Uncertainty: 0.726\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 63/100 [00:36<00:20,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of yomx is 21%. The probability of not yomx and xevu is 31%. The probability of yomx and xevu is 17%. Is the chance of xevu smaller when observing yomx?\n",
            "Predicted: no\n",
            "Confidence: 0.947 (Very High)\n",
            "Perplexity: 23.859\n",
            "Uncertainty: 0.297\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 64/100 [00:36<00:19,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of speaking english is 98%. For people who do not speak english and are not famous, the probability of talent is 94%. For people who do not speak english and are famous, the probability of talent is 81%. For people who speak english and are not famous, the probability of talent is 91%. For people who speak english and are famous, the probability of talent is 74%. If we look at people who are famous, does the chance of talent decrease when speaking english?\n",
            "Predicted: no\n",
            "Confidence: 0.372 (Low)\n",
            "Perplexity: 6.648\n",
            "Uncertainty: 0.952\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 65/100 [00:37<00:19,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people with nonsmoking genes and nonsmokers, the probability of lung cancer is 76%. For people with nonsmoking genes and smokers, the probability of lung cancer is 60%. For people with smoking genes and nonsmokers, the probability of lung cancer is 61%. For people with smoking genes and smokers, the probability of lung cancer is 34%. For people with nonsmoking genes and with low pollution, the probability of smoking is 97%. For people with nonsmoking genes and with high pollution, the probability of smoking is 67%. For people with smoking genes and with low pollution, the probability of smoking is 53%. For people with smoking genes and with high pollution, the probability of smoking is 24%. The overall probability of high pollution is 16%. If we disregard the mediation effect through smoking, would gene negatively affect lung cancer?\n",
            "Predicted: no\n",
            "Confidence: 0.207 (Low)\n",
            "Perplexity: 4.988\n",
            "Uncertainty: 0.736\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 66/100 [00:38<00:19,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For patients who are young and pay a low hospital bill, the probability of freckles is 2%. For patients who are young and pay a high hospital bill, the probability of freckles is 17%. For patients who are old and pay a low hospital bill, the probability of freckles is 81%. For patients who are old and pay a high hospital bill, the probability of freckles is 96%. The overall probability of old age is 45%. Will high hospital bill decrease the chance of freckles?\n",
            "Predicted: no\n",
            "Confidence: 0.987 (Very High)\n",
            "Perplexity: 6.539\n",
            "Uncertainty: 0.100\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 67/100 [00:38<00:18,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 13%. For those who are not jyka, the probability of kwox is 36%. For those who are jyka, the probability of kwox is 49%. Is kwox less likely than not kwox overall?\n",
            "Predicted: no\n",
            "Confidence: 0.733 (High)\n",
            "Perplexity: 18.078\n",
            "Uncertainty: 0.838\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 68/100 [00:39<00:18,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of yupt is 83%. For those who are not yupt, the probability of muvq is 70%. For those who are yupt, the probability of muvq is 77%. Is muvq less likely than not muvq overall?\n",
            "Predicted: no\n",
            "Confidence: 0.203 (Low)\n",
            "Perplexity: 21.297\n",
            "Uncertainty: 0.728\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 69/100 [00:39<00:17,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of male gender is 11%. For individuals who are not male, the probability of being lactose intolerant is 88%. For individuals who are male, the probability of being lactose intolerant is 13%. Is being lactose intolerant more likely than not being lactose intolerant overall?\n",
            "Predicted: no\n",
            "Confidence: 0.286 (Low)\n",
            "Perplexity: 10.984\n",
            "Uncertainty: 0.864\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 70/100 [00:40<00:17,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how zuph correlates with uvzi in general. Method 2: We look at this correlation case by case according to wibl. To understand how zuph affects uvzi, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.683 (Moderate)\n",
            "Perplexity: 46.531\n",
            "Uncertainty: 0.902\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 71/100 [00:40<00:16,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of college degree or higher is 19%. For people without a college degree, the probability of high salary is 42%. For people with a college degree or higher, the probability of high salary is 63%. Is high salary more likely than low salary overall?\n",
            "Predicted: no\n",
            "Confidence: 0.731 (High)\n",
            "Perplexity: 13.508\n",
            "Uncertainty: 0.840\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 72/100 [00:41<00:14,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people with nonsmoking genes, the probability of lung cancer is 43%. For people with smoking genes, the probability of lung cancer is 58%. Will smoking gene decrease the chance of lung cancer?\n",
            "Predicted: no\n",
            "Confidence: 0.477 (Low)\n",
            "Perplexity: 16.844\n",
            "Uncertainty: 0.998\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 73/100 [00:41<00:13,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of rixq is 62%. The probability of not rixq and xevu is 20%. The probability of rixq and xevu is 31%. Is the chance of xevu smaller when observing rixq?\n",
            "Predicted: no\n",
            "Confidence: 0.459 (Low)\n",
            "Perplexity: 22.797\n",
            "Uncertainty: 0.995\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 74/100 [00:42<00:12,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of having a sister is 99%. For people who do not have a sister, the probability of lung cancer is 27%. For people who have a sister, the probability of lung cancer is 57%. Is lung cancer less likely than absence of lung cancer overall?\n",
            "Predicted: no\n",
            "Confidence: 0.621 (Moderate)\n",
            "Perplexity: 15.797\n",
            "Uncertainty: 0.958\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 75/100 [00:42<00:12,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that tijw causes xevo. xevo causes tijv. tijw or tijv causes gyzp. We observed an individual is tijw. Would an individual is gyzp if not xevo instead of xevo?\n",
            "Predicted: yes\n",
            "Confidence: 0.147 (Low)\n",
            "Perplexity: 50.500\n",
            "Uncertainty: 0.602\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 76/100 [00:43<00:11,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how hospital costs correlates with recovery in general. Method 2: We look at this correlation case by case according to age. To understand how hospital costs affects recovery, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.722 (High)\n",
            "Perplexity: 40.500\n",
            "Uncertainty: 0.853\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 77/100 [00:43<00:10,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of zuph is 88%. For those who are not zuph, the probability of glimx is 84%. For those who are zuph, the probability of glimx is 70%. Is glimx more likely than not glimx overall?\n",
            "Predicted: no\n",
            "Confidence: 0.168 (Low)\n",
            "Perplexity: 27.031\n",
            "Uncertainty: 0.653\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 78/100 [00:44<00:10,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of pexu is 68%. For those who are not pexu, the probability of rukz is 78%. For those who are pexu, the probability of rukz is 79%. Is rukz more likely than not rukz overall?\n",
            "Predicted: no\n",
            "Confidence: 0.665 (Moderate)\n",
            "Perplexity: 17.828\n",
            "Uncertainty: 0.920\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 79/100 [00:44<00:10,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For normal weight people and without diabetes, the probability of long lifespan is 23%. For normal weight people and with diabetes, the probability of long lifespan is 51%. For obese people and without diabetes, the probability of long lifespan is 52%. For obese people and with diabetes, the probability of long lifespan is 75%. For normal weight people and nonsmokers, the probability of having diabetes is 80%. For normal weight people and smokers, the probability of having diabetes is 58%. For obese people and nonsmokers, the probability of having diabetes is 51%. For obese people and smokers, the probability of having diabetes is 22%. The overall probability of smoker is 88%. Does obesity negatively affect lifespan through diabetes?\n",
            "Predicted: no\n",
            "Confidence: 0.773 (High)\n",
            "Perplexity: 5.391\n",
            "Uncertainty: 0.772\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 80/100 [00:45<00:09,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not yomx, the probability of xevu is 76%. For those who are yomx, the probability of xevu is 84%. For those who are yomx, would it be less likely to see xevu if the individual was not yomx?\n",
            "Predicted: no\n",
            "Confidence: 0.547 (Moderate)\n",
            "Perplexity: 15.984\n",
            "Uncertainty: 0.994\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 81/100 [00:45<00:09,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For patients who have small kidney stones and not receiving treatment, the probability of thick lips is 6%. For patients who have small kidney stones and receiving treatment, the probability of thick lips is 38%. For patients who have large kidney stones and not receiving treatment, the probability of thick lips is 63%. For patients who have large kidney stones and receiving treatment, the probability of thick lips is 95%. The overall probability of large kidney stone is 50%. For patients receiving treatment, would it be more likely to see thick lips if the patient had received no treatment?\n",
            "Predicted: no\n",
            "Confidence: 0.989 (Very High)\n",
            "Perplexity: 6.746\n",
            "Uncertainty: 0.089\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 82/100 [00:46<00:08,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look at how xevo correlates with gyzp case by case according to tijw. Method 2: We look directly at how xevo correlates with gyzp in general. To understand how xevo affects gyzp, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.927 (Very High)\n",
            "Perplexity: 35.312\n",
            "Uncertainty: 0.376\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 83/100 [00:46<00:08,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not yomx, the probability of xevu is 70%. For those who are yomx, the probability of xevu is 60%. Does yomx positively affect xevu through gwet?\n",
            "Predicted: no\n",
            "Confidence: 0.494 (Low)\n",
            "Perplexity: 31.297\n",
            "Uncertainty: 1.000\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 84/100 [00:47<00:07,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of jyka is 40%. The probability of not jyka and lirg is 3%. The probability of jyka and lirg is 11%. Is the chance of lirg larger when observing jyka?\n",
            "Predicted: no\n",
            "Confidence: 0.983 (Very High)\n",
            "Perplexity: 23.766\n",
            "Uncertainty: 0.123\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 85/100 [00:47<00:07,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For infants who do not have a sister and low infant birth weight, the probability of high infant mortality is 32%. For infants who do not have a sister and normal infant birth weight, the probability of high infant mortality is 73%. For infants who have a sister and low infant birth weight, the probability of high infant mortality is 4%. For infants who have a sister and normal infant birth weight, the probability of high infant mortality is 37%. For infants who do not have a sister and with poor health, the probability of normal infant birth weight is 55%. For infants who do not have a sister and with good health, the probability of normal infant birth weight is 24%. For infants who have a sister and with poor health, the probability of normal infant birth weight is 83%. For infants who have a sister and with good health, the probability of normal infant birth weight is 57%. The overall probability of good health is 6%. Does having a sister negatively affect infant mortality through infant's birth weight?\n",
            "Predicted: no\n",
            "Confidence: 0.155 (Low)\n",
            "Perplexity: 3.842\n",
            "Uncertainty: 0.622\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 86/100 [00:48<00:07,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of the captain's order to execute the prisoner is 59%. For captains who release prisoners, the probability of the prisoner's death is 33%. For captains who execute prisoners, the probability of the prisoner's death is 56%. Is the prisoner's death less likely than the prisoner being alive overall?\n",
            "Predicted: no\n",
            "Confidence: 0.915 (Very High)\n",
            "Perplexity: 15.219\n",
            "Uncertainty: 0.420\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 87/100 [00:48<00:06,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not tijv and are not xevo, the probability of gyzp is 15%. For those who are not tijv and are xevo, the probability of gyzp is 30%. For those who are tijv and are not xevo, the probability of gyzp is 15%. For those who are tijv and are xevo, the probability of gyzp is 66%. The overall probability of tijv is 79%. Will xevo increase the chance of gyzp?\n",
            "Predicted: no\n",
            "Confidence: 0.988 (Very High)\n",
            "Perplexity: 6.762\n",
            "Uncertainty: 0.094\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 88/100 [00:49<00:05,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of yupt is 83%. The probability of not yupt and muvq is 4%. The probability of yupt and muvq is 77%. Is the chance of muvq larger when observing yupt?\n",
            "Predicted: no\n",
            "Confidence: 0.810 (High)\n",
            "Perplexity: 31.531\n",
            "Uncertainty: 0.700\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 89/100 [00:49<00:05,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look directly at how appearance correlates with talent in general. Method 2: We look at this correlation case by case according to fame. To understand how appearance affects talent, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.266 (Low)\n",
            "Perplexity: 39.781\n",
            "Uncertainty: 0.835\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 90/100 [00:50<00:04,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For nonsmokers, the probability of lung cancer is 34%. For smokers, the probability of lung cancer is 51%. Will smoking increase the chance of lung cancer?\n",
            "Predicted: no\n",
            "Confidence: 0.939 (Very High)\n",
            "Perplexity: 14.836\n",
            "Uncertainty: 0.333\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 91/100 [00:50<00:04,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Method 1: We look at how talent correlates with effort case by case according to elite institution admission status. Method 2: We look directly at how talent correlates with effort in general. To understand how talent affects effort, is it more correct to use the Method 1 than Method 2?\n",
            "Predicted: no\n",
            "Confidence: 0.857 (High)\n",
            "Perplexity: 44.562\n",
            "Uncertainty: 0.593\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 92/100 [00:51<00:04,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of smoking is 48%. For nonsmokers, the probability of being allergic to peanuts is 50%. For smokers, the probability of being allergic to peanuts is 51%. Is being allergic to peanuts less likely than not being allergic to peanuts overall?\n",
            "Predicted: no\n",
            "Confidence: 0.753 (High)\n",
            "Perplexity: 12.352\n",
            "Uncertainty: 0.806\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 93/100 [00:51<00:03,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For people who do not have a sister and with low blood pressure, the probability of healthy heart is 61%. For people who do not have a sister and with high blood pressure, the probability of healthy heart is 92%. For people who have a sister and with low blood pressure, the probability of healthy heart is 18%. For people who have a sister and with high blood pressure, the probability of healthy heart is 45%. For people who do not have a sister, the probability of high blood pressure is 61%. For people who have a sister, the probability of high blood pressure is 14%. Does having a sister positively affect heart condition through blood pressure?\n",
            "Predicted: no\n",
            "Confidence: 0.378 (Low)\n",
            "Perplexity: 4.629\n",
            "Uncertainty: 0.956\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 94/100 [00:52<00:03,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that blowing out the candle and candle with wax causes dark room. We observed the candle is out of wax. Would the room is bright if blowing out the candle instead of not blowing out the candle?\n",
            "Predicted: yes\n",
            "Confidence: 0.026 (Low)\n",
            "Perplexity: 40.406\n",
            "Uncertainty: 0.176\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 95/100 [00:53<00:02,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For children with unintelligent parents, the probability of intelligent child is 42%. For children with intelligent parents, the probability of intelligent child is 56%. For children with intelligent parents, would it be less likely to see intelligent child if the child had unintelligent parents?\n",
            "Predicted: no\n",
            "Confidence: 0.985 (Very High)\n",
            "Perplexity: 12.109\n",
            "Uncertainty: 0.115\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 96/100 [00:53<00:02,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of receives treatment is 56%. The probability of receives no treatment and being allergic to peanuts is 8%. The probability of receives treatment and being allergic to peanuts is 36%. Is the chance of being allergic to peanuts larger when observing receives treatment?\n",
            "Predicted: no\n",
            "Confidence: 0.917 (Very High)\n",
            "Perplexity: 21.891\n",
            "Uncertainty: 0.414\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 97/100 [00:54<00:01,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: We know that speaking english and smoker causes having diabetes. speaking english and smoker and having diabetes causes long lifespan. We observed the person is a smoker. Would the person has a long lifespan if not speaking english instead of speaking english?\n",
            "Predicted: yes\n",
            "Confidence: 0.009 (Low)\n",
            "Perplexity: 52.312\n",
            "Uncertainty: 0.074\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 98/100 [00:54<00:01,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of smoking mother is 15%. For infants with nonsmoking mothers, the probability of normal infant birth weight is 7%. For infants with smoking mothers, the probability of normal infant birth weight is 47%. Is normal infant birth weight more likely than low infant birth weight overall?\n",
            "Predicted: no\n",
            "Confidence: 0.953 (Very High)\n",
            "Perplexity: 17.344\n",
            "Uncertainty: 0.275\n",
            "Ground truth: no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 99/100 [00:55<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: The overall probability of manager signing the termination letter is 30%. For managers who don't sign termination letters, the probability of large feet is 73%. For managers who sign termination letters, the probability of large feet is 25%. Is large feet more likely than small feet overall?\n",
            "Predicted: no\n",
            "Confidence: 0.537 (Moderate)\n",
            "Perplexity: 21.672\n",
            "Uncertainty: 0.996\n",
            "Ground truth: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 100/100 [00:55<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: For those who are not yomx, the probability of xevu is 36%. For those who are yomx, the probability of xevu is 38%. For those who are yomx, would it be less likely to see xevu if the individual was not yomx?\n",
            "Predicted: no\n",
            "Confidence: 0.558 (Moderate)\n",
            "Perplexity: 15.703\n",
            "Uncertainty: 0.990\n",
            "Ground truth: yes\n",
            "\n",
            "Detailed Evaluation Results:\n",
            "accuracy: 0.4400\n",
            "f1: 0.0968\n",
            "precision: 0.4286\n",
            "recall: 0.0545\n",
            "roc_auc: 0.4832\n",
            "brier_score: 0.3299\n",
            "log_loss: 1.3498\n",
            "\n",
            "perplexity:\n",
            "  mean: 22.3496\n",
            "  std: 17.5182\n",
            "  min: 3.8418\n",
            "  max: 83.2500\n",
            "\n",
            "confidence_distribution:\n",
            "  Very High: 0.3500\n",
            "  High: 0.2500\n",
            "  Moderate: 0.1800\n",
            "  Low: 0.2200\n",
            "\n",
            "calibration:\n",
            "  ece: 0.3665\n",
            "  mce: 0.5921\n",
            "very high_confidence_accuracy: 0.3714\n",
            "high_confidence_accuracy: 0.4800\n",
            "moderate_confidence_accuracy: 0.4444\n",
            "low_confidence_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}